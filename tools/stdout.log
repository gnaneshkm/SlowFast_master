[12/04 09:39:56][INFO] train_net.py: 377: Train with config:
[12/04 09:39:56][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'action_list.pbtxt',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['person_box_67091280_iou90/ava_detection_val_boxes_and_labels.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['ava_train_v2.2.csv',
                                     'person_box_67091280_iou90/ava_detection_train_boxes_and_labels_include_negative_v2.2.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 80,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 8,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 8,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 64,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 09:44:10][INFO] train_net.py: 377: Train with config:
[12/04 09:44:10][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'action_list.pbtxt',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['person_box_67091280_iou90/ava_detection_val_boxes_and_labels.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['ava_train_v2.2.csv',
                                     'person_box_67091280_iou90/ava_detection_train_boxes_and_labels_include_negative_v2.2.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 09:44:12][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 09:44:12][INFO] misc.py: 170: Params: 33,653,708
[12/04 09:44:12][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 09:44:12][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 09:44:12][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 09:44:12][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 09:44:12][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 09:44:12][INFO] misc.py: 182: nvidia-smi
[12/04 09:44:12][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 09:49:29][INFO] train_net.py: 377: Train with config:
[12/04 09:49:29][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'action_list.pbtxt',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 09:49:31][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 09:49:31][INFO] misc.py: 170: Params: 33,653,708
[12/04 09:49:31][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 09:49:31][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 09:49:31][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 09:49:31][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 09:49:31][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 09:49:31][INFO] misc.py: 182: nvidia-smi
[12/04 09:49:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 09:58:02][INFO] train_net.py: 377: Train with config:
[12/04 09:58:02][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'action_list.pbtxt',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 09:58:04][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 09:58:04][INFO] misc.py: 170: Params: 33,653,708
[12/04 09:58:04][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 09:58:04][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 09:58:04][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 09:58:04][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 09:58:04][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 09:58:04][INFO] misc.py: 182: nvidia-smi
[12/04 09:58:04][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 09:58:04][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 09:58:04][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 09:58:04][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 09:58:04][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 09:58:04][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 09:58:04][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 09:58:04][INFO] ava_dataset.py:  89: Split: train
[12/04 09:58:04][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 09:58:04][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 09:58:04][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 09:58:04][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 09:58:04][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 09:58:04][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 09:58:04][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 09:58:04][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 09:58:04][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 09:58:04][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 09:58:04][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 09:58:04][INFO] ava_dataset.py:  89: Split: val
[12/04 09:58:04][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 09:58:04][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 09:58:04][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 09:58:04][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 10:03:00][INFO] train_net.py: 377: Train with config:
[12/04 10:03:00][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'action_list.pbtxt',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 10:03:02][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 10:03:02][INFO] misc.py: 170: Params: 33,653,708
[12/04 10:03:02][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 10:03:02][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:03:02][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 10:03:02][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:03:02][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 10:03:02][INFO] misc.py: 182: nvidia-smi
[12/04 10:03:02][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 10:03:02][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 10:03:02][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:03:02][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 10:03:02][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 10:03:02][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:03:02][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:03:02][INFO] ava_dataset.py:  89: Split: train
[12/04 10:03:02][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:03:02][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 10:03:02][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:03:02][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 10:03:02][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 10:03:02][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 10:03:02][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:03:02][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 10:03:02][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 10:03:02][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:03:02][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:03:02][INFO] ava_dataset.py:  89: Split: val
[12/04 10:03:02][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:03:02][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 10:03:02][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:03:02][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 10:14:31][INFO] train_net.py: 377: Train with config:
[12/04 10:14:31][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 10:14:33][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 10:14:33][INFO] misc.py: 170: Params: 33,653,708
[12/04 10:14:33][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 10:14:33][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:14:33][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 10:14:33][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:14:33][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 10:14:33][INFO] misc.py: 182: nvidia-smi
[12/04 10:14:33][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 10:14:33][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 10:14:33][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:14:33][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 10:14:33][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 10:14:33][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:14:33][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:14:33][INFO] ava_dataset.py:  89: Split: train
[12/04 10:14:33][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:14:33][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 10:14:33][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:14:33][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 10:14:33][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 10:14:33][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 10:14:33][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:14:33][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 10:14:33][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 10:14:33][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:14:33][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:14:33][INFO] ava_dataset.py:  89: Split: val
[12/04 10:14:33][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:14:33][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 10:14:33][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:14:33][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 10:14:33][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 10:14:33][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 10:14:33][INFO] train_net.py: 417: Start epoch: 1
[12/04 10:14:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.28074, "dt_data": 0.69688, "dt_net": 0.58386, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 10:14:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.21643, "dt_data": 0.68440, "dt_net": 0.53203, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 10:14:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.21309, "dt_data": 0.68075, "dt_net": 0.53234, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 10:14:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.21248, "dt_data": 0.67990, "dt_net": 0.53258, "eta": "0:00:01", "loss": 0.45408, "lr": 0.06005, "mode": "train"}
[12/04 10:14:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.20986, "dt_data": 0.67792, "dt_net": 0.53194, "eta": "0:00:01", "loss": 0.58590, "lr": 0.08002, "mode": "train"}
[12/04 10:14:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.74618, "dt_data": 0.67219, "dt_net": 0.07399, "eta": "0:00:00", "mode": "val"}
[12/04 10:15:20][INFO] train_net.py: 377: Train with config:
[12/04 10:15:20][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 10:15:21][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 10:15:21][INFO] misc.py: 170: Params: 33,653,708
[12/04 10:15:21][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 10:15:22][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:15:22][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 10:15:22][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:15:22][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 10:15:22][INFO] misc.py: 182: nvidia-smi
[12/04 10:15:22][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00005.pyth.
[12/04 10:15:22][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00005.pyth.
[12/04 10:15:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 10:15:22][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 10:15:22][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:15:22][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 10:15:22][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 10:15:22][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:15:22][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:15:22][INFO] ava_dataset.py:  89: Split: train
[12/04 10:15:22][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:15:22][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 10:15:22][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:15:22][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 10:15:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 10:15:22][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 10:15:22][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:15:22][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 10:15:22][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 10:15:22][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:15:22][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:15:22][INFO] ava_dataset.py:  89: Split: val
[12/04 10:15:22][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:15:22][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 10:15:22][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:15:22][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 10:15:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 10:15:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 10:15:22][INFO] train_net.py: 417: Start epoch: 6
[12/04 10:15:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.23004, "dt_data": 0.68798, "dt_net": 0.54205, "eta": "0:00:01", "loss": 0.77237, "lr": 0.10000, "mode": "train"}
[12/04 10:15:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.20825, "dt_data": 0.67558, "dt_net": 0.53267, "eta": "0:00:01", "loss": 0.44853, "lr": 0.10000, "mode": "train"}
[12/04 10:15:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.21036, "dt_data": 0.67808, "dt_net": 0.53229, "eta": "0:00:01", "loss": 0.30881, "lr": 0.10000, "mode": "train"}
[12/04 10:15:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.20949, "dt_data": 0.67701, "dt_net": 0.53248, "eta": "0:00:01", "loss": 0.29903, "lr": 0.10000, "mode": "train"}
[12/04 10:15:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.21725, "dt_data": 0.68481, "dt_net": 0.53244, "eta": "0:00:01", "loss": 0.33113, "lr": 0.10000, "mode": "train"}
[12/04 10:15:30][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.75428, "dt_data": 0.68077, "dt_net": 0.07350, "eta": "0:00:00", "mode": "val"}
[12/04 10:59:35][INFO] train_net.py: 377: Train with config:
[12/04 10:59:35][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 10:59:36][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 10:59:36][INFO] misc.py: 170: Params: 33,653,708
[12/04 10:59:36][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 10:59:37][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:59:37][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 10:59:37][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 10:59:37][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 10:59:37][INFO] misc.py: 182: nvidia-smi
[12/04 10:59:37][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00010.pyth.
[12/04 10:59:37][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00010.pyth.
[12/04 10:59:37][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 10:59:37][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 10:59:37][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:59:37][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 10:59:37][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 10:59:37][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:59:37][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:59:37][INFO] ava_dataset.py:  89: Split: train
[12/04 10:59:37][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:59:37][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 10:59:37][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:59:37][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 10:59:37][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 10:59:37][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 10:59:37][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 10:59:37][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 10:59:37][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 10:59:37][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 10:59:37][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 10:59:37][INFO] ava_dataset.py:  89: Split: val
[12/04 10:59:37][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 10:59:37][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 10:59:37][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 10:59:37][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 10:59:37][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 10:59:37][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 10:59:37][INFO] train_net.py: 417: Start epoch: 11
[12/04 10:59:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.22300, "dt_data": 0.69108, "dt_net": 0.53192, "eta": "0:00:01", "loss": 0.28810, "lr": 0.01000, "mode": "train"}
[12/04 10:59:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.21875, "dt_data": 0.68424, "dt_net": 0.53452, "eta": "0:00:01", "loss": 0.28044, "lr": 0.01000, "mode": "train"}
[12/04 10:59:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.21893, "dt_data": 0.68506, "dt_net": 0.53387, "eta": "0:00:01", "loss": 0.26905, "lr": 0.01000, "mode": "train"}
[12/04 10:59:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.21754, "dt_data": 0.68333, "dt_net": 0.53421, "eta": "0:00:01", "loss": 0.27520, "lr": 0.01000, "mode": "train"}
[12/04 10:59:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.21766, "dt_data": 0.68358, "dt_net": 0.53407, "eta": "0:00:01", "loss": 0.26708, "lr": 0.01000, "mode": "train"}
[12/04 10:59:45][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.76023, "dt_data": 0.68643, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/04 10:59:45][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 10:59:45][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 10:59:45][INFO] ava_eval_helper.py: 302: AVA results wrote to detections_latest.csv
[12/04 10:59:45][INFO] ava_eval_helper.py: 303: 	took 0 seconds.
[12/04 10:59:45][INFO] ava_eval_helper.py: 302: AVA results wrote to groundtruth_latest.csv
[12/04 10:59:45][INFO] ava_eval_helper.py: 303: 	took 0 seconds.
[12/04 11:00:43][INFO] train_net.py: 377: Train with config:
[12/04 11:00:43][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 11:00:44][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 11:00:44][INFO] misc.py: 170: Params: 33,653,708
[12/04 11:00:44][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 11:00:45][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:00:45][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 11:00:45][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:00:45][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 11:00:45][INFO] misc.py: 182: nvidia-smi
[12/04 11:00:45][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00015.pyth.
[12/04 11:00:45][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00015.pyth.
[12/04 11:00:45][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 11:00:45][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 11:00:45][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:00:45][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 11:00:45][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 11:00:45][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:00:45][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:00:45][INFO] ava_dataset.py:  89: Split: train
[12/04 11:00:45][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:00:45][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 11:00:45][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:00:45][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 11:00:45][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:00:45][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 11:00:45][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:00:45][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 11:00:45][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 11:00:45][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:00:45][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:00:45][INFO] ava_dataset.py:  89: Split: val
[12/04 11:00:45][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:00:45][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 11:00:45][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:00:45][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 11:00:45][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 11:00:45][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:00:45][INFO] train_net.py: 417: Start epoch: 16
[12/04 11:00:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.24687, "dt_data": 0.69265, "dt_net": 0.55422, "eta": "0:00:01", "loss": 0.26746, "lr": 0.00100, "mode": "train"}
[12/04 11:00:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.21649, "dt_data": 0.68184, "dt_net": 0.53465, "eta": "0:00:01", "loss": 0.26460, "lr": 0.00100, "mode": "train"}
[12/04 11:00:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.22275, "dt_data": 0.68888, "dt_net": 0.53387, "eta": "0:00:01", "loss": 0.26429, "lr": 0.00100, "mode": "train"}
[12/04 11:00:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.22174, "dt_data": 0.68768, "dt_net": 0.53406, "eta": "0:00:01", "loss": 0.26554, "lr": 0.00100, "mode": "train"}
[12/04 11:00:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.22235, "dt_data": 0.68863, "dt_net": 0.53372, "eta": "0:00:01", "loss": 0.26478, "lr": 0.00100, "mode": "train"}
[12/04 11:00:53][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.77182, "dt_data": 0.69826, "dt_net": 0.07356, "eta": "0:00:00", "mode": "val"}
[12/04 11:00:53][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 11:00:53][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 11:00:53][INFO] ava_eval_helper.py: 293: AVA results wrote to detections_latest.csv
[12/04 11:00:53][INFO] ava_eval_helper.py: 294: 	took 0 seconds.
[12/04 11:00:53][INFO] ava_eval_helper.py: 293: AVA results wrote to groundtruth_latest.csv
[12/04 11:00:53][INFO] ava_eval_helper.py: 294: 	took 0 seconds.
[12/04 11:01:22][INFO] train_net.py: 377: Train with config:
[12/04 11:01:22][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 11:01:24][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 11:01:24][INFO] misc.py: 170: Params: 33,653,708
[12/04 11:01:24][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 11:01:24][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:01:24][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 11:01:24][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:01:24][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 11:01:24][INFO] misc.py: 182: nvidia-smi
[12/04 11:01:24][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 11:01:24][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 11:01:24][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 11:01:24][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 11:01:24][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:01:24][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 11:01:24][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 11:01:24][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:01:24][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:01:24][INFO] ava_dataset.py:  89: Split: train
[12/04 11:01:24][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:01:24][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 11:01:24][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:01:24][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 11:01:24][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:01:24][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 11:01:24][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:01:24][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 11:01:24][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 11:01:24][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:01:24][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:01:24][INFO] ava_dataset.py:  89: Split: val
[12/04 11:01:24][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:01:24][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 11:01:24][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:01:24][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 11:01:24][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 11:01:24][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:01:24][INFO] train_net.py: 417: Start epoch: 21
[12/04 11:01:24][INFO] test_net.py: 156: Test with config:
[12/04 11:01:24][INFO] test_net.py: 157: AVA:
  ANNOTATION_DIR: /home/gnk/data_ava/data/ava/annotations/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: 
  FRAME_DIR: /home/gnk/data_ava/data/ava/frames/
  FRAME_LIST_DIR: /home/gnk/data_ava/data/ava/frame_lists/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_bbox5.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: action_list.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val3.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_bbox5.csv']
  TRAIN_GT_BOX_LISTS: []
  TRAIN_LISTS: ['train3.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: ['train_ava_box.csv']
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: /home/gnk/data_ava/data/ava
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 5
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 2
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 1
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 4
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[], []], [[], []]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 7
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: [1, 0.1, 0.01, 0.001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 20
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: [0, 10, 15, 20]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.000125
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 1
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: caffe2
  DATASET: ava
  ENABLE: True
  EVAL_PERIOD: 5
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/04 11:01:25][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 11:01:25][INFO] misc.py: 170: Params: 33,653,708
[12/04 11:01:25][INFO] misc.py: 171: Mem: 1.6054115295410156 MB
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 11:01:25][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:01:25][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 11:01:25][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:01:25][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 11:01:25][INFO] misc.py: 182: nvidia-smi
[12/04 11:01:25][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 11:01:25][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:01:25][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 11:01:25][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:01:25][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 11:01:25][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 11:01:25][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:01:25][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:01:25][INFO] ava_dataset.py:  89: Split: test
[12/04 11:01:25][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:01:25][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 11:01:25][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:01:25][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 11:01:25][INFO] test_net.py: 168: Testing model for 1 iterations
[12/04 11:01:25][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:01:26][INFO] logging.py:  96: json_stats: {"_type": "test_iter", "cur_iter": "1", "dt": 0.78360, "dt_data": 0.71030, "dt_net": 0.07330, "eta": "0:00:00", "mode": "test"}
[12/04 11:01:26][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 11:01:26][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 11:01:26][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 11:01:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 11:01:26][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 11:01:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 11:01:26][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 11:01:26][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003274 seconds.
[12/04 11:01:26][INFO] logging.py:  96: json_stats: {"map": 0.55666, "mode": "test"}
[12/04 11:02:09][INFO] train_net.py: 377: Train with config:
[12/04 11:02:09][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 11:02:10][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 11:02:10][INFO] misc.py: 170: Params: 33,653,708
[12/04 11:02:10][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 11:02:11][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:02:11][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 11:02:11][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:02:11][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 11:02:11][INFO] misc.py: 182: nvidia-smi
[12/04 11:02:11][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 11:02:11][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 11:02:11][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 11:02:11][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 11:02:11][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:02:11][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 11:02:11][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 11:02:11][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:02:11][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:02:11][INFO] ava_dataset.py:  89: Split: train
[12/04 11:02:11][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:02:11][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 11:02:11][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:02:11][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 11:02:11][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:02:11][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 11:02:11][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:02:11][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 11:02:11][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 11:02:11][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:02:11][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:02:11][INFO] ava_dataset.py:  89: Split: val
[12/04 11:02:11][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:02:11][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 11:02:11][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:02:11][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 11:02:11][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 11:02:11][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:02:11][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 11:02:12][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 11:02:12][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 11:02:12][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 11:02:12][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 11:02:12][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./runs-ava`
[12/04 11:02:12][INFO] train_net.py: 417: Start epoch: 21
[12/04 11:02:12][INFO] test_net.py: 156: Test with config:
[12/04 11:02:12][INFO] test_net.py: 157: AVA:
  ANNOTATION_DIR: /home/gnk/data_ava/data/ava/annotations/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: 
  FRAME_DIR: /home/gnk/data_ava/data/ava/frames/
  FRAME_LIST_DIR: /home/gnk/data_ava/data/ava/frame_lists/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_bbox5.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: action_list.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val3.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_bbox5.csv']
  TRAIN_GT_BOX_LISTS: []
  TRAIN_LISTS: ['train3.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: ['train_ava_box.csv']
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: /home/gnk/data_ava/data/ava
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 5
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 2
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 1
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 4
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[], []], [[], []]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 7
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: [1, 0.1, 0.01, 0.001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 20
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: [0, 10, 15, 20]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.000125
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 1
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: caffe2
  DATASET: ava
  ENABLE: True
  EVAL_PERIOD: 5
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/04 11:02:12][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 11:02:12][INFO] misc.py: 170: Params: 33,653,708
[12/04 11:02:12][INFO] misc.py: 171: Mem: 1.6054115295410156 MB
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 11:02:12][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:02:12][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 11:02:13][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 11:02:13][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 11:02:13][INFO] misc.py: 182: nvidia-smi
[12/04 11:02:13][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 11:02:13][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:02:13][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 11:02:13][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 11:02:13][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 11:02:13][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 11:02:13][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 11:02:13][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 11:02:13][INFO] ava_dataset.py:  89: Split: test
[12/04 11:02:13][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 11:02:13][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 11:02:13][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 11:02:13][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 11:02:13][INFO] test_net.py: 168: Testing model for 1 iterations
[12/04 11:02:13][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 11:02:13][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./runs-ava`
[12/04 11:02:14][INFO] logging.py:  96: json_stats: {"_type": "test_iter", "cur_iter": "1", "dt": 0.75784, "dt_data": 0.68442, "dt_net": 0.07341, "eta": "0:00:00", "mode": "test"}
[12/04 11:02:14][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 11:02:14][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 11:02:14][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 11:02:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 11:02:14][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 11:02:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 11:02:14][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 11:02:14][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003359 seconds.
[12/04 11:02:14][INFO] logging.py:  96: json_stats: {"map": 0.55666, "mode": "test"}
[12/04 14:53:28][INFO] train_net.py: 377: Train with config:
[12/04 14:53:28][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 14:53:30][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 14:53:30][INFO] misc.py: 170: Params: 33,653,708
[12/04 14:53:30][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 14:53:30][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:53:30][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 14:53:31][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:53:31][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 14:53:31][INFO] misc.py: 182: nvidia-smi
[12/04 14:53:31][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:53:31][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:53:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 14:53:31][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 14:53:31][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:53:31][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 14:53:31][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 14:53:31][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:53:31][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:53:31][INFO] ava_dataset.py:  89: Split: train
[12/04 14:53:31][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:53:31][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 14:53:31][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:53:31][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 14:53:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:53:31][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 14:53:31][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:53:31][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 14:53:31][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 14:53:31][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:53:31][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:53:31][INFO] ava_dataset.py:  89: Split: val
[12/04 14:53:31][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:53:31][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 14:53:31][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:53:31][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 14:53:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 14:53:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:53:31][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 14:53:31][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 14:53:31][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 14:53:31][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 14:53:31][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 14:53:32][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./runs-ava`
[12/04 14:53:32][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 14:53:32][INFO] train_net.py: 417: Start epoch: 21
[12/04 14:53:32][INFO] test_net.py: 156: Test with config:
[12/04 14:53:32][INFO] test_net.py: 157: AVA:
  ANNOTATION_DIR: /home/gnk/data_ava/data/ava/annotations/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: 
  FRAME_DIR: /home/gnk/data_ava/data/ava/frames/
  FRAME_LIST_DIR: /home/gnk/data_ava/data/ava/frame_lists/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_bbox5.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: action_list.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val3.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_bbox5.csv']
  TRAIN_GT_BOX_LISTS: []
  TRAIN_LISTS: ['train3.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: ['train_ava_box.csv']
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: /home/gnk/data_ava/data/ava
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 5
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 2
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 1
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 4
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[], []], [[], []]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 7
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: [1, 0.1, 0.01, 0.001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 20
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: [0, 10, 15, 20]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.000125
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: /home/gnk/data_ava/data/ava/annotations/AVA_classnames.json
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 1
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: caffe2
  DATASET: ava
  ENABLE: True
  EVAL_PERIOD: 5
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/04 14:53:32][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 14:53:32][INFO] misc.py: 170: Params: 33,653,708
[12/04 14:53:32][INFO] misc.py: 171: Mem: 1.6054115295410156 MB
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 14:53:32][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:53:32][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 14:53:33][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:53:33][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 14:53:33][INFO] misc.py: 182: nvidia-smi
[12/04 14:53:33][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:53:33][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:53:33][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 14:53:33][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:53:33][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 14:53:33][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 14:53:33][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:53:33][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:53:33][INFO] ava_dataset.py:  89: Split: test
[12/04 14:53:33][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:53:33][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 14:53:33][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:53:33][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 14:53:33][INFO] test_net.py: 168: Testing model for 1 iterations
[12/04 14:53:33][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:53:33][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./runs-ava`
[12/04 14:53:33][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 14:53:34][INFO] logging.py:  96: json_stats: {"_type": "test_iter", "cur_iter": "1", "dt": 0.78629, "dt_data": 0.71279, "dt_net": 0.07350, "eta": "0:00:00", "mode": "test"}
[12/04 14:53:34][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 14:53:34][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 14:53:34][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 14:53:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 14:53:34][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 14:53:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 14:53:34][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 14:53:34][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002973 seconds.
[12/04 14:53:34][INFO] logging.py:  96: json_stats: {"map": 0.55666, "mode": "test"}
[12/04 14:58:30][INFO] train_net.py: 377: Train with config:
[12/04 14:58:30][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 14:58:32][INFO] train_net.py: 377: Train with config:
[12/04 14:58:32][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 14:58:34][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 14:58:34][INFO] misc.py: 170: Params: 33,653,708
[12/04 14:58:34][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 14:58:34][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:58:34][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 14:58:34][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:58:34][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 14:58:34][INFO] misc.py: 182: nvidia-smi
[12/04 14:58:34][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:58:34][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:58:35][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 14:58:35][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 14:58:35][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:58:35][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 14:58:35][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 14:58:35][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:58:35][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:58:35][INFO] ava_dataset.py:  89: Split: train
[12/04 14:58:35][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:58:35][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 14:58:35][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:58:35][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 14:58:35][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:58:35][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 14:58:35][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:58:35][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 14:58:35][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 14:58:35][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:58:35][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:58:35][INFO] ava_dataset.py:  89: Split: val
[12/04 14:58:35][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:58:35][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 14:58:35][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:58:35][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 14:58:35][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 14:58:35][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:58:35][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 14:58:35][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 14:58:35][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 14:58:35][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 14:58:35][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 14:58:35][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./runs-ava`
[12/04 14:58:35][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 14:58:35][INFO] train_net.py: 417: Start epoch: 21
[12/04 14:58:35][INFO] test_net.py: 156: Test with config:
[12/04 14:58:35][INFO] test_net.py: 157: AVA:
  ANNOTATION_DIR: /home/gnk/data_ava/data/ava/annotations/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: 
  FRAME_DIR: /home/gnk/data_ava/data/ava/frames/
  FRAME_LIST_DIR: /home/gnk/data_ava/data/ava/frame_lists/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_bbox5.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: action_list.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val3.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_bbox5.csv']
  TRAIN_GT_BOX_LISTS: []
  TRAIN_LISTS: ['train3.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: ['train_ava_box.csv']
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: /home/gnk/data_ava/data/ava
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 5
  TEST_CROP_SIZE: 224
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 2
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 1
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 4
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[], []], [[], []]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 7
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: [1, 0.1, 0.01, 0.001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 20
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: [0, 10, 15, 20]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.000125
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: /home/gnk/data_ava/data/ava/annotations/AVA_classnames.json
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: True
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 1
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: caffe2
  DATASET: ava
  ENABLE: True
  EVAL_PERIOD: 5
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[12/04 14:58:36][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 14:58:36][INFO] misc.py: 170: Params: 33,653,708
[12/04 14:58:36][INFO] misc.py: 171: Mem: 1.6054115295410156 MB
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 14:58:36][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:58:36][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 14:58:36][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:58:36][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 14:58:36][INFO] misc.py: 182: nvidia-smi
[12/04 14:58:36][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:58:36][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:58:36][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 14:58:36][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:58:36][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 14:58:36][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 14:58:36][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:58:36][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:58:36][INFO] ava_dataset.py:  89: Split: test
[12/04 14:58:36][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:58:36][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 14:58:36][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:58:36][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 14:58:36][INFO] test_net.py: 168: Testing model for 1 iterations
[12/04 14:58:36][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:58:36][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./runs-ava`
[12/04 14:58:36][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 14:58:37][INFO] logging.py:  96: json_stats: {"_type": "test_iter", "cur_iter": "1", "dt": 0.76122, "dt_data": 0.68797, "dt_net": 0.07324, "eta": "0:00:00", "mode": "test"}
[12/04 14:58:37][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 14:58:37][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 14:58:37][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 14:58:37][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 14:58:37][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 14:58:37][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 14:58:37][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 14:58:37][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003445 seconds.
[12/04 14:58:37][INFO] logging.py:  96: json_stats: {"map": 0.55666, "mode": "test"}
[12/04 14:59:28][INFO] train_net.py: 377: Train with config:
[12/04 14:59:28][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 14:59:30][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 14:59:30][INFO] misc.py: 170: Params: 33,653,708
[12/04 14:59:30][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 14:59:30][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:59:30][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 14:59:30][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 14:59:30][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 14:59:30][INFO] misc.py: 182: nvidia-smi
[12/04 14:59:31][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:59:31][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 14:59:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 14:59:31][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 14:59:31][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:59:31][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 14:59:31][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 14:59:31][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:59:31][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:59:31][INFO] ava_dataset.py:  89: Split: train
[12/04 14:59:31][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:59:31][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 14:59:31][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:59:31][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 14:59:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:59:31][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 14:59:31][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 14:59:31][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 14:59:31][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 14:59:31][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 14:59:31][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 14:59:31][INFO] ava_dataset.py:  89: Split: val
[12/04 14:59:31][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 14:59:31][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 14:59:31][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 14:59:31][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 14:59:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 14:59:31][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 14:59:31][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 14:59:31][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 14:59:31][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 14:59:31][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 14:59:31][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 14:59:32][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir ./runs-ava`
[12/04 14:59:32][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 14:59:32][INFO] train_net.py: 417: Start epoch: 21
[12/04 15:05:20][INFO] train_net.py: 377: Train with config:
[12/04 15:05:20][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 15:05:21][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 15:05:21][INFO] misc.py: 170: Params: 33,653,708
[12/04 15:05:21][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 15:05:22][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 15:05:22][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 15:05:22][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 15:05:22][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 15:05:22][INFO] misc.py: 182: nvidia-smi
[12/04 15:05:22][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 15:05:22][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 15:05:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 15:05:22][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 15:05:22][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 15:05:22][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 15:05:22][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 15:05:22][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 15:05:22][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 15:05:22][INFO] ava_dataset.py:  89: Split: train
[12/04 15:05:22][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 15:05:22][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 15:05:22][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 15:05:22][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 15:05:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 15:05:22][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 15:05:22][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 15:05:22][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 15:05:22][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 15:05:22][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 15:05:22][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 15:05:22][INFO] ava_dataset.py:  89: Split: val
[12/04 15:05:22][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 15:05:22][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 15:05:22][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 15:05:22][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 15:05:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 15:05:22][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 15:05:22][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 15:05:23][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 15:05:23][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 15:05:23][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 15:05:23][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 15:05:23][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 15:05:23][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 15:05:23][INFO] train_net.py: 417: Start epoch: 21
[12/04 15:25:33][INFO] train_net.py: 377: Train with config:
[12/04 15:25:33][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 15:25:35][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 15:25:35][INFO] misc.py: 170: Params: 33,653,708
[12/04 15:25:35][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 15:25:35][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 15:25:35][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 15:25:35][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 15:25:35][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 15:25:35][INFO] misc.py: 182: nvidia-smi
[12/04 15:25:35][INFO] checkpoint.py: 493: Load from last checkpoint, ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 15:25:35][INFO] checkpoint.py: 209: Loading network weights from ./checkpoints/checkpoint_epoch_00020.pyth.
[12/04 15:25:36][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 15:25:36][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 15:25:36][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 15:25:36][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 15:25:36][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 15:25:36][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 15:25:36][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 15:25:36][INFO] ava_dataset.py:  89: Split: train
[12/04 15:25:36][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 15:25:36][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 15:25:36][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 15:25:36][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 15:25:36][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 15:25:36][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 15:25:36][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 15:25:36][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 15:25:36][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 15:25:36][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 15:25:36][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 15:25:36][INFO] ava_dataset.py:  89: Split: val
[12/04 15:25:36][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 15:25:36][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 15:25:36][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 15:25:36][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 15:25:36][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 15:25:36][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 15:25:36][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 15:25:36][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 15:25:36][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 15:25:36][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 15:25:36][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 15:25:36][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 15:25:36][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 15:25:36][INFO] train_net.py: 417: Start epoch: 21
[12/04 15:28:39][INFO] train_net.py: 377: Train with config:
[12/04 15:28:39][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 15:28:41][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 15:28:41][INFO] misc.py: 170: Params: 33,653,708
[12/04 15:28:41][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 15:28:41][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 15:28:41][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 15:28:41][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 15:28:41][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 15:28:41][INFO] misc.py: 182: nvidia-smi
[12/04 15:28:41][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 15:28:41][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 15:28:41][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 15:28:41][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 15:28:41][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 15:28:41][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 15:28:41][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 15:28:41][INFO] ava_dataset.py:  89: Split: train
[12/04 15:28:41][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 15:28:41][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 15:28:41][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 15:28:41][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 15:28:41][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 15:28:41][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 15:28:41][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 15:28:41][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 15:28:41][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 15:28:41][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 15:28:41][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 15:28:41][INFO] ava_dataset.py:  89: Split: val
[12/04 15:28:41][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 15:28:41][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 15:28:41][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 15:28:41][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 15:28:41][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 15:28:41][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 15:28:42][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 15:28:42][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 15:28:42][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 15:28:42][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 15:28:42][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 15:28:42][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 15:28:42][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 15:28:42][INFO] train_net.py: 417: Start epoch: 1
[12/04 15:28:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.33985, "dt_data": 0.81161, "dt_net": 0.52824, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 15:28:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.29219, "dt_data": 0.75943, "dt_net": 0.53276, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 15:28:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.29265, "dt_data": 0.75974, "dt_net": 0.53290, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 15:28:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.29513, "dt_data": 0.76220, "dt_net": 0.53292, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/04 15:28:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.29543, "dt_data": 0.76225, "dt_net": 0.53317, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/04 15:28:51][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.86240, "dt_data": 0.78923, "dt_net": 0.07316, "eta": "0:00:00", "mode": "val"}
[12/04 15:28:51][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 15:28:51][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 15:28:51][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 15:28:51][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:28:51][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 15:28:51][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:28:51][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 15:28:51][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003194 seconds.
[12/04 15:28:51][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/04 15:28:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.29252, "dt_data": 0.75927, "dt_net": 0.53324, "eta": "0:00:01", "loss": 0.92409, "lr": 0.10000, "mode": "train"}
[12/04 15:28:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.29534, "dt_data": 0.76269, "dt_net": 0.53265, "eta": "0:00:01", "loss": 0.72429, "lr": 0.10000, "mode": "train"}
[12/04 15:28:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.29846, "dt_data": 0.76556, "dt_net": 0.53290, "eta": "0:00:01", "loss": 0.71014, "lr": 0.10000, "mode": "train"}
[12/04 15:28:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.29112, "dt_data": 0.75822, "dt_net": 0.53290, "eta": "0:00:01", "loss": 0.49085, "lr": 0.10000, "mode": "train"}
[12/04 15:28:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.29225, "dt_data": 0.75957, "dt_net": 0.53267, "eta": "0:00:01", "loss": 0.80441, "lr": 0.10000, "mode": "train"}
[12/04 15:28:59][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.85197, "dt_data": 0.77889, "dt_net": 0.07307, "eta": "0:00:00", "mode": "val"}
[12/04 15:28:59][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 15:28:59][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 15:28:59][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 15:28:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:28:59][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 15:28:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:28:59][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 15:28:59][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003010 seconds.
[12/04 15:28:59][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.81250, "mode": "val"}
[12/04 15:29:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.29363, "dt_data": 0.76101, "dt_net": 0.53262, "eta": "0:00:01", "loss": 2.73837, "lr": 0.01000, "mode": "train"}
[12/04 15:29:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.29160, "dt_data": 0.75875, "dt_net": 0.53285, "eta": "0:00:01", "loss": 0.99053, "lr": 0.01000, "mode": "train"}
[12/04 15:29:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.29497, "dt_data": 0.76145, "dt_net": 0.53352, "eta": "0:00:01", "loss": 0.41521, "lr": 0.01000, "mode": "train"}
[12/04 15:29:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.29328, "dt_data": 0.75967, "dt_net": 0.53360, "eta": "0:00:01", "loss": 0.32314, "lr": 0.01000, "mode": "train"}
[12/04 15:29:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.29711, "dt_data": 0.76300, "dt_net": 0.53411, "eta": "0:00:01", "loss": 0.29427, "lr": 0.01000, "mode": "train"}
[12/04 15:29:08][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.85694, "dt_data": 0.78352, "dt_net": 0.07341, "eta": "0:00:00", "mode": "val"}
[12/04 15:29:08][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 15:29:08][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 15:29:08][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 15:29:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:29:08][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 15:29:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:29:08][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 15:29:08][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003039 seconds.
[12/04 15:29:08][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.57879, "mode": "val"}
[12/04 15:29:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.29504, "dt_data": 0.76040, "dt_net": 0.53463, "eta": "0:00:01", "loss": 0.36411, "lr": 0.00100, "mode": "train"}
[12/04 15:29:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.29262, "dt_data": 0.75868, "dt_net": 0.53393, "eta": "0:00:01", "loss": 0.36215, "lr": 0.00100, "mode": "train"}
[12/04 15:29:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.29523, "dt_data": 0.76094, "dt_net": 0.53429, "eta": "0:00:01", "loss": 0.34661, "lr": 0.00100, "mode": "train"}
[12/04 15:29:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.29421, "dt_data": 0.75971, "dt_net": 0.53450, "eta": "0:00:01", "loss": 0.35164, "lr": 0.00100, "mode": "train"}
[12/04 15:29:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.29642, "dt_data": 0.76268, "dt_net": 0.53374, "eta": "0:00:01", "loss": 0.37447, "lr": 0.00100, "mode": "train"}
[12/04 15:29:16][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.84705, "dt_data": 0.77385, "dt_net": 0.07319, "eta": "0:00:00", "mode": "val"}
[12/04 15:29:16][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 15:29:16][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 15:29:16][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 15:29:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:29:16][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 15:29:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 15:29:16][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 15:29:16][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002760 seconds.
[12/04 15:29:16][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.57879, "mode": "val"}
[12/04 18:25:41][INFO] train_net.py: 377: Train with config:
[12/04 18:25:41][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 18:25:43][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 18:25:43][INFO] misc.py: 170: Params: 33,653,708
[12/04 18:25:43][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 18:25:43][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 18:25:43][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 18:25:44][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 18:25:44][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 18:25:44][INFO] misc.py: 182: nvidia-smi
[12/04 18:25:44][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 18:25:44][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 18:25:44][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 18:25:44][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 18:25:44][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 18:25:44][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 18:25:44][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 18:25:44][INFO] ava_dataset.py:  89: Split: train
[12/04 18:25:44][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 18:25:44][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 18:25:44][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 18:25:44][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 18:25:44][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 18:25:44][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 18:25:44][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 18:25:44][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 18:25:44][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 18:25:44][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 18:25:44][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 18:25:44][INFO] ava_dataset.py:  89: Split: val
[12/04 18:25:44][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 18:25:44][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 18:25:44][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 18:25:44][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 18:25:44][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 18:25:44][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 18:25:44][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 18:25:44][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 18:25:44][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 18:25:44][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 18:25:44][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 18:25:44][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 18:25:44][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 18:25:44][INFO] train_net.py: 417: Start epoch: 1
[12/04 18:25:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.34353, "dt_data": 0.78817, "dt_net": 0.55536, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 18:25:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.28821, "dt_data": 0.75584, "dt_net": 0.53237, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 18:25:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.29195, "dt_data": 0.75861, "dt_net": 0.53334, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 18:25:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.28643, "dt_data": 0.75340, "dt_net": 0.53303, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/04 18:25:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.28622, "dt_data": 0.75353, "dt_net": 0.53269, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/04 18:25:53][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.84459, "dt_data": 0.77149, "dt_net": 0.07310, "eta": "0:00:00", "mode": "val"}
[12/04 18:25:53][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:25:53][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:25:53][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:25:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:25:53][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:25:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:25:53][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:25:53][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003427 seconds.
[12/04 18:25:53][INFO] logging.py:  96: json_stats: {"RAM": "2.41/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/04 18:25:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.28903, "dt_data": 0.75621, "dt_net": 0.53282, "eta": "0:00:01", "loss": 0.92416, "lr": 0.10000, "mode": "train"}
[12/04 18:25:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.29064, "dt_data": 0.75765, "dt_net": 0.53299, "eta": "0:00:01", "loss": 0.72452, "lr": 0.10000, "mode": "train"}
[12/04 18:25:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.29069, "dt_data": 0.75761, "dt_net": 0.53307, "eta": "0:00:01", "loss": 0.68952, "lr": 0.10000, "mode": "train"}
[12/04 18:25:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.28941, "dt_data": 0.75685, "dt_net": 0.53255, "eta": "0:00:01", "loss": 0.47064, "lr": 0.10000, "mode": "train"}
[12/04 18:26:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.29170, "dt_data": 0.75816, "dt_net": 0.53354, "eta": "0:00:01", "loss": 0.67673, "lr": 0.10000, "mode": "train"}
[12/04 18:26:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.85023, "dt_data": 0.77682, "dt_net": 0.07341, "eta": "0:00:00", "mode": "val"}
[12/04 18:26:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:26:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:26:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:26:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:26:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:26:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:26:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:26:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003001 seconds.
[12/04 18:26:01][INFO] logging.py:  96: json_stats: {"RAM": "2.41/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.78117, "mode": "val"}
[12/04 18:26:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.29251, "dt_data": 0.75927, "dt_net": 0.53324, "eta": "0:00:01", "loss": 0.89720, "lr": 0.01000, "mode": "train"}
[12/04 18:26:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.29084, "dt_data": 0.75799, "dt_net": 0.53285, "eta": "0:00:01", "loss": 0.70818, "lr": 0.01000, "mode": "train"}
[12/04 18:26:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.28962, "dt_data": 0.75707, "dt_net": 0.53255, "eta": "0:00:01", "loss": 0.40234, "lr": 0.01000, "mode": "train"}
[12/04 18:26:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.29143, "dt_data": 0.75833, "dt_net": 0.53310, "eta": "0:00:01", "loss": 0.31428, "lr": 0.01000, "mode": "train"}
[12/04 18:26:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.28998, "dt_data": 0.75750, "dt_net": 0.53248, "eta": "0:00:01", "loss": 0.27893, "lr": 0.01000, "mode": "train"}
[12/04 18:26:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.85116, "dt_data": 0.77783, "dt_net": 0.07332, "eta": "0:00:00", "mode": "val"}
[12/04 18:26:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:26:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:26:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:26:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:26:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:26:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:26:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:26:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003084 seconds.
[12/04 18:26:10][INFO] logging.py:  96: json_stats: {"RAM": "2.41/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.78206, "mode": "val"}
[12/04 18:26:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.28889, "dt_data": 0.75607, "dt_net": 0.53282, "eta": "0:00:01", "loss": 0.32630, "lr": 0.00100, "mode": "train"}
[12/04 18:26:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.29098, "dt_data": 0.75837, "dt_net": 0.53260, "eta": "0:00:01", "loss": 0.31953, "lr": 0.00100, "mode": "train"}
[12/04 18:26:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.29444, "dt_data": 0.76106, "dt_net": 0.53338, "eta": "0:00:01", "loss": 0.31874, "lr": 0.00100, "mode": "train"}
[12/04 18:26:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.28959, "dt_data": 0.75595, "dt_net": 0.53364, "eta": "0:00:01", "loss": 0.31272, "lr": 0.00100, "mode": "train"}
[12/04 18:26:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.29553, "dt_data": 0.76138, "dt_net": 0.53414, "eta": "0:00:01", "loss": 0.32191, "lr": 0.00100, "mode": "train"}
[12/04 18:26:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.84762, "dt_data": 0.77407, "dt_net": 0.07354, "eta": "0:00:00", "mode": "val"}
[12/04 18:26:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:26:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:26:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:26:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:26:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:26:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:26:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:26:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003008 seconds.
[12/04 18:26:18][INFO] logging.py:  96: json_stats: {"RAM": "2.41/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.63166, "mode": "val"}
[12/04 18:31:41][INFO] train_net.py: 377: Train with config:
[12/04 18:31:41][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 18:31:42][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 18:31:42][INFO] misc.py: 170: Params: 33,653,708
[12/04 18:31:42][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 18:31:43][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 18:31:43][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 18:31:43][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 18:31:43][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 18:31:43][INFO] misc.py: 182: nvidia-smi
[12/04 18:31:43][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 18:31:43][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 18:31:43][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 18:31:43][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 18:31:43][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 18:31:43][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 18:31:43][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 18:31:43][INFO] ava_dataset.py:  89: Split: train
[12/04 18:31:43][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 18:31:43][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 18:31:43][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 18:31:43][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 18:31:43][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 18:31:43][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 18:31:43][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 18:31:43][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 18:31:43][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 18:31:43][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 18:31:43][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 18:31:43][INFO] ava_dataset.py:  89: Split: val
[12/04 18:31:43][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 18:31:43][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 18:31:43][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 18:31:43][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 18:31:43][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 18:31:43][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 18:31:43][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 18:31:43][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 18:31:43][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 18:31:43][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 18:31:43][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 18:31:44][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 18:31:44][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 18:31:44][INFO] train_net.py: 417: Start epoch: 1
[12/04 18:31:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.33227, "dt_data": 0.79200, "dt_net": 0.54027, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 18:31:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.28940, "dt_data": 0.75586, "dt_net": 0.53353, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 18:31:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.29135, "dt_data": 0.75658, "dt_net": 0.53476, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 18:31:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.29150, "dt_data": 0.75727, "dt_net": 0.53423, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/04 18:31:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.29207, "dt_data": 0.75822, "dt_net": 0.53384, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/04 18:31:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.84940, "dt_data": 0.77607, "dt_net": 0.07332, "eta": "0:00:00", "mode": "val"}
[12/04 18:31:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:31:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:31:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:31:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:31:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:31:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:31:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:31:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003469 seconds.
[12/04 18:31:52][INFO] logging.py:  96: json_stats: {"RAM": "2.41/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/04 18:31:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.29013, "dt_data": 0.75605, "dt_net": 0.53407, "eta": "0:00:01", "loss": 0.92417, "lr": 0.10000, "mode": "train"}
[12/04 18:31:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.29200, "dt_data": 0.75742, "dt_net": 0.53460, "eta": "0:00:01", "loss": 0.73744, "lr": 0.10000, "mode": "train"}
[12/04 18:31:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.29757, "dt_data": 0.76375, "dt_net": 0.53382, "eta": "0:00:01", "loss": 0.63266, "lr": 0.10000, "mode": "train"}
[12/04 18:31:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.29325, "dt_data": 0.75932, "dt_net": 0.53393, "eta": "0:00:01", "loss": 0.50696, "lr": 0.10000, "mode": "train"}
[12/04 18:31:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.29657, "dt_data": 0.76220, "dt_net": 0.53436, "eta": "0:00:01", "loss": 0.78945, "lr": 0.10000, "mode": "train"}
[12/04 18:32:00][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.84849, "dt_data": 0.77526, "dt_net": 0.07322, "eta": "0:00:00", "mode": "val"}
[12/04 18:32:00][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:32:00][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:32:00][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:32:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:32:00][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:32:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:32:00][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:32:00][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003077 seconds.
[12/04 18:32:00][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.80804, "mode": "val"}
[12/04 18:32:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.29334, "dt_data": 0.75883, "dt_net": 0.53451, "eta": "0:00:01", "loss": 0.86170, "lr": 0.01000, "mode": "train"}
[12/04 18:32:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.29508, "dt_data": 0.76121, "dt_net": 0.53387, "eta": "0:00:01", "loss": 0.69041, "lr": 0.01000, "mode": "train"}
[12/04 18:32:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.29628, "dt_data": 0.76256, "dt_net": 0.53371, "eta": "0:00:01", "loss": 0.32924, "lr": 0.01000, "mode": "train"}
[12/04 18:32:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.29387, "dt_data": 0.75985, "dt_net": 0.53401, "eta": "0:00:01", "loss": 0.30869, "lr": 0.01000, "mode": "train"}
[12/04 18:32:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.29699, "dt_data": 0.76358, "dt_net": 0.53341, "eta": "0:00:01", "loss": 0.27876, "lr": 0.01000, "mode": "train"}
[12/04 18:32:09][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.85291, "dt_data": 0.77968, "dt_net": 0.07323, "eta": "0:00:00", "mode": "val"}
[12/04 18:32:09][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:32:09][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:32:09][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:32:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:32:09][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:32:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:32:09][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:32:09][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002956 seconds.
[12/04 18:32:09][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.55487, "mode": "val"}
[12/04 18:32:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.29207, "dt_data": 0.75796, "dt_net": 0.53411, "eta": "0:00:01", "loss": 0.31799, "lr": 0.00100, "mode": "train"}
[12/04 18:32:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.29366, "dt_data": 0.75955, "dt_net": 0.53410, "eta": "0:00:01", "loss": 0.36731, "lr": 0.00100, "mode": "train"}
[12/04 18:32:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.29542, "dt_data": 0.76160, "dt_net": 0.53382, "eta": "0:00:01", "loss": 0.33153, "lr": 0.00100, "mode": "train"}
[12/04 18:32:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.31156, "dt_data": 0.77776, "dt_net": 0.53380, "eta": "0:00:01", "loss": 0.31043, "lr": 0.00100, "mode": "train"}
[12/04 18:32:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.29326, "dt_data": 0.75941, "dt_net": 0.53385, "eta": "0:00:01", "loss": 0.33070, "lr": 0.00100, "mode": "train"}
[12/04 18:32:17][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.85442, "dt_data": 0.78122, "dt_net": 0.07320, "eta": "0:00:00", "mode": "val"}
[12/04 18:32:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 18:32:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 18:32:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 18:32:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:32:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 18:32:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 18:32:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 18:32:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003152 seconds.
[12/04 18:32:18][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 19:50:53][INFO] train_net.py: 377: Train with config:
[12/04 19:50:53][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 19:50:55][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 19:50:55][INFO] misc.py: 170: Params: 33,653,708
[12/04 19:50:55][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 19:50:55][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 19:50:55][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 19:50:55][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 19:50:55][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 19:50:55][INFO] misc.py: 182: nvidia-smi
[12/04 19:50:55][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 19:50:55][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 19:50:55][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 19:50:55][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 19:50:55][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 19:50:55][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 19:50:55][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 19:50:55][INFO] ava_dataset.py:  89: Split: train
[12/04 19:50:55][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 19:50:55][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 19:50:55][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 19:50:55][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 19:50:55][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 19:50:55][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 19:50:55][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 19:50:55][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 19:50:55][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 19:50:55][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 19:50:55][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 19:50:55][INFO] ava_dataset.py:  89: Split: val
[12/04 19:50:55][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 19:50:55][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 19:50:55][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 19:50:55][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 19:50:55][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 19:50:55][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 19:50:55][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 19:50:55][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 19:50:55][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 19:50:55][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 19:50:55][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 19:50:56][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 19:50:56][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 19:50:56][INFO] train_net.py: 417: Start epoch: 1
[12/04 19:50:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.32184, "dt_data": 0.79472, "dt_net": 0.52711, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 19:50:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.28658, "dt_data": 0.75467, "dt_net": 0.53191, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 19:51:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.29318, "dt_data": 0.75952, "dt_net": 0.53366, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 19:51:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.29562, "dt_data": 0.76275, "dt_net": 0.53287, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/04 19:51:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.29161, "dt_data": 0.75804, "dt_net": 0.53357, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/04 19:51:04][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.85544, "dt_data": 0.78216, "dt_net": 0.07327, "eta": "0:00:00", "mode": "val"}
[12/04 19:51:04][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 19:51:04][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 19:51:04][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 19:51:04][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:04][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 19:51:04][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:04][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 19:51:04][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003520 seconds.
[12/04 19:51:04][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/04 19:51:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.29578, "dt_data": 0.76122, "dt_net": 0.53455, "eta": "0:00:01", "loss": 0.92414, "lr": 0.10000, "mode": "train"}
[12/04 19:51:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.30865, "dt_data": 0.77420, "dt_net": 0.53445, "eta": "0:00:01", "loss": 0.72937, "lr": 0.10000, "mode": "train"}
[12/04 19:51:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.29821, "dt_data": 0.76405, "dt_net": 0.53416, "eta": "0:00:01", "loss": 0.70035, "lr": 0.10000, "mode": "train"}
[12/04 19:51:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.29810, "dt_data": 0.76327, "dt_net": 0.53483, "eta": "0:00:01", "loss": 0.48223, "lr": 0.10000, "mode": "train"}
[12/04 19:51:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.29906, "dt_data": 0.76419, "dt_net": 0.53487, "eta": "0:00:01", "loss": 0.74443, "lr": 0.10000, "mode": "train"}
[12/04 19:51:13][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.84739, "dt_data": 0.77409, "dt_net": 0.07329, "eta": "0:00:00", "mode": "val"}
[12/04 19:51:13][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 19:51:13][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 19:51:13][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 19:51:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:13][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 19:51:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:13][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 19:51:13][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003068 seconds.
[12/04 19:51:13][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.74643, "mode": "val"}
[12/04 19:51:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.29603, "dt_data": 0.76180, "dt_net": 0.53423, "eta": "0:00:01", "loss": 1.18148, "lr": 0.01000, "mode": "train"}
[12/04 19:51:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.29380, "dt_data": 0.75968, "dt_net": 0.53412, "eta": "0:00:01", "loss": 0.76772, "lr": 0.01000, "mode": "train"}
[12/04 19:51:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.29566, "dt_data": 0.76112, "dt_net": 0.53453, "eta": "0:00:01", "loss": 0.38416, "lr": 0.01000, "mode": "train"}
[12/04 19:51:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.29469, "dt_data": 0.76077, "dt_net": 0.53392, "eta": "0:00:01", "loss": 0.30236, "lr": 0.01000, "mode": "train"}
[12/04 19:51:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.29675, "dt_data": 0.76246, "dt_net": 0.53429, "eta": "0:00:01", "loss": 0.28572, "lr": 0.01000, "mode": "train"}
[12/04 19:51:21][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.85355, "dt_data": 0.78030, "dt_net": 0.07325, "eta": "0:00:00", "mode": "val"}
[12/04 19:51:21][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 19:51:21][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 19:51:21][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 19:51:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:21][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 19:51:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:21][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 19:51:21][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002998 seconds.
[12/04 19:51:21][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.60101, "mode": "val"}
[12/04 19:51:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.29751, "dt_data": 0.76259, "dt_net": 0.53492, "eta": "0:00:01", "loss": 0.36981, "lr": 0.00100, "mode": "train"}
[12/04 19:51:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.29300, "dt_data": 0.75850, "dt_net": 0.53450, "eta": "0:00:01", "loss": 0.34090, "lr": 0.00100, "mode": "train"}
[12/04 19:51:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.29415, "dt_data": 0.75994, "dt_net": 0.53421, "eta": "0:00:01", "loss": 0.34770, "lr": 0.00100, "mode": "train"}
[12/04 19:51:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.29559, "dt_data": 0.76121, "dt_net": 0.53438, "eta": "0:00:01", "loss": 0.33461, "lr": 0.00100, "mode": "train"}
[12/04 19:51:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.29374, "dt_data": 0.75902, "dt_net": 0.53472, "eta": "0:00:01", "loss": 0.33509, "lr": 0.00100, "mode": "train"}
[12/04 19:51:30][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.84953, "dt_data": 0.77621, "dt_net": 0.07332, "eta": "0:00:00", "mode": "val"}
[12/04 19:51:30][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 19:51:30][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 19:51:30][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 19:51:30][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:30][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 19:51:30][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 19:51:30][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 19:51:30][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003031 seconds.
[12/04 19:51:30][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:03:12][INFO] train_net.py: 377: Train with config:
[12/04 20:03:12][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 20:03:14][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 20:03:14][INFO] misc.py: 170: Params: 33,653,708
[12/04 20:03:14][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 20:03:14][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 20:03:14][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 20:03:14][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 20:03:14][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 20:03:14][INFO] misc.py: 182: nvidia-smi
[12/04 20:03:14][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 20:03:14][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 20:03:14][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 20:03:14][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 20:03:14][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 20:03:14][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 20:03:14][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 20:03:14][INFO] ava_dataset.py:  89: Split: train
[12/04 20:03:14][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 20:03:14][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 20:03:14][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 20:03:14][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 20:03:14][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 20:03:14][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 20:03:14][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 20:03:14][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 20:03:14][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 20:03:14][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 20:03:14][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 20:03:14][INFO] ava_dataset.py:  89: Split: val
[12/04 20:03:14][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 20:03:14][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 20:03:14][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 20:03:14][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 20:03:14][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 20:03:14][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 20:03:15][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 20:03:15][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 20:03:15][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 20:03:15][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 20:03:15][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 20:03:15][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 20:03:15][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 20:03:15][INFO] train_net.py: 417: Start epoch: 1
[12/04 20:03:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.32674, "dt_data": 0.79883, "dt_net": 0.52791, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 20:03:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.28437, "dt_data": 0.75059, "dt_net": 0.53377, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 20:03:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.28857, "dt_data": 0.75429, "dt_net": 0.53428, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 20:03:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.28898, "dt_data": 0.75458, "dt_net": 0.53439, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/04 20:03:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.28725, "dt_data": 0.75288, "dt_net": 0.53436, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/04 20:03:24][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.83159, "dt_data": 0.75806, "dt_net": 0.07352, "eta": "0:00:00", "mode": "val"}
[12/04 20:03:24][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:03:24][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:03:24][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:03:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:24][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:03:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:24][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:03:24][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003362 seconds.
[12/04 20:03:24][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/04 20:03:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.28771, "dt_data": 0.75309, "dt_net": 0.53462, "eta": "0:00:01", "loss": 0.92420, "lr": 0.10000, "mode": "train"}
[12/04 20:03:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.29161, "dt_data": 0.75760, "dt_net": 0.53401, "eta": "0:00:01", "loss": 0.72748, "lr": 0.10000, "mode": "train"}
[12/04 20:03:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.29201, "dt_data": 0.75732, "dt_net": 0.53469, "eta": "0:00:01", "loss": 0.70057, "lr": 0.10000, "mode": "train"}
[12/04 20:03:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.29007, "dt_data": 0.75598, "dt_net": 0.53409, "eta": "0:00:01", "loss": 0.47756, "lr": 0.10000, "mode": "train"}
[12/04 20:03:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.29170, "dt_data": 0.75740, "dt_net": 0.53430, "eta": "0:00:01", "loss": 0.78265, "lr": 0.10000, "mode": "train"}
[12/04 20:03:32][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.84789, "dt_data": 0.77451, "dt_net": 0.07337, "eta": "0:00:00", "mode": "val"}
[12/04 20:03:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:03:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:03:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:03:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:03:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:03:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002978 seconds.
[12/04 20:03:32][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.80645, "mode": "val"}
[12/04 20:03:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.28731, "dt_data": 0.75313, "dt_net": 0.53418, "eta": "0:00:01", "loss": 1.00651, "lr": 0.01000, "mode": "train"}
[12/04 20:03:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.29056, "dt_data": 0.75595, "dt_net": 0.53461, "eta": "0:00:01", "loss": 0.77392, "lr": 0.01000, "mode": "train"}
[12/04 20:03:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.29164, "dt_data": 0.75753, "dt_net": 0.53411, "eta": "0:00:01", "loss": 0.42811, "lr": 0.01000, "mode": "train"}
[12/04 20:03:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.28801, "dt_data": 0.75384, "dt_net": 0.53417, "eta": "0:00:01", "loss": 0.30435, "lr": 0.01000, "mode": "train"}
[12/04 20:03:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.28827, "dt_data": 0.75383, "dt_net": 0.53443, "eta": "0:00:01", "loss": 0.28107, "lr": 0.01000, "mode": "train"}
[12/04 20:03:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.83867, "dt_data": 0.76539, "dt_net": 0.07328, "eta": "0:00:00", "mode": "val"}
[12/04 20:03:41][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:03:41][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:03:41][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:03:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:41][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:03:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:41][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:03:41][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002999 seconds.
[12/04 20:03:41][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.57462, "mode": "val"}
[12/04 20:03:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.28652, "dt_data": 0.75136, "dt_net": 0.53516, "eta": "0:00:01", "loss": 0.31413, "lr": 0.00100, "mode": "train"}
[12/04 20:03:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.28690, "dt_data": 0.75274, "dt_net": 0.53416, "eta": "0:00:01", "loss": 0.30442, "lr": 0.00100, "mode": "train"}
[12/04 20:03:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.28763, "dt_data": 0.75274, "dt_net": 0.53489, "eta": "0:00:01", "loss": 0.29698, "lr": 0.00100, "mode": "train"}
[12/04 20:03:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.29032, "dt_data": 0.75548, "dt_net": 0.53483, "eta": "0:00:01", "loss": 0.29428, "lr": 0.00100, "mode": "train"}
[12/04 20:03:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.29215, "dt_data": 0.75800, "dt_net": 0.53416, "eta": "0:00:01", "loss": 0.31754, "lr": 0.00100, "mode": "train"}
[12/04 20:03:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.84695, "dt_data": 0.77354, "dt_net": 0.07341, "eta": "0:00:00", "mode": "val"}
[12/04 20:03:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:03:49][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:03:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:03:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:03:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:03:49][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:03:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003006 seconds.
[12/04 20:03:49][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.64643, "mode": "val"}
[12/04 20:11:30][INFO] train_net.py: 377: Train with config:
[12/04 20:11:30][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 20:11:32][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 20:11:32][INFO] misc.py: 170: Params: 33,653,708
[12/04 20:11:32][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 20:11:32][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 20:11:32][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 20:11:32][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 20:11:32][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 20:11:32][INFO] misc.py: 182: nvidia-smi
[12/04 20:11:32][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 20:11:32][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 20:11:32][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 20:11:32][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 20:11:32][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 20:11:32][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 20:11:32][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 20:11:32][INFO] ava_dataset.py:  89: Split: train
[12/04 20:11:32][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 20:11:32][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 20:11:32][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 20:11:32][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 20:11:32][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 20:11:32][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 20:11:32][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 20:11:32][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 20:11:32][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 20:11:32][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 20:11:32][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 20:11:32][INFO] ava_dataset.py:  89: Split: val
[12/04 20:11:32][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 20:11:32][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 20:11:32][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 20:11:32][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 20:11:32][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 20:11:32][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 20:11:33][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 20:11:33][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 20:11:33][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 20:11:33][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 20:11:33][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 20:11:33][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 20:11:33][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 20:11:33][INFO] train_net.py: 417: Start epoch: 1
[12/04 20:11:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.33287, "dt_data": 0.78980, "dt_net": 0.54306, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 20:11:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.29132, "dt_data": 0.75822, "dt_net": 0.53310, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 20:11:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.28862, "dt_data": 0.75425, "dt_net": 0.53438, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 20:11:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.28541, "dt_data": 0.75070, "dt_net": 0.53471, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/04 20:11:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.28763, "dt_data": 0.75297, "dt_net": 0.53466, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/04 20:11:42][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.84802, "dt_data": 0.77469, "dt_net": 0.07332, "eta": "0:00:00", "mode": "val"}
[12/04 20:11:42][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:11:42][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:11:42][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:11:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:11:42][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:11:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:11:42][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:11:42][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003355 seconds.
[12/04 20:11:42][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/04 20:11:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.29024, "dt_data": 0.75590, "dt_net": 0.53433, "eta": "0:00:01", "loss": 0.92385, "lr": 0.10000, "mode": "train"}
[12/04 20:11:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.29433, "dt_data": 0.76036, "dt_net": 0.53396, "eta": "0:00:01", "loss": 0.72715, "lr": 0.10000, "mode": "train"}
[12/04 20:11:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.29139, "dt_data": 0.75702, "dt_net": 0.53436, "eta": "0:00:01", "loss": 0.66463, "lr": 0.10000, "mode": "train"}
[12/04 20:11:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.29314, "dt_data": 0.75882, "dt_net": 0.53432, "eta": "0:00:01", "loss": 0.44415, "lr": 0.10000, "mode": "train"}
[12/04 20:11:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.29153, "dt_data": 0.75715, "dt_net": 0.53438, "eta": "0:00:01", "loss": 0.64528, "lr": 0.10000, "mode": "train"}
[12/04 20:11:50][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.83801, "dt_data": 0.76428, "dt_net": 0.07372, "eta": "0:00:00", "mode": "val"}
[12/04 20:11:50][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:11:50][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:11:50][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:11:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:11:50][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:11:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:11:50][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:11:50][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002909 seconds.
[12/04 20:11:50][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.76091, "mode": "val"}
[12/04 20:11:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.29358, "dt_data": 0.75871, "dt_net": 0.53487, "eta": "0:00:01", "loss": 2.56831, "lr": 0.01000, "mode": "train"}
[12/04 20:11:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.29118, "dt_data": 0.75637, "dt_net": 0.53480, "eta": "0:00:01", "loss": 0.92838, "lr": 0.01000, "mode": "train"}
[12/04 20:11:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.29166, "dt_data": 0.75720, "dt_net": 0.53446, "eta": "0:00:01", "loss": 0.48187, "lr": 0.01000, "mode": "train"}
[12/04 20:11:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.29108, "dt_data": 0.75623, "dt_net": 0.53485, "eta": "0:00:01", "loss": 0.36106, "lr": 0.01000, "mode": "train"}
[12/04 20:11:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.29134, "dt_data": 0.75672, "dt_net": 0.53462, "eta": "0:00:01", "loss": 0.28588, "lr": 0.01000, "mode": "train"}
[12/04 20:11:59][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.84706, "dt_data": 0.77347, "dt_net": 0.07359, "eta": "0:00:00", "mode": "val"}
[12/04 20:11:59][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:11:59][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:11:59][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:11:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:11:59][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:11:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:11:59][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:11:59][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003130 seconds.
[12/04 20:11:59][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.56748, "mode": "val"}
[12/04 20:12:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.29257, "dt_data": 0.75790, "dt_net": 0.53467, "eta": "0:00:01", "loss": 0.32264, "lr": 0.00100, "mode": "train"}
[12/04 20:12:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.28936, "dt_data": 0.75523, "dt_net": 0.53413, "eta": "0:00:01", "loss": 0.30970, "lr": 0.00100, "mode": "train"}
[12/04 20:12:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.29140, "dt_data": 0.75661, "dt_net": 0.53478, "eta": "0:00:01", "loss": 0.30684, "lr": 0.00100, "mode": "train"}
[12/04 20:12:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.28923, "dt_data": 0.75515, "dt_net": 0.53408, "eta": "0:00:01", "loss": 0.29889, "lr": 0.00100, "mode": "train"}
[12/04 20:12:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.29468, "dt_data": 0.75932, "dt_net": 0.53535, "eta": "0:00:01", "loss": 0.31902, "lr": 0.00100, "mode": "train"}
[12/04 20:12:07][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.84933, "dt_data": 0.77543, "dt_net": 0.07390, "eta": "0:00:00", "mode": "val"}
[12/04 20:12:07][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:12:07][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:12:07][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:12:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:07][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:12:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:07][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:12:07][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003091 seconds.
[12/04 20:12:07][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:12:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "21", "cur_iter": "1", "dt": 1.29243, "dt_data": 0.75755, "dt_net": 0.53488, "eta": "0:00:01", "loss": 0.29197, "lr": 0.00010, "mode": "train"}
[12/04 20:12:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "22", "cur_iter": "1", "dt": 1.29143, "dt_data": 0.75560, "dt_net": 0.53582, "eta": "0:00:01", "loss": 0.31334, "lr": 0.00010, "mode": "train"}
[12/04 20:12:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "23", "cur_iter": "1", "dt": 1.28982, "dt_data": 0.75527, "dt_net": 0.53455, "eta": "0:00:01", "loss": 0.31208, "lr": 0.00010, "mode": "train"}
[12/04 20:12:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "24", "cur_iter": "1", "dt": 1.29111, "dt_data": 0.75534, "dt_net": 0.53576, "eta": "0:00:01", "loss": 0.30315, "lr": 0.00010, "mode": "train"}
[12/04 20:12:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 1.29324, "dt_data": 0.75630, "dt_net": 0.53694, "eta": "0:00:01", "loss": 0.29508, "lr": 0.00010, "mode": "train"}
[12/04 20:12:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 0.83797, "dt_data": 0.76413, "dt_net": 0.07384, "eta": "0:00:00", "mode": "val"}
[12/04 20:12:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:12:15][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:12:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:12:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:12:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:15][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:12:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003175 seconds.
[12/04 20:12:15][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "25", "gpu_mem": "1.74G", "map": 0.58263, "mode": "val"}
[12/04 20:12:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "26", "cur_iter": "1", "dt": 1.29618, "dt_data": 0.75983, "dt_net": 0.53635, "eta": "0:00:01", "loss": 0.29320, "lr": 0.00010, "mode": "train"}
[12/04 20:12:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "27", "cur_iter": "1", "dt": 1.29504, "dt_data": 0.75806, "dt_net": 0.53698, "eta": "0:00:01", "loss": 0.29566, "lr": 0.00010, "mode": "train"}
[12/04 20:12:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "28", "cur_iter": "1", "dt": 1.29164, "dt_data": 0.75541, "dt_net": 0.53622, "eta": "0:00:01", "loss": 0.29839, "lr": 0.00010, "mode": "train"}
[12/04 20:12:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "29", "cur_iter": "1", "dt": 1.29308, "dt_data": 0.75686, "dt_net": 0.53621, "eta": "0:00:01", "loss": 0.30141, "lr": 0.00010, "mode": "train"}
[12/04 20:12:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.29274, "dt_data": 0.75594, "dt_net": 0.53680, "eta": "0:00:01", "loss": 0.28582, "lr": 0.00010, "mode": "train"}
[12/04 20:12:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 0.83202, "dt_data": 0.75841, "dt_net": 0.07361, "eta": "0:00:00", "mode": "val"}
[12/04 20:12:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:12:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:12:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:12:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:12:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:12:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003128 seconds.
[12/04 20:12:23][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "30", "gpu_mem": "1.74G", "map": 0.65379, "mode": "val"}
[12/04 20:12:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "31", "cur_iter": "1", "dt": 1.29431, "dt_data": 0.75801, "dt_net": 0.53630, "eta": "0:00:01", "loss": 0.28436, "lr": 0.00010, "mode": "train"}
[12/04 20:12:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "32", "cur_iter": "1", "dt": 1.29285, "dt_data": 0.75599, "dt_net": 0.53686, "eta": "0:00:01", "loss": 0.29672, "lr": 0.00010, "mode": "train"}
[12/04 20:12:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "33", "cur_iter": "1", "dt": 1.29493, "dt_data": 0.75833, "dt_net": 0.53659, "eta": "0:00:01", "loss": 0.30350, "lr": 0.00010, "mode": "train"}
[12/04 20:12:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "34", "cur_iter": "1", "dt": 1.29311, "dt_data": 0.75670, "dt_net": 0.53641, "eta": "0:00:01", "loss": 0.29135, "lr": 0.00010, "mode": "train"}
[12/04 20:12:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 1.29419, "dt_data": 0.75734, "dt_net": 0.53684, "eta": "0:00:01", "loss": 0.29381, "lr": 0.00010, "mode": "train"}
[12/04 20:12:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 0.83645, "dt_data": 0.76291, "dt_net": 0.07354, "eta": "0:00:00", "mode": "val"}
[12/04 20:12:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:12:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:12:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:12:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:12:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:12:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003035 seconds.
[12/04 20:12:31][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "35", "gpu_mem": "1.74G", "map": 0.66180, "mode": "val"}
[12/04 20:12:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "36", "cur_iter": "1", "dt": 1.29336, "dt_data": 0.75686, "dt_net": 0.53650, "eta": "0:00:01", "loss": 0.27978, "lr": 0.00010, "mode": "train"}
[12/04 20:12:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "37", "cur_iter": "1", "dt": 1.29342, "dt_data": 0.75670, "dt_net": 0.53672, "eta": "0:00:01", "loss": 0.32593, "lr": 0.00010, "mode": "train"}
[12/04 20:12:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "38", "cur_iter": "1", "dt": 1.29309, "dt_data": 0.75644, "dt_net": 0.53664, "eta": "0:00:01", "loss": 0.32842, "lr": 0.00010, "mode": "train"}
[12/04 20:12:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "39", "cur_iter": "1", "dt": 1.29211, "dt_data": 0.75599, "dt_net": 0.53612, "eta": "0:00:01", "loss": 0.29346, "lr": 0.00010, "mode": "train"}
[12/04 20:12:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 1.29501, "dt_data": 0.75825, "dt_net": 0.53676, "eta": "0:00:01", "loss": 0.29220, "lr": 0.00010, "mode": "train"}
[12/04 20:12:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 0.83009, "dt_data": 0.75644, "dt_net": 0.07366, "eta": "0:00:00", "mode": "val"}
[12/04 20:12:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:12:39][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:12:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:12:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:12:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:39][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:12:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003160 seconds.
[12/04 20:12:39][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "40", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:12:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "41", "cur_iter": "1", "dt": 1.29002, "dt_data": 0.75354, "dt_net": 0.53648, "eta": "0:00:01", "loss": 0.28672, "lr": 0.00010, "mode": "train"}
[12/04 20:12:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "42", "cur_iter": "1", "dt": 1.29358, "dt_data": 0.75720, "dt_net": 0.53638, "eta": "0:00:01", "loss": 0.30693, "lr": 0.00010, "mode": "train"}
[12/04 20:12:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "43", "cur_iter": "1", "dt": 1.29449, "dt_data": 0.75742, "dt_net": 0.53707, "eta": "0:00:01", "loss": 0.30361, "lr": 0.00010, "mode": "train"}
[12/04 20:12:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "44", "cur_iter": "1", "dt": 1.29305, "dt_data": 0.75618, "dt_net": 0.53687, "eta": "0:00:01", "loss": 0.31744, "lr": 0.00010, "mode": "train"}
[12/04 20:12:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 1.29502, "dt_data": 0.75826, "dt_net": 0.53676, "eta": "0:00:01", "loss": 0.29559, "lr": 0.00010, "mode": "train"}
[12/04 20:12:47][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 0.83949, "dt_data": 0.76573, "dt_net": 0.07375, "eta": "0:00:00", "mode": "val"}
[12/04 20:12:47][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:12:47][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:12:47][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:12:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:47][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:12:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:47][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:12:47][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003000 seconds.
[12/04 20:12:47][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "45", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:12:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "46", "cur_iter": "1", "dt": 1.29190, "dt_data": 0.75486, "dt_net": 0.53703, "eta": "0:00:01", "loss": 0.28596, "lr": 0.00010, "mode": "train"}
[12/04 20:12:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "47", "cur_iter": "1", "dt": 1.29245, "dt_data": 0.75531, "dt_net": 0.53714, "eta": "0:00:01", "loss": 0.30314, "lr": 0.00010, "mode": "train"}
[12/04 20:12:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "48", "cur_iter": "1", "dt": 1.29685, "dt_data": 0.75878, "dt_net": 0.53806, "eta": "0:00:01", "loss": 0.29982, "lr": 0.00010, "mode": "train"}
[12/04 20:12:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "49", "cur_iter": "1", "dt": 1.29243, "dt_data": 0.75501, "dt_net": 0.53742, "eta": "0:00:01", "loss": 0.29666, "lr": 0.00010, "mode": "train"}
[12/04 20:12:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 1.29618, "dt_data": 0.75878, "dt_net": 0.53739, "eta": "0:00:01", "loss": 0.28183, "lr": 0.00010, "mode": "train"}
[12/04 20:12:54][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 0.83686, "dt_data": 0.76266, "dt_net": 0.07421, "eta": "0:00:00", "mode": "val"}
[12/04 20:12:55][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:12:55][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:12:55][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:12:55][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:55][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:12:55][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:12:55][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:12:55][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003005 seconds.
[12/04 20:12:55][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "50", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:12:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "51", "cur_iter": "1", "dt": 1.29727, "dt_data": 0.75932, "dt_net": 0.53795, "eta": "0:00:01", "loss": 0.28728, "lr": 0.00010, "mode": "train"}
[12/04 20:12:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "52", "cur_iter": "1", "dt": 1.29422, "dt_data": 0.75693, "dt_net": 0.53729, "eta": "0:00:01", "loss": 0.29182, "lr": 0.00010, "mode": "train"}
[12/04 20:12:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "53", "cur_iter": "1", "dt": 1.29679, "dt_data": 0.75893, "dt_net": 0.53786, "eta": "0:00:01", "loss": 0.27932, "lr": 0.00010, "mode": "train"}
[12/04 20:13:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "54", "cur_iter": "1", "dt": 1.31080, "dt_data": 0.77285, "dt_net": 0.53795, "eta": "0:00:01", "loss": 0.29170, "lr": 0.00010, "mode": "train"}
[12/04 20:13:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 1.31188, "dt_data": 0.77439, "dt_net": 0.53748, "eta": "0:00:01", "loss": 0.28506, "lr": 0.00010, "mode": "train"}
[12/04 20:13:02][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 0.83835, "dt_data": 0.76426, "dt_net": 0.07409, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:02][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:02][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:02][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:02][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:02][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:02][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:02][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:03][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003152 seconds.
[12/04 20:13:03][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "55", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "56", "cur_iter": "1", "dt": 1.29479, "dt_data": 0.75687, "dt_net": 0.53791, "eta": "0:00:01", "loss": 0.28990, "lr": 0.00010, "mode": "train"}
[12/04 20:13:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "57", "cur_iter": "1", "dt": 1.29542, "dt_data": 0.75780, "dt_net": 0.53761, "eta": "0:00:01", "loss": 0.28039, "lr": 0.00010, "mode": "train"}
[12/04 20:13:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "58", "cur_iter": "1", "dt": 1.29534, "dt_data": 0.75727, "dt_net": 0.53806, "eta": "0:00:01", "loss": 0.28586, "lr": 0.00010, "mode": "train"}
[12/04 20:13:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "59", "cur_iter": "1", "dt": 1.29288, "dt_data": 0.75516, "dt_net": 0.53773, "eta": "0:00:01", "loss": 0.28507, "lr": 0.00010, "mode": "train"}
[12/04 20:13:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 1.29576, "dt_data": 0.75827, "dt_net": 0.53748, "eta": "0:00:01", "loss": 0.29277, "lr": 0.00010, "mode": "train"}
[12/04 20:13:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 0.83837, "dt_data": 0.76438, "dt_net": 0.07399, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003145 seconds.
[12/04 20:13:10][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "60", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "61", "cur_iter": "1", "dt": 1.29617, "dt_data": 0.75828, "dt_net": 0.53788, "eta": "0:00:01", "loss": 0.30388, "lr": 0.00010, "mode": "train"}
[12/04 20:13:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "62", "cur_iter": "1", "dt": 1.29360, "dt_data": 0.75586, "dt_net": 0.53774, "eta": "0:00:01", "loss": 0.31014, "lr": 0.00010, "mode": "train"}
[12/04 20:13:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "63", "cur_iter": "1", "dt": 1.29352, "dt_data": 0.75602, "dt_net": 0.53750, "eta": "0:00:01", "loss": 0.30266, "lr": 0.00010, "mode": "train"}
[12/04 20:13:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "64", "cur_iter": "1", "dt": 1.29471, "dt_data": 0.75664, "dt_net": 0.53807, "eta": "0:00:01", "loss": 0.29479, "lr": 0.00010, "mode": "train"}
[12/04 20:13:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 1.29383, "dt_data": 0.75652, "dt_net": 0.53731, "eta": "0:00:01", "loss": 0.31432, "lr": 0.00010, "mode": "train"}
[12/04 20:13:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 0.83323, "dt_data": 0.75927, "dt_net": 0.07396, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003088 seconds.
[12/04 20:13:18][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "65", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "66", "cur_iter": "1", "dt": 1.29756, "dt_data": 0.75943, "dt_net": 0.53813, "eta": "0:00:01", "loss": 0.29261, "lr": 0.00010, "mode": "train"}
[12/04 20:13:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "67", "cur_iter": "1", "dt": 1.29484, "dt_data": 0.75717, "dt_net": 0.53766, "eta": "0:00:01", "loss": 0.28008, "lr": 0.00010, "mode": "train"}
[12/04 20:13:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "68", "cur_iter": "1", "dt": 1.29572, "dt_data": 0.75798, "dt_net": 0.53774, "eta": "0:00:01", "loss": 0.29109, "lr": 0.00010, "mode": "train"}
[12/04 20:13:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "69", "cur_iter": "1", "dt": 1.29383, "dt_data": 0.75617, "dt_net": 0.53766, "eta": "0:00:01", "loss": 0.29427, "lr": 0.00010, "mode": "train"}
[12/04 20:13:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 1.29401, "dt_data": 0.75697, "dt_net": 0.53703, "eta": "0:00:01", "loss": 0.29719, "lr": 0.00010, "mode": "train"}
[12/04 20:13:26][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 0.83134, "dt_data": 0.75742, "dt_net": 0.07392, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:26][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:26][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:26][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:26][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:26][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:26][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003007 seconds.
[12/04 20:13:26][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "70", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "71", "cur_iter": "1", "dt": 1.29338, "dt_data": 0.75529, "dt_net": 0.53808, "eta": "0:00:01", "loss": 0.30954, "lr": 0.00010, "mode": "train"}
[12/04 20:13:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "72", "cur_iter": "1", "dt": 1.29526, "dt_data": 0.75607, "dt_net": 0.53918, "eta": "0:00:01", "loss": 0.27749, "lr": 0.00010, "mode": "train"}
[12/04 20:13:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "73", "cur_iter": "1", "dt": 1.29805, "dt_data": 0.75849, "dt_net": 0.53956, "eta": "0:00:01", "loss": 0.31064, "lr": 0.00010, "mode": "train"}
[12/04 20:13:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "74", "cur_iter": "1", "dt": 1.29777, "dt_data": 0.75736, "dt_net": 0.54040, "eta": "0:00:01", "loss": 0.28755, "lr": 0.00010, "mode": "train"}
[12/04 20:13:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 1.31542, "dt_data": 0.77502, "dt_net": 0.54039, "eta": "0:00:01", "loss": 0.28636, "lr": 0.00010, "mode": "train"}
[12/04 20:13:34][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 0.84194, "dt_data": 0.76765, "dt_net": 0.07428, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:34][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:34][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:34][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:34][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:34][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:34][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003119 seconds.
[12/04 20:13:34][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "75", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "76", "cur_iter": "1", "dt": 1.30003, "dt_data": 0.76004, "dt_net": 0.53998, "eta": "0:00:01", "loss": 0.29972, "lr": 0.00010, "mode": "train"}
[12/04 20:13:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "77", "cur_iter": "1", "dt": 1.29637, "dt_data": 0.75611, "dt_net": 0.54025, "eta": "0:00:01", "loss": 0.28272, "lr": 0.00010, "mode": "train"}
[12/04 20:13:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "78", "cur_iter": "1", "dt": 1.29770, "dt_data": 0.75760, "dt_net": 0.54009, "eta": "0:00:01", "loss": 0.31107, "lr": 0.00010, "mode": "train"}
[12/04 20:13:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "79", "cur_iter": "1", "dt": 1.29773, "dt_data": 0.75729, "dt_net": 0.54043, "eta": "0:00:01", "loss": 0.28967, "lr": 0.00010, "mode": "train"}
[12/04 20:13:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 1.29903, "dt_data": 0.75827, "dt_net": 0.54076, "eta": "0:00:01", "loss": 0.27801, "lr": 0.00010, "mode": "train"}
[12/04 20:13:42][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 0.84014, "dt_data": 0.76608, "dt_net": 0.07405, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:42][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:42][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:42][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:42][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:42][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:42][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003174 seconds.
[12/04 20:13:42][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "80", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "81", "cur_iter": "1", "dt": 1.29896, "dt_data": 0.75894, "dt_net": 0.54001, "eta": "0:00:01", "loss": 0.28502, "lr": 0.00010, "mode": "train"}
[12/04 20:13:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "82", "cur_iter": "1", "dt": 1.30266, "dt_data": 0.76235, "dt_net": 0.54031, "eta": "0:00:01", "loss": 0.28029, "lr": 0.00010, "mode": "train"}
[12/04 20:13:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "83", "cur_iter": "1", "dt": 1.29872, "dt_data": 0.75882, "dt_net": 0.53990, "eta": "0:00:01", "loss": 0.28402, "lr": 0.00010, "mode": "train"}
[12/04 20:13:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "84", "cur_iter": "1", "dt": 1.30944, "dt_data": 0.76950, "dt_net": 0.53994, "eta": "0:00:01", "loss": 0.28484, "lr": 0.00010, "mode": "train"}
[12/04 20:13:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 1.30839, "dt_data": 0.76778, "dt_net": 0.54061, "eta": "0:00:01", "loss": 0.28115, "lr": 0.00010, "mode": "train"}
[12/04 20:13:50][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 0.84000, "dt_data": 0.76578, "dt_net": 0.07422, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:50][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:50][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:50][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:50][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:50][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:50][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003014 seconds.
[12/04 20:13:50][INFO] logging.py:  96: json_stats: {"RAM": "2.59/15.59G", "_type": "val_epoch", "cur_epoch": "85", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "86", "cur_iter": "1", "dt": 1.29988, "dt_data": 0.75999, "dt_net": 0.53988, "eta": "0:00:01", "loss": 0.27090, "lr": 0.00010, "mode": "train"}
[12/04 20:13:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "87", "cur_iter": "1", "dt": 1.29935, "dt_data": 0.75917, "dt_net": 0.54018, "eta": "0:00:01", "loss": 0.28640, "lr": 0.00010, "mode": "train"}
[12/04 20:13:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "88", "cur_iter": "1", "dt": 1.29689, "dt_data": 0.75722, "dt_net": 0.53966, "eta": "0:00:01", "loss": 0.27889, "lr": 0.00010, "mode": "train"}
[12/04 20:13:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "89", "cur_iter": "1", "dt": 1.29649, "dt_data": 0.75641, "dt_net": 0.54007, "eta": "0:00:01", "loss": 0.27902, "lr": 0.00010, "mode": "train"}
[12/04 20:13:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 1.29806, "dt_data": 0.75810, "dt_net": 0.53996, "eta": "0:00:01", "loss": 0.29210, "lr": 0.00010, "mode": "train"}
[12/04 20:13:58][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 0.84241, "dt_data": 0.76817, "dt_net": 0.07423, "eta": "0:00:00", "mode": "val"}
[12/04 20:13:58][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:13:58][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:13:58][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:13:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:58][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:13:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:13:58][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:13:58][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003010 seconds.
[12/04 20:13:58][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "90", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:13:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "91", "cur_iter": "1", "dt": 1.30030, "dt_data": 0.76022, "dt_net": 0.54008, "eta": "0:00:01", "loss": 0.28634, "lr": 0.00010, "mode": "train"}
[12/04 20:14:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "92", "cur_iter": "1", "dt": 1.29871, "dt_data": 0.75865, "dt_net": 0.54006, "eta": "0:00:01", "loss": 0.28730, "lr": 0.00010, "mode": "train"}
[12/04 20:14:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "93", "cur_iter": "1", "dt": 1.29931, "dt_data": 0.75877, "dt_net": 0.54054, "eta": "0:00:01", "loss": 0.28756, "lr": 0.00010, "mode": "train"}
[12/04 20:14:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "94", "cur_iter": "1", "dt": 1.29535, "dt_data": 0.75558, "dt_net": 0.53978, "eta": "0:00:01", "loss": 0.28183, "lr": 0.00010, "mode": "train"}
[12/04 20:14:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 1.29839, "dt_data": 0.75809, "dt_net": 0.54030, "eta": "0:00:01", "loss": 0.28592, "lr": 0.00010, "mode": "train"}
[12/04 20:14:06][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 0.84884, "dt_data": 0.77481, "dt_net": 0.07403, "eta": "0:00:00", "mode": "val"}
[12/04 20:14:06][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:14:06][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:14:06][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:14:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:06][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:14:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:06][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:14:06][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003070 seconds.
[12/04 20:14:06][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "95", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:14:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "96", "cur_iter": "1", "dt": 1.29930, "dt_data": 0.75948, "dt_net": 0.53982, "eta": "0:00:01", "loss": 0.28187, "lr": 0.00010, "mode": "train"}
[12/04 20:14:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "97", "cur_iter": "1", "dt": 1.29733, "dt_data": 0.75699, "dt_net": 0.54034, "eta": "0:00:01", "loss": 0.28420, "lr": 0.00010, "mode": "train"}
[12/04 20:14:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "98", "cur_iter": "1", "dt": 1.30620, "dt_data": 0.76537, "dt_net": 0.54082, "eta": "0:00:01", "loss": 0.28352, "lr": 0.00010, "mode": "train"}
[12/04 20:14:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "99", "cur_iter": "1", "dt": 1.29744, "dt_data": 0.75748, "dt_net": 0.53996, "eta": "0:00:01", "loss": 0.28435, "lr": 0.00010, "mode": "train"}
[12/04 20:14:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 1.31599, "dt_data": 0.77565, "dt_net": 0.54034, "eta": "0:00:01", "loss": 0.28387, "lr": 0.00010, "mode": "train"}
[12/04 20:14:14][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 0.83677, "dt_data": 0.76243, "dt_net": 0.07434, "eta": "0:00:00", "mode": "val"}
[12/04 20:14:14][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:14:14][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:14:14][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:14:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:14][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:14:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:14][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:14:14][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003142 seconds.
[12/04 20:14:14][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "100", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:14:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "101", "cur_iter": "1", "dt": 1.29295, "dt_data": 0.75533, "dt_net": 0.53761, "eta": "0:00:01", "loss": 0.28717, "lr": 0.00010, "mode": "train"}
[12/04 20:14:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "102", "cur_iter": "1", "dt": 1.29945, "dt_data": 0.76224, "dt_net": 0.53721, "eta": "0:00:01", "loss": 0.27394, "lr": 0.00010, "mode": "train"}
[12/04 20:14:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "103", "cur_iter": "1", "dt": 1.30503, "dt_data": 0.76717, "dt_net": 0.53786, "eta": "0:00:01", "loss": 0.28385, "lr": 0.00010, "mode": "train"}
[12/04 20:14:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "104", "cur_iter": "1", "dt": 1.29414, "dt_data": 0.75673, "dt_net": 0.53740, "eta": "0:00:01", "loss": 0.27976, "lr": 0.00010, "mode": "train"}
[12/04 20:14:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 1.30486, "dt_data": 0.76709, "dt_net": 0.53777, "eta": "0:00:01", "loss": 0.29549, "lr": 0.00010, "mode": "train"}
[12/04 20:14:22][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 0.83762, "dt_data": 0.76357, "dt_net": 0.07405, "eta": "0:00:00", "mode": "val"}
[12/04 20:14:22][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:14:22][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:14:22][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:14:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:22][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:14:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:22][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:14:22][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003192 seconds.
[12/04 20:14:22][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "105", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:14:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "106", "cur_iter": "1", "dt": 1.29891, "dt_data": 0.76131, "dt_net": 0.53760, "eta": "0:00:01", "loss": 0.27957, "lr": 0.00010, "mode": "train"}
[12/04 20:14:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "107", "cur_iter": "1", "dt": 1.29764, "dt_data": 0.76036, "dt_net": 0.53727, "eta": "0:00:01", "loss": 0.30291, "lr": 0.00010, "mode": "train"}
[12/04 20:14:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "108", "cur_iter": "1", "dt": 1.29547, "dt_data": 0.75764, "dt_net": 0.53782, "eta": "0:00:01", "loss": 0.27695, "lr": 0.00010, "mode": "train"}
[12/04 20:14:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "109", "cur_iter": "1", "dt": 1.29313, "dt_data": 0.75587, "dt_net": 0.53725, "eta": "0:00:01", "loss": 0.27223, "lr": 0.00010, "mode": "train"}
[12/04 20:14:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 1.29487, "dt_data": 0.75761, "dt_net": 0.53725, "eta": "0:00:01", "loss": 0.27631, "lr": 0.00010, "mode": "train"}
[12/04 20:14:30][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 0.84391, "dt_data": 0.77009, "dt_net": 0.07382, "eta": "0:00:00", "mode": "val"}
[12/04 20:14:30][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:14:30][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:14:30][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:14:30][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:30][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:14:30][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:30][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:14:30][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003088 seconds.
[12/04 20:14:30][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "110", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:14:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "111", "cur_iter": "1", "dt": 1.29310, "dt_data": 0.75525, "dt_net": 0.53785, "eta": "0:00:01", "loss": 0.28393, "lr": 0.00010, "mode": "train"}
[12/04 20:14:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "112", "cur_iter": "1", "dt": 1.29610, "dt_data": 0.75858, "dt_net": 0.53752, "eta": "0:00:01", "loss": 0.27724, "lr": 0.00010, "mode": "train"}
[12/04 20:14:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "113", "cur_iter": "1", "dt": 1.29769, "dt_data": 0.76006, "dt_net": 0.53763, "eta": "0:00:01", "loss": 0.29435, "lr": 0.00010, "mode": "train"}
[12/04 20:14:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "114", "cur_iter": "1", "dt": 1.29819, "dt_data": 0.76012, "dt_net": 0.53807, "eta": "0:00:01", "loss": 0.27506, "lr": 0.00010, "mode": "train"}
[12/04 20:14:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 1.31445, "dt_data": 0.77624, "dt_net": 0.53821, "eta": "0:00:01", "loss": 0.28295, "lr": 0.00010, "mode": "train"}
[12/04 20:14:37][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 0.83126, "dt_data": 0.75708, "dt_net": 0.07418, "eta": "0:00:00", "mode": "val"}
[12/04 20:14:38][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:14:38][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:14:38][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:14:38][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:38][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:14:38][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:38][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:14:38][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003030 seconds.
[12/04 20:14:38][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "115", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:14:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "116", "cur_iter": "1", "dt": 1.29766, "dt_data": 0.75972, "dt_net": 0.53793, "eta": "0:00:01", "loss": 0.31062, "lr": 0.00010, "mode": "train"}
[12/04 20:14:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "117", "cur_iter": "1", "dt": 1.29755, "dt_data": 0.76000, "dt_net": 0.53755, "eta": "0:00:01", "loss": 0.28860, "lr": 0.00010, "mode": "train"}
[12/04 20:14:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "118", "cur_iter": "1", "dt": 1.29611, "dt_data": 0.75810, "dt_net": 0.53801, "eta": "0:00:01", "loss": 0.27158, "lr": 0.00010, "mode": "train"}
[12/04 20:14:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "119", "cur_iter": "1", "dt": 1.29494, "dt_data": 0.75666, "dt_net": 0.53828, "eta": "0:00:01", "loss": 0.28925, "lr": 0.00010, "mode": "train"}
[12/04 20:14:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 1.29587, "dt_data": 0.75826, "dt_net": 0.53760, "eta": "0:00:01", "loss": 0.29180, "lr": 0.00010, "mode": "train"}
[12/04 20:14:45][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 0.82480, "dt_data": 0.75064, "dt_net": 0.07416, "eta": "0:00:00", "mode": "val"}
[12/04 20:14:45][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:14:45][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:14:45][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:14:45][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:45][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:14:45][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:45][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:14:45][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003067 seconds.
[12/04 20:14:45][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "120", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:14:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "121", "cur_iter": "1", "dt": 1.29691, "dt_data": 0.75886, "dt_net": 0.53805, "eta": "0:00:01", "loss": 0.27929, "lr": 0.00010, "mode": "train"}
[12/04 20:14:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "122", "cur_iter": "1", "dt": 1.29479, "dt_data": 0.75715, "dt_net": 0.53764, "eta": "0:00:01", "loss": 0.28212, "lr": 0.00010, "mode": "train"}
[12/04 20:14:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "123", "cur_iter": "1", "dt": 1.29606, "dt_data": 0.75848, "dt_net": 0.53757, "eta": "0:00:01", "loss": 0.27344, "lr": 0.00010, "mode": "train"}
[12/04 20:14:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "124", "cur_iter": "1", "dt": 1.29299, "dt_data": 0.75516, "dt_net": 0.53782, "eta": "0:00:01", "loss": 0.28331, "lr": 0.00010, "mode": "train"}
[12/04 20:14:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 1.29508, "dt_data": 0.75786, "dt_net": 0.53722, "eta": "0:00:01", "loss": 0.27987, "lr": 0.00010, "mode": "train"}
[12/04 20:14:53][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 0.82488, "dt_data": 0.75104, "dt_net": 0.07384, "eta": "0:00:00", "mode": "val"}
[12/04 20:14:53][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:14:53][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:14:53][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:14:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:53][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:14:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:14:53][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:14:53][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003053 seconds.
[12/04 20:14:53][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "125", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:14:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "126", "cur_iter": "1", "dt": 1.29672, "dt_data": 0.75867, "dt_net": 0.53805, "eta": "0:00:01", "loss": 0.28049, "lr": 0.00010, "mode": "train"}
[12/04 20:14:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "127", "cur_iter": "1", "dt": 1.29293, "dt_data": 0.75522, "dt_net": 0.53771, "eta": "0:00:01", "loss": 0.27987, "lr": 0.00010, "mode": "train"}
[12/04 20:14:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "128", "cur_iter": "1", "dt": 1.29374, "dt_data": 0.75629, "dt_net": 0.53745, "eta": "0:00:01", "loss": 0.28558, "lr": 0.00010, "mode": "train"}
[12/04 20:14:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "129", "cur_iter": "1", "dt": 1.29442, "dt_data": 0.75643, "dt_net": 0.53799, "eta": "0:00:01", "loss": 0.28510, "lr": 0.00010, "mode": "train"}
[12/04 20:15:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 1.29562, "dt_data": 0.75743, "dt_net": 0.53818, "eta": "0:00:01", "loss": 0.27912, "lr": 0.00010, "mode": "train"}
[12/04 20:15:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 0.83550, "dt_data": 0.76164, "dt_net": 0.07386, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003106 seconds.
[12/04 20:15:01][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "130", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "131", "cur_iter": "1", "dt": 1.29449, "dt_data": 0.75720, "dt_net": 0.53729, "eta": "0:00:01", "loss": 0.27685, "lr": 0.00010, "mode": "train"}
[12/04 20:15:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "132", "cur_iter": "1", "dt": 1.29429, "dt_data": 0.75676, "dt_net": 0.53753, "eta": "0:00:01", "loss": 0.27427, "lr": 0.00010, "mode": "train"}
[12/04 20:15:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "133", "cur_iter": "1", "dt": 1.29734, "dt_data": 0.75998, "dt_net": 0.53736, "eta": "0:00:01", "loss": 0.27459, "lr": 0.00010, "mode": "train"}
[12/04 20:15:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "134", "cur_iter": "1", "dt": 1.29366, "dt_data": 0.75549, "dt_net": 0.53817, "eta": "0:00:01", "loss": 0.28688, "lr": 0.00010, "mode": "train"}
[12/04 20:15:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 1.30394, "dt_data": 0.76582, "dt_net": 0.53811, "eta": "0:00:01", "loss": 0.27156, "lr": 0.00010, "mode": "train"}
[12/04 20:15:09][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 0.83587, "dt_data": 0.76214, "dt_net": 0.07373, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:09][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:09][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:09][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:09][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:09][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:09][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003134 seconds.
[12/04 20:15:09][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "135", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "136", "cur_iter": "1", "dt": 1.29436, "dt_data": 0.75663, "dt_net": 0.53773, "eta": "0:00:01", "loss": 0.27852, "lr": 0.00010, "mode": "train"}
[12/04 20:15:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "137", "cur_iter": "1", "dt": 1.29612, "dt_data": 0.75802, "dt_net": 0.53810, "eta": "0:00:01", "loss": 0.27211, "lr": 0.00010, "mode": "train"}
[12/04 20:15:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "138", "cur_iter": "1", "dt": 1.29567, "dt_data": 0.75806, "dt_net": 0.53761, "eta": "0:00:01", "loss": 0.28342, "lr": 0.00010, "mode": "train"}
[12/04 20:15:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "139", "cur_iter": "1", "dt": 1.29327, "dt_data": 0.75612, "dt_net": 0.53715, "eta": "0:00:01", "loss": 0.29031, "lr": 0.00010, "mode": "train"}
[12/04 20:15:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 1.29684, "dt_data": 0.75908, "dt_net": 0.53776, "eta": "0:00:01", "loss": 0.29601, "lr": 0.00010, "mode": "train"}
[12/04 20:15:17][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 0.84522, "dt_data": 0.77142, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:17][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:17][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:17][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:17][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:17][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:17][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:17][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:17][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003058 seconds.
[12/04 20:15:17][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "140", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "141", "cur_iter": "1", "dt": 1.29626, "dt_data": 0.75854, "dt_net": 0.53772, "eta": "0:00:01", "loss": 0.28499, "lr": 0.00010, "mode": "train"}
[12/04 20:15:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "142", "cur_iter": "1", "dt": 1.29386, "dt_data": 0.75607, "dt_net": 0.53779, "eta": "0:00:01", "loss": 0.28756, "lr": 0.00010, "mode": "train"}
[12/04 20:15:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "143", "cur_iter": "1", "dt": 1.29504, "dt_data": 0.75708, "dt_net": 0.53795, "eta": "0:00:01", "loss": 0.27919, "lr": 0.00010, "mode": "train"}
[12/04 20:15:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "144", "cur_iter": "1", "dt": 1.29939, "dt_data": 0.76182, "dt_net": 0.53757, "eta": "0:00:01", "loss": 0.28918, "lr": 0.00010, "mode": "train"}
[12/04 20:15:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 1.30554, "dt_data": 0.76727, "dt_net": 0.53826, "eta": "0:00:01", "loss": 0.27732, "lr": 0.00010, "mode": "train"}
[12/04 20:15:25][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 0.83924, "dt_data": 0.76537, "dt_net": 0.07387, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:25][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:25][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:25][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:25][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:25][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:25][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:25][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:25][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002869 seconds.
[12/04 20:15:25][INFO] logging.py:  96: json_stats: {"RAM": "2.59/15.59G", "_type": "val_epoch", "cur_epoch": "145", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "146", "cur_iter": "1", "dt": 1.29760, "dt_data": 0.76008, "dt_net": 0.53752, "eta": "0:00:01", "loss": 0.30180, "lr": 0.00010, "mode": "train"}
[12/04 20:15:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "147", "cur_iter": "1", "dt": 1.29463, "dt_data": 0.75652, "dt_net": 0.53811, "eta": "0:00:01", "loss": 0.27407, "lr": 0.00010, "mode": "train"}
[12/04 20:15:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "148", "cur_iter": "1", "dt": 1.29732, "dt_data": 0.75981, "dt_net": 0.53751, "eta": "0:00:01", "loss": 0.28145, "lr": 0.00010, "mode": "train"}
[12/04 20:15:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "149", "cur_iter": "1", "dt": 1.29358, "dt_data": 0.75620, "dt_net": 0.53738, "eta": "0:00:01", "loss": 0.26977, "lr": 0.00010, "mode": "train"}
[12/04 20:15:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 1.29955, "dt_data": 0.76190, "dt_net": 0.53764, "eta": "0:00:01", "loss": 0.28571, "lr": 0.00010, "mode": "train"}
[12/04 20:15:33][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 0.83524, "dt_data": 0.76116, "dt_net": 0.07407, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:33][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:33][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:33][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:33][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:33][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:33][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:33][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:33][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002936 seconds.
[12/04 20:15:33][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "150", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "151", "cur_iter": "1", "dt": 1.29329, "dt_data": 0.75573, "dt_net": 0.53756, "eta": "0:00:01", "loss": 0.30476, "lr": 0.00010, "mode": "train"}
[12/04 20:15:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "152", "cur_iter": "1", "dt": 1.29269, "dt_data": 0.75527, "dt_net": 0.53742, "eta": "0:00:01", "loss": 0.28662, "lr": 0.00010, "mode": "train"}
[12/04 20:15:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "153", "cur_iter": "1", "dt": 1.29733, "dt_data": 0.75911, "dt_net": 0.53821, "eta": "0:00:01", "loss": 0.29148, "lr": 0.00010, "mode": "train"}
[12/04 20:15:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "154", "cur_iter": "1", "dt": 1.29366, "dt_data": 0.75606, "dt_net": 0.53760, "eta": "0:00:01", "loss": 0.27534, "lr": 0.00010, "mode": "train"}
[12/04 20:15:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 1.29501, "dt_data": 0.75694, "dt_net": 0.53806, "eta": "0:00:01", "loss": 0.27581, "lr": 0.00010, "mode": "train"}
[12/04 20:15:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 0.83854, "dt_data": 0.76466, "dt_net": 0.07387, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:41][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:41][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:41][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:41][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:41][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:41][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003019 seconds.
[12/04 20:15:41][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "155", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "156", "cur_iter": "1", "dt": 1.29674, "dt_data": 0.75946, "dt_net": 0.53727, "eta": "0:00:01", "loss": 0.27315, "lr": 0.00010, "mode": "train"}
[12/04 20:15:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "157", "cur_iter": "1", "dt": 1.29708, "dt_data": 0.75762, "dt_net": 0.53945, "eta": "0:00:01", "loss": 0.28700, "lr": 0.00010, "mode": "train"}
[12/04 20:15:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "158", "cur_iter": "1", "dt": 1.29847, "dt_data": 0.75792, "dt_net": 0.54055, "eta": "0:00:01", "loss": 0.28387, "lr": 0.00010, "mode": "train"}
[12/04 20:15:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "159", "cur_iter": "1", "dt": 1.29733, "dt_data": 0.75724, "dt_net": 0.54008, "eta": "0:00:01", "loss": 0.26866, "lr": 0.00010, "mode": "train"}
[12/04 20:15:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 1.30750, "dt_data": 0.76703, "dt_net": 0.54047, "eta": "0:00:01", "loss": 0.27493, "lr": 0.00010, "mode": "train"}
[12/04 20:15:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 0.84162, "dt_data": 0.76733, "dt_net": 0.07429, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:49][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:49][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003073 seconds.
[12/04 20:15:49][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "160", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "161", "cur_iter": "1", "dt": 1.29957, "dt_data": 0.75890, "dt_net": 0.54066, "eta": "0:00:01", "loss": 0.28590, "lr": 0.00010, "mode": "train"}
[12/04 20:15:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "162", "cur_iter": "1", "dt": 1.29737, "dt_data": 0.75737, "dt_net": 0.54000, "eta": "0:00:01", "loss": 0.27479, "lr": 0.00010, "mode": "train"}
[12/04 20:15:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "163", "cur_iter": "1", "dt": 1.29786, "dt_data": 0.75726, "dt_net": 0.54060, "eta": "0:00:01", "loss": 0.28531, "lr": 0.00010, "mode": "train"}
[12/04 20:15:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "164", "cur_iter": "1", "dt": 1.29509, "dt_data": 0.75504, "dt_net": 0.54005, "eta": "0:00:01", "loss": 0.27554, "lr": 0.00010, "mode": "train"}
[12/04 20:15:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 1.30839, "dt_data": 0.76803, "dt_net": 0.54035, "eta": "0:00:01", "loss": 0.27732, "lr": 0.00010, "mode": "train"}
[12/04 20:15:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 0.84487, "dt_data": 0.77086, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/04 20:15:57][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:15:57][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:15:57][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:15:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:57][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:15:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:15:57][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:15:57][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003207 seconds.
[12/04 20:15:57][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "165", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:15:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "166", "cur_iter": "1", "dt": 1.30670, "dt_data": 0.76637, "dt_net": 0.54033, "eta": "0:00:01", "loss": 0.27237, "lr": 0.00010, "mode": "train"}
[12/04 20:15:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "167", "cur_iter": "1", "dt": 1.30027, "dt_data": 0.76019, "dt_net": 0.54008, "eta": "0:00:01", "loss": 0.28246, "lr": 0.00010, "mode": "train"}
[12/04 20:16:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "168", "cur_iter": "1", "dt": 1.30445, "dt_data": 0.76412, "dt_net": 0.54033, "eta": "0:00:01", "loss": 0.27903, "lr": 0.00010, "mode": "train"}
[12/04 20:16:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "169", "cur_iter": "1", "dt": 1.30053, "dt_data": 0.76021, "dt_net": 0.54032, "eta": "0:00:01", "loss": 0.28329, "lr": 0.00010, "mode": "train"}
[12/04 20:16:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 1.30007, "dt_data": 0.76012, "dt_net": 0.53995, "eta": "0:00:01", "loss": 0.27595, "lr": 0.00010, "mode": "train"}
[12/04 20:16:04][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 0.84799, "dt_data": 0.77334, "dt_net": 0.07465, "eta": "0:00:00", "mode": "val"}
[12/04 20:16:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:16:05][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:16:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:16:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:16:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:05][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:16:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003091 seconds.
[12/04 20:16:05][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "170", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:16:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "171", "cur_iter": "1", "dt": 1.29777, "dt_data": 0.75726, "dt_net": 0.54051, "eta": "0:00:01", "loss": 0.27658, "lr": 0.00010, "mode": "train"}
[12/04 20:16:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "172", "cur_iter": "1", "dt": 1.29962, "dt_data": 0.75953, "dt_net": 0.54008, "eta": "0:00:01", "loss": 0.27630, "lr": 0.00010, "mode": "train"}
[12/04 20:16:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "173", "cur_iter": "1", "dt": 1.29940, "dt_data": 0.75917, "dt_net": 0.54022, "eta": "0:00:01", "loss": 0.27412, "lr": 0.00010, "mode": "train"}
[12/04 20:16:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "174", "cur_iter": "1", "dt": 1.30319, "dt_data": 0.76270, "dt_net": 0.54049, "eta": "0:00:01", "loss": 0.26784, "lr": 0.00010, "mode": "train"}
[12/04 20:16:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 1.31975, "dt_data": 0.77929, "dt_net": 0.54046, "eta": "0:00:01", "loss": 0.27557, "lr": 0.00010, "mode": "train"}
[12/04 20:16:12][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 0.83340, "dt_data": 0.75920, "dt_net": 0.07420, "eta": "0:00:00", "mode": "val"}
[12/04 20:16:12][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:16:12][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:16:12][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:16:12][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:12][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:16:12][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:12][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:16:12][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003228 seconds.
[12/04 20:16:12][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "175", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:16:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "176", "cur_iter": "1", "dt": 1.29852, "dt_data": 0.75795, "dt_net": 0.54057, "eta": "0:00:01", "loss": 0.27437, "lr": 0.00010, "mode": "train"}
[12/04 20:16:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "177", "cur_iter": "1", "dt": 1.29593, "dt_data": 0.75617, "dt_net": 0.53975, "eta": "0:00:01", "loss": 0.28078, "lr": 0.00010, "mode": "train"}
[12/04 20:16:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "178", "cur_iter": "1", "dt": 1.29898, "dt_data": 0.75822, "dt_net": 0.54076, "eta": "0:00:01", "loss": 0.27855, "lr": 0.00010, "mode": "train"}
[12/04 20:16:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "179", "cur_iter": "1", "dt": 1.29997, "dt_data": 0.75918, "dt_net": 0.54078, "eta": "0:00:01", "loss": 0.28886, "lr": 0.00010, "mode": "train"}
[12/04 20:16:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 1.29809, "dt_data": 0.75790, "dt_net": 0.54019, "eta": "0:00:01", "loss": 0.27458, "lr": 0.00010, "mode": "train"}
[12/04 20:16:20][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 0.83647, "dt_data": 0.76245, "dt_net": 0.07402, "eta": "0:00:00", "mode": "val"}
[12/04 20:16:20][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:16:20][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:16:20][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:16:20][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:20][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:16:20][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:20][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:16:20][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003026 seconds.
[12/04 20:16:20][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "180", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:16:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "181", "cur_iter": "1", "dt": 1.29598, "dt_data": 0.75619, "dt_net": 0.53978, "eta": "0:00:01", "loss": 0.29099, "lr": 0.00010, "mode": "train"}
[12/04 20:16:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "182", "cur_iter": "1", "dt": 1.29479, "dt_data": 0.75618, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.28182, "lr": 0.00010, "mode": "train"}
[12/04 20:16:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "183", "cur_iter": "1", "dt": 1.29552, "dt_data": 0.75720, "dt_net": 0.53832, "eta": "0:00:01", "loss": 0.28268, "lr": 0.00010, "mode": "train"}
[12/04 20:16:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "184", "cur_iter": "1", "dt": 1.29623, "dt_data": 0.75698, "dt_net": 0.53925, "eta": "0:00:01", "loss": 0.27954, "lr": 0.00010, "mode": "train"}
[12/04 20:16:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 1.29518, "dt_data": 0.75641, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27110, "lr": 0.00010, "mode": "train"}
[12/04 20:16:28][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 0.83687, "dt_data": 0.76270, "dt_net": 0.07417, "eta": "0:00:00", "mode": "val"}
[12/04 20:16:28][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:16:28][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:16:28][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:16:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:28][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:16:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:28][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:16:28][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002961 seconds.
[12/04 20:16:28][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "185", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:16:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "186", "cur_iter": "1", "dt": 1.29536, "dt_data": 0.75662, "dt_net": 0.53873, "eta": "0:00:01", "loss": 0.28489, "lr": 0.00010, "mode": "train"}
[12/04 20:16:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "187", "cur_iter": "1", "dt": 1.29709, "dt_data": 0.75788, "dt_net": 0.53921, "eta": "0:00:01", "loss": 0.27596, "lr": 0.00010, "mode": "train"}
[12/04 20:16:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "188", "cur_iter": "1", "dt": 1.29533, "dt_data": 0.75673, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.30693, "lr": 0.00010, "mode": "train"}
[12/04 20:16:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "189", "cur_iter": "1", "dt": 1.29500, "dt_data": 0.75640, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.27280, "lr": 0.00010, "mode": "train"}
[12/04 20:16:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 1.29823, "dt_data": 0.75971, "dt_net": 0.53852, "eta": "0:00:01", "loss": 0.27097, "lr": 0.00010, "mode": "train"}
[12/04 20:16:36][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 0.83798, "dt_data": 0.76405, "dt_net": 0.07393, "eta": "0:00:00", "mode": "val"}
[12/04 20:16:36][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:16:36][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:16:36][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:16:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:36][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:16:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:36][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:16:36][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003101 seconds.
[12/04 20:16:36][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "190", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:16:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "191", "cur_iter": "1", "dt": 1.29800, "dt_data": 0.75902, "dt_net": 0.53898, "eta": "0:00:01", "loss": 0.27972, "lr": 0.00010, "mode": "train"}
[12/04 20:16:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "192", "cur_iter": "1", "dt": 1.29647, "dt_data": 0.75759, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27328, "lr": 0.00010, "mode": "train"}
[12/04 20:16:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "193", "cur_iter": "1", "dt": 1.29679, "dt_data": 0.75794, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.29818, "lr": 0.00010, "mode": "train"}
[12/04 20:16:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "194", "cur_iter": "1", "dt": 1.29487, "dt_data": 0.75589, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27358, "lr": 0.00010, "mode": "train"}
[12/04 20:16:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 1.31070, "dt_data": 0.77149, "dt_net": 0.53921, "eta": "0:00:01", "loss": 0.27375, "lr": 0.00010, "mode": "train"}
[12/04 20:16:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 0.83996, "dt_data": 0.76604, "dt_net": 0.07391, "eta": "0:00:00", "mode": "val"}
[12/04 20:16:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:16:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:16:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:16:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:16:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:16:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003072 seconds.
[12/04 20:16:44][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "195", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:16:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "196", "cur_iter": "1", "dt": 1.29919, "dt_data": 0.76041, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.27057, "lr": 0.00010, "mode": "train"}
[12/04 20:16:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "197", "cur_iter": "1", "dt": 1.29635, "dt_data": 0.75746, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.27641, "lr": 0.00010, "mode": "train"}
[12/04 20:16:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "198", "cur_iter": "1", "dt": 1.29778, "dt_data": 0.75885, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.27800, "lr": 0.00010, "mode": "train"}
[12/04 20:16:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "199", "cur_iter": "1", "dt": 1.29673, "dt_data": 0.75756, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.27620, "lr": 0.00010, "mode": "train"}
[12/04 20:16:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 1.29827, "dt_data": 0.75934, "dt_net": 0.53893, "eta": "0:00:01", "loss": 0.28712, "lr": 0.00010, "mode": "train"}
[12/04 20:16:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 0.84415, "dt_data": 0.77019, "dt_net": 0.07396, "eta": "0:00:00", "mode": "val"}
[12/04 20:16:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:16:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:16:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:16:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:16:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:16:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:16:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.021169 seconds.
[12/04 20:16:52][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "200", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:16:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "201", "cur_iter": "1", "dt": 1.32073, "dt_data": 0.78217, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.27487, "lr": 0.00010, "mode": "train"}
[12/04 20:16:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "202", "cur_iter": "1", "dt": 1.29738, "dt_data": 0.75857, "dt_net": 0.53880, "eta": "0:00:01", "loss": 0.28217, "lr": 0.00010, "mode": "train"}
[12/04 20:16:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "203", "cur_iter": "1", "dt": 1.29735, "dt_data": 0.75856, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.26682, "lr": 0.00010, "mode": "train"}
[12/04 20:16:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "204", "cur_iter": "1", "dt": 1.29811, "dt_data": 0.75909, "dt_net": 0.53902, "eta": "0:00:01", "loss": 0.27536, "lr": 0.00010, "mode": "train"}
[12/04 20:16:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 1.32581, "dt_data": 0.78642, "dt_net": 0.53939, "eta": "0:00:01", "loss": 0.27512, "lr": 0.00010, "mode": "train"}
[12/04 20:17:00][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 0.83941, "dt_data": 0.76531, "dt_net": 0.07410, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:00][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:00][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:00][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:00][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:00][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:00][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002727 seconds.
[12/04 20:17:00][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "205", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "206", "cur_iter": "1", "dt": 1.29431, "dt_data": 0.75558, "dt_net": 0.53873, "eta": "0:00:01", "loss": 0.27327, "lr": 0.00010, "mode": "train"}
[12/04 20:17:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "207", "cur_iter": "1", "dt": 1.29665, "dt_data": 0.75769, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.28079, "lr": 0.00010, "mode": "train"}
[12/04 20:17:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "208", "cur_iter": "1", "dt": 1.29789, "dt_data": 0.75899, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27807, "lr": 0.00010, "mode": "train"}
[12/04 20:17:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "209", "cur_iter": "1", "dt": 1.29670, "dt_data": 0.75832, "dt_net": 0.53838, "eta": "0:00:01", "loss": 0.26965, "lr": 0.00010, "mode": "train"}
[12/04 20:17:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 1.29842, "dt_data": 0.75942, "dt_net": 0.53899, "eta": "0:00:01", "loss": 0.27355, "lr": 0.00010, "mode": "train"}
[12/04 20:17:08][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 0.83375, "dt_data": 0.75984, "dt_net": 0.07391, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:08][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:08][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:08][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:08][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:08][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:08][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002980 seconds.
[12/04 20:17:08][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "210", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "211", "cur_iter": "1", "dt": 1.29933, "dt_data": 0.76074, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.27465, "lr": 0.00010, "mode": "train"}
[12/04 20:17:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "212", "cur_iter": "1", "dt": 1.29842, "dt_data": 0.75911, "dt_net": 0.53931, "eta": "0:00:01", "loss": 0.28021, "lr": 0.00010, "mode": "train"}
[12/04 20:17:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "213", "cur_iter": "1", "dt": 1.29786, "dt_data": 0.75915, "dt_net": 0.53871, "eta": "0:00:01", "loss": 0.27474, "lr": 0.00010, "mode": "train"}
[12/04 20:17:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "214", "cur_iter": "1", "dt": 1.29676, "dt_data": 0.75823, "dt_net": 0.53852, "eta": "0:00:01", "loss": 0.28361, "lr": 0.00010, "mode": "train"}
[12/04 20:17:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 1.29839, "dt_data": 0.75976, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.27666, "lr": 0.00010, "mode": "train"}
[12/04 20:17:16][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 0.83678, "dt_data": 0.76289, "dt_net": 0.07389, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:16][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:16][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:16][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:16][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:16][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:16][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003029 seconds.
[12/04 20:17:16][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "215", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "216", "cur_iter": "1", "dt": 1.29948, "dt_data": 0.76081, "dt_net": 0.53866, "eta": "0:00:01", "loss": 0.27995, "lr": 0.00010, "mode": "train"}
[12/04 20:17:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "217", "cur_iter": "1", "dt": 1.29628, "dt_data": 0.75744, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.27330, "lr": 0.00010, "mode": "train"}
[12/04 20:17:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "218", "cur_iter": "1", "dt": 1.29936, "dt_data": 0.76041, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.27931, "lr": 0.00010, "mode": "train"}
[12/04 20:17:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "219", "cur_iter": "1", "dt": 1.29615, "dt_data": 0.75786, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.27126, "lr": 0.00010, "mode": "train"}
[12/04 20:17:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 1.29781, "dt_data": 0.75855, "dt_net": 0.53926, "eta": "0:00:01", "loss": 0.26759, "lr": 0.00010, "mode": "train"}
[12/04 20:17:24][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 0.83430, "dt_data": 0.76043, "dt_net": 0.07387, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:24][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:24][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:24][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:24][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:24][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:24][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003202 seconds.
[12/04 20:17:24][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "220", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "221", "cur_iter": "1", "dt": 1.30036, "dt_data": 0.76166, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.28244, "lr": 0.00010, "mode": "train"}
[12/04 20:17:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "222", "cur_iter": "1", "dt": 1.29848, "dt_data": 0.75973, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.28031, "lr": 0.00010, "mode": "train"}
[12/04 20:17:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "223", "cur_iter": "1", "dt": 1.29803, "dt_data": 0.75902, "dt_net": 0.53901, "eta": "0:00:01", "loss": 0.27529, "lr": 0.00010, "mode": "train"}
[12/04 20:17:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "224", "cur_iter": "1", "dt": 1.29677, "dt_data": 0.75814, "dt_net": 0.53863, "eta": "0:00:01", "loss": 0.27841, "lr": 0.00010, "mode": "train"}
[12/04 20:17:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 1.29853, "dt_data": 0.75927, "dt_net": 0.53926, "eta": "0:00:01", "loss": 0.27167, "lr": 0.00010, "mode": "train"}
[12/04 20:17:32][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 0.84229, "dt_data": 0.76835, "dt_net": 0.07394, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003072 seconds.
[12/04 20:17:32][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "225", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "226", "cur_iter": "1", "dt": 1.30057, "dt_data": 0.76220, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27148, "lr": 0.00010, "mode": "train"}
[12/04 20:17:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "227", "cur_iter": "1", "dt": 1.29637, "dt_data": 0.75761, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27579, "lr": 0.00010, "mode": "train"}
[12/04 20:17:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "228", "cur_iter": "1", "dt": 1.30064, "dt_data": 0.76178, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27888, "lr": 0.00010, "mode": "train"}
[12/04 20:17:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "229", "cur_iter": "1", "dt": 1.29570, "dt_data": 0.75720, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.27818, "lr": 0.00010, "mode": "train"}
[12/04 20:17:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 1.29752, "dt_data": 0.75857, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.27154, "lr": 0.00010, "mode": "train"}
[12/04 20:17:40][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 0.85833, "dt_data": 0.78411, "dt_net": 0.07421, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:40][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:40][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:40][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:40][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:40][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:40][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003049 seconds.
[12/04 20:17:40][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "230", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "231", "cur_iter": "1", "dt": 1.30161, "dt_data": 0.76247, "dt_net": 0.53913, "eta": "0:00:01", "loss": 0.26958, "lr": 0.00010, "mode": "train"}
[12/04 20:17:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "232", "cur_iter": "1", "dt": 1.29622, "dt_data": 0.75706, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.27024, "lr": 0.00010, "mode": "train"}
[12/04 20:17:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "233", "cur_iter": "1", "dt": 1.29668, "dt_data": 0.75799, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.27772, "lr": 0.00010, "mode": "train"}
[12/04 20:17:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "234", "cur_iter": "1", "dt": 1.30146, "dt_data": 0.76290, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.26892, "lr": 0.00010, "mode": "train"}
[12/04 20:17:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 1.31946, "dt_data": 0.77964, "dt_net": 0.53981, "eta": "0:00:01", "loss": 0.27848, "lr": 0.00010, "mode": "train"}
[12/04 20:17:48][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 0.84005, "dt_data": 0.76583, "dt_net": 0.07422, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003096 seconds.
[12/04 20:17:48][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "235", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "236", "cur_iter": "1", "dt": 1.29708, "dt_data": 0.75616, "dt_net": 0.54092, "eta": "0:00:01", "loss": 0.27151, "lr": 0.00010, "mode": "train"}
[12/04 20:17:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "237", "cur_iter": "1", "dt": 1.29929, "dt_data": 0.75937, "dt_net": 0.53992, "eta": "0:00:01", "loss": 0.27686, "lr": 0.00010, "mode": "train"}
[12/04 20:17:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "238", "cur_iter": "1", "dt": 1.30022, "dt_data": 0.75935, "dt_net": 0.54087, "eta": "0:00:01", "loss": 0.28194, "lr": 0.00010, "mode": "train"}
[12/04 20:17:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "239", "cur_iter": "1", "dt": 1.29823, "dt_data": 0.75771, "dt_net": 0.54051, "eta": "0:00:01", "loss": 0.27160, "lr": 0.00010, "mode": "train"}
[12/04 20:17:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 1.30060, "dt_data": 0.76042, "dt_net": 0.54018, "eta": "0:00:01", "loss": 0.27955, "lr": 0.00010, "mode": "train"}
[12/04 20:17:55][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 0.83793, "dt_data": 0.76387, "dt_net": 0.07406, "eta": "0:00:00", "mode": "val"}
[12/04 20:17:56][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:17:56][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:17:56][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:17:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:56][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:17:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:17:56][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:17:56][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003106 seconds.
[12/04 20:17:56][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "240", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:17:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "241", "cur_iter": "1", "dt": 1.30329, "dt_data": 0.76257, "dt_net": 0.54072, "eta": "0:00:01", "loss": 0.28441, "lr": 0.00010, "mode": "train"}
[12/04 20:17:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "242", "cur_iter": "1", "dt": 1.30100, "dt_data": 0.76093, "dt_net": 0.54007, "eta": "0:00:01", "loss": 0.27442, "lr": 0.00010, "mode": "train"}
[12/04 20:18:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "243", "cur_iter": "1", "dt": 1.29965, "dt_data": 0.75916, "dt_net": 0.54048, "eta": "0:00:01", "loss": 0.26642, "lr": 0.00010, "mode": "train"}
[12/04 20:18:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "244", "cur_iter": "1", "dt": 1.29731, "dt_data": 0.75683, "dt_net": 0.54049, "eta": "0:00:01", "loss": 0.26932, "lr": 0.00010, "mode": "train"}
[12/04 20:18:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 1.30060, "dt_data": 0.76014, "dt_net": 0.54045, "eta": "0:00:01", "loss": 0.28936, "lr": 0.00010, "mode": "train"}
[12/04 20:18:03][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 0.83542, "dt_data": 0.76145, "dt_net": 0.07397, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:03][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:03][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:03][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:03][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:03][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:03][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:03][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:03][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003029 seconds.
[12/04 20:18:03][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "245", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:18:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "246", "cur_iter": "1", "dt": 1.29654, "dt_data": 0.75593, "dt_net": 0.54061, "eta": "0:00:01", "loss": 0.27804, "lr": 0.00010, "mode": "train"}
[12/04 20:18:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "247", "cur_iter": "1", "dt": 1.29810, "dt_data": 0.75839, "dt_net": 0.53971, "eta": "0:00:01", "loss": 0.26629, "lr": 0.00010, "mode": "train"}
[12/04 20:18:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "248", "cur_iter": "1", "dt": 1.29825, "dt_data": 0.75812, "dt_net": 0.54013, "eta": "0:00:01", "loss": 0.27858, "lr": 0.00010, "mode": "train"}
[12/04 20:18:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "249", "cur_iter": "1", "dt": 1.29623, "dt_data": 0.75595, "dt_net": 0.54028, "eta": "0:00:01", "loss": 0.27233, "lr": 0.00010, "mode": "train"}
[12/04 20:18:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 1.29762, "dt_data": 0.75771, "dt_net": 0.53990, "eta": "0:00:01", "loss": 0.27148, "lr": 0.00010, "mode": "train"}
[12/04 20:18:11][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 0.83212, "dt_data": 0.75771, "dt_net": 0.07441, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:11][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:11][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:11][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:11][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:11][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:11][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:11][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:11][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002984 seconds.
[12/04 20:18:11][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "250", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:18:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "251", "cur_iter": "1", "dt": 1.30021, "dt_data": 0.75989, "dt_net": 0.54032, "eta": "0:00:01", "loss": 0.27703, "lr": 0.00010, "mode": "train"}
[12/04 20:18:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "252", "cur_iter": "1", "dt": 1.29719, "dt_data": 0.75685, "dt_net": 0.54034, "eta": "0:00:01", "loss": 0.28011, "lr": 0.00010, "mode": "train"}
[12/04 20:18:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "253", "cur_iter": "1", "dt": 1.29900, "dt_data": 0.75897, "dt_net": 0.54003, "eta": "0:00:01", "loss": 0.28415, "lr": 0.00010, "mode": "train"}
[12/04 20:18:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "254", "cur_iter": "1", "dt": 1.29762, "dt_data": 0.75726, "dt_net": 0.54035, "eta": "0:00:01", "loss": 0.26871, "lr": 0.00010, "mode": "train"}
[12/04 20:18:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 1.30688, "dt_data": 0.76683, "dt_net": 0.54005, "eta": "0:00:01", "loss": 0.27083, "lr": 0.00010, "mode": "train"}
[12/04 20:18:19][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 0.83927, "dt_data": 0.76531, "dt_net": 0.07395, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:19][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:19][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:19][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:19][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:19][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:19][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:19][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:19][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003014 seconds.
[12/04 20:18:19][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "255", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:18:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "256", "cur_iter": "1", "dt": 1.30160, "dt_data": 0.76101, "dt_net": 0.54058, "eta": "0:00:01", "loss": 0.27928, "lr": 0.00010, "mode": "train"}
[12/04 20:18:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "257", "cur_iter": "1", "dt": 1.29881, "dt_data": 0.75844, "dt_net": 0.54037, "eta": "0:00:01", "loss": 0.27533, "lr": 0.00010, "mode": "train"}
[12/04 20:18:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "258", "cur_iter": "1", "dt": 1.29719, "dt_data": 0.75831, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.26632, "lr": 0.00010, "mode": "train"}
[12/04 20:18:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "259", "cur_iter": "1", "dt": 1.29539, "dt_data": 0.75652, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27107, "lr": 0.00010, "mode": "train"}
[12/04 20:18:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 1.29826, "dt_data": 0.75917, "dt_net": 0.53909, "eta": "0:00:01", "loss": 0.28493, "lr": 0.00010, "mode": "train"}
[12/04 20:18:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 0.83809, "dt_data": 0.76395, "dt_net": 0.07414, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003150 seconds.
[12/04 20:18:27][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "260", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:18:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "261", "cur_iter": "1", "dt": 1.30472, "dt_data": 0.76558, "dt_net": 0.53913, "eta": "0:00:01", "loss": 0.27434, "lr": 0.00010, "mode": "train"}
[12/04 20:18:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "262", "cur_iter": "1", "dt": 1.29817, "dt_data": 0.75939, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.28462, "lr": 0.00010, "mode": "train"}
[12/04 20:18:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "263", "cur_iter": "1", "dt": 1.29550, "dt_data": 0.75676, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.27172, "lr": 0.00010, "mode": "train"}
[12/04 20:18:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "264", "cur_iter": "1", "dt": 1.29699, "dt_data": 0.75837, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.27038, "lr": 0.00010, "mode": "train"}
[12/04 20:18:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 1.30024, "dt_data": 0.76111, "dt_net": 0.53913, "eta": "0:00:01", "loss": 0.27349, "lr": 0.00010, "mode": "train"}
[12/04 20:18:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 0.83255, "dt_data": 0.75862, "dt_net": 0.07393, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003157 seconds.
[12/04 20:18:35][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "265", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:18:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "266", "cur_iter": "1", "dt": 1.29864, "dt_data": 0.75986, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27554, "lr": 0.00010, "mode": "train"}
[12/04 20:18:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "267", "cur_iter": "1", "dt": 1.29768, "dt_data": 0.75869, "dt_net": 0.53899, "eta": "0:00:01", "loss": 0.26947, "lr": 0.00010, "mode": "train"}
[12/04 20:18:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "268", "cur_iter": "1", "dt": 1.29493, "dt_data": 0.75646, "dt_net": 0.53846, "eta": "0:00:01", "loss": 0.27000, "lr": 0.00010, "mode": "train"}
[12/04 20:18:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "269", "cur_iter": "1", "dt": 1.29536, "dt_data": 0.75716, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.27343, "lr": 0.00010, "mode": "train"}
[12/04 20:18:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 1.29634, "dt_data": 0.75766, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.26528, "lr": 0.00010, "mode": "train"}
[12/04 20:18:43][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 0.84143, "dt_data": 0.76755, "dt_net": 0.07387, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:43][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:43][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:43][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:43][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:43][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:43][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:43][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:43][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003101 seconds.
[12/04 20:18:43][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "270", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:18:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "271", "cur_iter": "1", "dt": 1.29777, "dt_data": 0.75948, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.26676, "lr": 0.00010, "mode": "train"}
[12/04 20:18:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "272", "cur_iter": "1", "dt": 1.29792, "dt_data": 0.75867, "dt_net": 0.53924, "eta": "0:00:01", "loss": 0.27335, "lr": 0.00010, "mode": "train"}
[12/04 20:18:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "273", "cur_iter": "1", "dt": 1.29724, "dt_data": 0.75848, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.28175, "lr": 0.00010, "mode": "train"}
[12/04 20:18:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "274", "cur_iter": "1", "dt": 1.29476, "dt_data": 0.75643, "dt_net": 0.53833, "eta": "0:00:01", "loss": 0.27242, "lr": 0.00010, "mode": "train"}
[12/04 20:18:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 1.29659, "dt_data": 0.75744, "dt_net": 0.53915, "eta": "0:00:01", "loss": 0.27264, "lr": 0.00010, "mode": "train"}
[12/04 20:18:51][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 0.83699, "dt_data": 0.76315, "dt_net": 0.07384, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:51][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:51][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:51][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:51][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:51][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:51][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:51][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:51][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002970 seconds.
[12/04 20:18:51][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "275", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:18:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "276", "cur_iter": "1", "dt": 1.29404, "dt_data": 0.75591, "dt_net": 0.53813, "eta": "0:00:01", "loss": 0.27180, "lr": 0.00010, "mode": "train"}
[12/04 20:18:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "277", "cur_iter": "1", "dt": 1.29678, "dt_data": 0.75806, "dt_net": 0.53871, "eta": "0:00:01", "loss": 0.26953, "lr": 0.00010, "mode": "train"}
[12/04 20:18:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "278", "cur_iter": "1", "dt": 1.29509, "dt_data": 0.75622, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27136, "lr": 0.00010, "mode": "train"}
[12/04 20:18:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "279", "cur_iter": "1", "dt": 1.29581, "dt_data": 0.75741, "dt_net": 0.53840, "eta": "0:00:01", "loss": 0.27375, "lr": 0.00010, "mode": "train"}
[12/04 20:18:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 1.30058, "dt_data": 0.76164, "dt_net": 0.53893, "eta": "0:00:01", "loss": 0.28913, "lr": 0.00010, "mode": "train"}
[12/04 20:18:59][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 0.83473, "dt_data": 0.76053, "dt_net": 0.07419, "eta": "0:00:00", "mode": "val"}
[12/04 20:18:59][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:18:59][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:18:59][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:18:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:59][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:18:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:18:59][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:18:59][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003213 seconds.
[12/04 20:18:59][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "280", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:19:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "281", "cur_iter": "1", "dt": 1.29502, "dt_data": 0.75618, "dt_net": 0.53883, "eta": "0:00:01", "loss": 0.26663, "lr": 0.00010, "mode": "train"}
[12/04 20:19:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "282", "cur_iter": "1", "dt": 1.31054, "dt_data": 0.77138, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.28414, "lr": 0.00010, "mode": "train"}
[12/04 20:19:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "283", "cur_iter": "1", "dt": 1.29905, "dt_data": 0.75988, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.27865, "lr": 0.00010, "mode": "train"}
[12/04 20:19:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "284", "cur_iter": "1", "dt": 1.29514, "dt_data": 0.75676, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.27145, "lr": 0.00010, "mode": "train"}
[12/04 20:19:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 1.29722, "dt_data": 0.75854, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.26698, "lr": 0.00010, "mode": "train"}
[12/04 20:19:07][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 0.84312, "dt_data": 0.76887, "dt_net": 0.07424, "eta": "0:00:00", "mode": "val"}
[12/04 20:19:07][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:19:07][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:19:07][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:19:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:07][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:19:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:07][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:19:07][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002964 seconds.
[12/04 20:19:07][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "285", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:19:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "286", "cur_iter": "1", "dt": 1.29812, "dt_data": 0.75967, "dt_net": 0.53845, "eta": "0:00:01", "loss": 0.27468, "lr": 0.00010, "mode": "train"}
[12/04 20:19:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "287", "cur_iter": "1", "dt": 1.29682, "dt_data": 0.75792, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.26978, "lr": 0.00010, "mode": "train"}
[12/04 20:19:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "288", "cur_iter": "1", "dt": 1.29763, "dt_data": 0.75857, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.27380, "lr": 0.00010, "mode": "train"}
[12/04 20:19:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "289", "cur_iter": "1", "dt": 1.29636, "dt_data": 0.75778, "dt_net": 0.53858, "eta": "0:00:01", "loss": 0.27106, "lr": 0.00010, "mode": "train"}
[12/04 20:19:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 1.30422, "dt_data": 0.76545, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27499, "lr": 0.00010, "mode": "train"}
[12/04 20:19:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 0.84012, "dt_data": 0.76637, "dt_net": 0.07375, "eta": "0:00:00", "mode": "val"}
[12/04 20:19:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:19:15][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:19:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:19:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:19:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:15][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:19:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002944 seconds.
[12/04 20:19:15][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "290", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:19:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "291", "cur_iter": "1", "dt": 1.29823, "dt_data": 0.75940, "dt_net": 0.53883, "eta": "0:00:01", "loss": 0.27156, "lr": 0.00010, "mode": "train"}
[12/04 20:19:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "292", "cur_iter": "1", "dt": 1.30071, "dt_data": 0.76238, "dt_net": 0.53832, "eta": "0:00:01", "loss": 0.27872, "lr": 0.00010, "mode": "train"}
[12/04 20:19:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "293", "cur_iter": "1", "dt": 1.29799, "dt_data": 0.75910, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.26984, "lr": 0.00010, "mode": "train"}
[12/04 20:19:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "294", "cur_iter": "1", "dt": 1.29514, "dt_data": 0.75676, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.26482, "lr": 0.00010, "mode": "train"}
[12/04 20:19:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 1.29497, "dt_data": 0.75665, "dt_net": 0.53832, "eta": "0:00:01", "loss": 0.27241, "lr": 0.00010, "mode": "train"}
[12/04 20:19:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 0.84481, "dt_data": 0.77015, "dt_net": 0.07466, "eta": "0:00:00", "mode": "val"}
[12/04 20:19:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:19:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:19:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:19:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:19:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:19:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002892 seconds.
[12/04 20:19:23][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "295", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:19:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "296", "cur_iter": "1", "dt": 1.29463, "dt_data": 0.75578, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.27351, "lr": 0.00010, "mode": "train"}
[12/04 20:19:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "297", "cur_iter": "1", "dt": 1.29581, "dt_data": 0.75747, "dt_net": 0.53833, "eta": "0:00:01", "loss": 0.26827, "lr": 0.00010, "mode": "train"}
[12/04 20:19:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "298", "cur_iter": "1", "dt": 1.29675, "dt_data": 0.75754, "dt_net": 0.53920, "eta": "0:00:01", "loss": 0.27189, "lr": 0.00010, "mode": "train"}
[12/04 20:19:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "299", "cur_iter": "1", "dt": 1.29571, "dt_data": 0.75672, "dt_net": 0.53899, "eta": "0:00:01", "loss": 0.26954, "lr": 0.00010, "mode": "train"}
[12/04 20:19:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 1.29629, "dt_data": 0.75769, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.26687, "lr": 0.00010, "mode": "train"}
[12/04 20:19:30][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 0.83190, "dt_data": 0.75811, "dt_net": 0.07379, "eta": "0:00:00", "mode": "val"}
[12/04 20:19:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:19:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:19:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:19:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:19:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:19:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:19:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003199 seconds.
[12/04 20:19:31][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "300", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/04 20:26:21][INFO] train_net.py: 377: Train with config:
[12/04 20:26:21][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/04 20:26:23][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/04 20:26:23][INFO] misc.py: 170: Params: 33,653,708
[12/04 20:26:23][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/04 20:26:23][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/04 20:26:23][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/04 20:26:23][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/04 20:26:23][INFO] misc.py: 177: Activations: 155.545604 M
[12/04 20:26:23][INFO] misc.py: 182: nvidia-smi
[12/04 20:26:23][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 20:26:23][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/04 20:26:23][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 20:26:23][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/04 20:26:23][INFO] ava_helper.py: 111: Number of annotations: 15
[12/04 20:26:23][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 20:26:23][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 20:26:23][INFO] ava_dataset.py:  89: Split: train
[12/04 20:26:23][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 20:26:23][INFO] ava_dataset.py:  94: Number of frames: 5
[12/04 20:26:23][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 20:26:23][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/04 20:26:23][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 20:26:23][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/04 20:26:23][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/04 20:26:23][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/04 20:26:23][INFO] ava_helper.py: 111: Number of annotations: 11
[12/04 20:26:23][INFO] ava_helper.py: 157: 1 keyframes used.
[12/04 20:26:23][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/04 20:26:23][INFO] ava_dataset.py:  89: Split: val
[12/04 20:26:23][INFO] ava_dataset.py:  90: Number of videos: 1
[12/04 20:26:23][INFO] ava_dataset.py:  94: Number of frames: 4
[12/04 20:26:23][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/04 20:26:23][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/04 20:26:24][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/04 20:26:24][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/04 20:26:24][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/04 20:26:24][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 20:26:24][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 20:26:24][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/04 20:26:24][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/04 20:26:24][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/04 20:26:24][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/04 20:26:24][INFO] train_net.py: 417: Start epoch: 1
[12/04 20:26:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.33450, "dt_data": 0.80518, "dt_net": 0.52932, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/04 20:26:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.29601, "dt_data": 0.76112, "dt_net": 0.53489, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/04 20:26:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.30114, "dt_data": 0.76508, "dt_net": 0.53605, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/04 20:26:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.30125, "dt_data": 0.76502, "dt_net": 0.53621, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/04 20:26:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.30131, "dt_data": 0.76568, "dt_net": 0.53563, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/04 20:26:33][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.86547, "dt_data": 0.79193, "dt_net": 0.07354, "eta": "0:00:00", "mode": "val"}
[12/04 20:26:33][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:26:33][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:26:33][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:26:33][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:33][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:26:33][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:33][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:26:33][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003477 seconds.
[12/04 20:26:33][INFO] logging.py:  96: json_stats: {"RAM": "2.40/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/04 20:26:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.29808, "dt_data": 0.76188, "dt_net": 0.53620, "eta": "0:00:01", "loss": 0.92406, "lr": 0.10000, "mode": "train"}
[12/04 20:26:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.30218, "dt_data": 0.76608, "dt_net": 0.53609, "eta": "0:00:01", "loss": 0.72614, "lr": 0.10000, "mode": "train"}
[12/04 20:26:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.30190, "dt_data": 0.76583, "dt_net": 0.53608, "eta": "0:00:01", "loss": 0.69231, "lr": 0.10000, "mode": "train"}
[12/04 20:26:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.30176, "dt_data": 0.76582, "dt_net": 0.53593, "eta": "0:00:01", "loss": 0.42325, "lr": 0.10000, "mode": "train"}
[12/04 20:26:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.30501, "dt_data": 0.76864, "dt_net": 0.53637, "eta": "0:00:01", "loss": 0.81549, "lr": 0.10000, "mode": "train"}
[12/04 20:26:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.85249, "dt_data": 0.77890, "dt_net": 0.07358, "eta": "0:00:00", "mode": "val"}
[12/04 20:26:41][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:26:41][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:26:41][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:26:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:41][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:26:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:41][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:26:41][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003054 seconds.
[12/04 20:26:41][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.88591, "mode": "val"}
[12/04 20:26:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.29964, "dt_data": 0.76340, "dt_net": 0.53624, "eta": "0:00:01", "loss": 2.65446, "lr": 0.01000, "mode": "train"}
[12/04 20:26:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.30142, "dt_data": 0.76542, "dt_net": 0.53599, "eta": "0:00:01", "loss": 0.85896, "lr": 0.01000, "mode": "train"}
[12/04 20:26:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.30137, "dt_data": 0.76542, "dt_net": 0.53595, "eta": "0:00:01", "loss": 0.48799, "lr": 0.01000, "mode": "train"}
[12/04 20:26:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.29737, "dt_data": 0.76149, "dt_net": 0.53588, "eta": "0:00:01", "loss": 0.36430, "lr": 0.01000, "mode": "train"}
[12/04 20:26:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.30111, "dt_data": 0.76498, "dt_net": 0.53613, "eta": "0:00:01", "loss": 0.30639, "lr": 0.01000, "mode": "train"}
[12/04 20:26:50][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.86312, "dt_data": 0.78961, "dt_net": 0.07350, "eta": "0:00:00", "mode": "val"}
[12/04 20:26:50][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:26:50][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:26:50][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:26:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:50][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:26:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:50][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:26:50][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003095 seconds.
[12/04 20:26:50][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.64603, "mode": "val"}
[12/04 20:26:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.30163, "dt_data": 0.76542, "dt_net": 0.53621, "eta": "0:00:01", "loss": 0.34808, "lr": 0.00100, "mode": "train"}
[12/04 20:26:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.29865, "dt_data": 0.76216, "dt_net": 0.53649, "eta": "0:00:01", "loss": 0.31635, "lr": 0.00100, "mode": "train"}
[12/04 20:26:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.30248, "dt_data": 0.76628, "dt_net": 0.53619, "eta": "0:00:01", "loss": 0.32031, "lr": 0.00100, "mode": "train"}
[12/04 20:26:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.30198, "dt_data": 0.76592, "dt_net": 0.53605, "eta": "0:00:01", "loss": 0.31132, "lr": 0.00100, "mode": "train"}
[12/04 20:26:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.30301, "dt_data": 0.76664, "dt_net": 0.53637, "eta": "0:00:01", "loss": 0.32460, "lr": 0.00100, "mode": "train"}
[12/04 20:26:58][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.86895, "dt_data": 0.79534, "dt_net": 0.07361, "eta": "0:00:00", "mode": "val"}
[12/04 20:26:58][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:26:58][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:26:58][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:26:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:58][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:26:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:26:58][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:26:58][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003000 seconds.
[12/04 20:26:58][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.62006, "mode": "val"}
[12/04 20:27:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "21", "cur_iter": "1", "dt": 1.30138, "dt_data": 0.76431, "dt_net": 0.53707, "eta": "0:00:01", "loss": 0.28568, "lr": 0.00010, "mode": "train"}
[12/04 20:27:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "22", "cur_iter": "1", "dt": 1.30689, "dt_data": 0.76807, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.31057, "lr": 0.00010, "mode": "train"}
[12/04 20:27:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "23", "cur_iter": "1", "dt": 1.30761, "dt_data": 0.76877, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.29460, "lr": 0.00010, "mode": "train"}
[12/04 20:27:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "24", "cur_iter": "1", "dt": 1.30597, "dt_data": 0.76737, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.29807, "lr": 0.00010, "mode": "train"}
[12/04 20:27:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 1.30217, "dt_data": 0.76363, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.29653, "lr": 0.00010, "mode": "train"}
[12/04 20:27:07][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 0.87011, "dt_data": 0.79618, "dt_net": 0.07392, "eta": "0:00:00", "mode": "val"}
[12/04 20:27:07][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:27:07][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:27:07][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:27:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:07][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:27:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:07][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:27:07][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003168 seconds.
[12/04 20:27:07][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "25", "gpu_mem": "1.74G", "map": 0.66180, "mode": "val"}
[12/04 20:27:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "26", "cur_iter": "1", "dt": 1.30601, "dt_data": 0.76732, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.29391, "lr": 0.00010, "mode": "train"}
[12/04 20:27:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "27", "cur_iter": "1", "dt": 1.30448, "dt_data": 0.76556, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.29542, "lr": 0.00010, "mode": "train"}
[12/04 20:27:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "28", "cur_iter": "1", "dt": 1.30871, "dt_data": 0.76936, "dt_net": 0.53934, "eta": "0:00:01", "loss": 0.29295, "lr": 0.00010, "mode": "train"}
[12/04 20:27:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "29", "cur_iter": "1", "dt": 1.30716, "dt_data": 0.76863, "dt_net": 0.53852, "eta": "0:00:01", "loss": 0.29461, "lr": 0.00010, "mode": "train"}
[12/04 20:27:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.30244, "dt_data": 0.76354, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.27668, "lr": 0.00010, "mode": "train"}
[12/04 20:27:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 0.86135, "dt_data": 0.78749, "dt_net": 0.07385, "eta": "0:00:00", "mode": "val"}
[12/04 20:27:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:27:15][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:27:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:27:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:27:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:15][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:27:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003110 seconds.
[12/04 20:27:15][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "30", "gpu_mem": "1.74G", "map": 0.64513, "mode": "val"}
[12/04 20:27:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "31", "cur_iter": "1", "dt": 1.30325, "dt_data": 0.76433, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.28170, "lr": 0.00010, "mode": "train"}
[12/04 20:27:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "32", "cur_iter": "1", "dt": 1.30257, "dt_data": 0.76398, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.29166, "lr": 0.00010, "mode": "train"}
[12/04 20:27:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "33", "cur_iter": "1", "dt": 1.30289, "dt_data": 0.76466, "dt_net": 0.53822, "eta": "0:00:01", "loss": 0.30586, "lr": 0.00010, "mode": "train"}
[12/04 20:27:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "34", "cur_iter": "1", "dt": 1.30479, "dt_data": 0.76611, "dt_net": 0.53867, "eta": "0:00:01", "loss": 0.28678, "lr": 0.00010, "mode": "train"}
[12/04 20:27:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 1.30210, "dt_data": 0.76360, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.29831, "lr": 0.00010, "mode": "train"}
[12/04 20:27:24][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 0.86723, "dt_data": 0.79341, "dt_net": 0.07382, "eta": "0:00:00", "mode": "val"}
[12/04 20:27:24][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:27:24][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:27:24][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:27:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:24][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:27:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:24][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:27:24][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003219 seconds.
[12/04 20:27:24][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "35", "gpu_mem": "1.74G", "map": 0.66786, "mode": "val"}
[12/04 20:27:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "36", "cur_iter": "1", "dt": 1.30146, "dt_data": 0.76300, "dt_net": 0.53845, "eta": "0:00:01", "loss": 0.27103, "lr": 0.00010, "mode": "train"}
[12/04 20:27:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "37", "cur_iter": "1", "dt": 1.30180, "dt_data": 0.76296, "dt_net": 0.53883, "eta": "0:00:01", "loss": 0.30759, "lr": 0.00010, "mode": "train"}
[12/04 20:27:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "38", "cur_iter": "1", "dt": 1.30567, "dt_data": 0.76648, "dt_net": 0.53919, "eta": "0:00:01", "loss": 0.30965, "lr": 0.00010, "mode": "train"}
[12/04 20:27:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "39", "cur_iter": "1", "dt": 1.30136, "dt_data": 0.76312, "dt_net": 0.53824, "eta": "0:00:01", "loss": 0.28347, "lr": 0.00010, "mode": "train"}
[12/04 20:27:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 1.30360, "dt_data": 0.76468, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.28679, "lr": 0.00010, "mode": "train"}
[12/04 20:27:32][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 0.87178, "dt_data": 0.79789, "dt_net": 0.07388, "eta": "0:00:00", "mode": "val"}
[12/04 20:27:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:27:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:27:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:27:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:27:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:27:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003005 seconds.
[12/04 20:27:32][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "40", "gpu_mem": "1.74G", "map": 0.58263, "mode": "val"}
[12/04 20:27:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "41", "cur_iter": "1", "dt": 1.30469, "dt_data": 0.76599, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.27891, "lr": 0.00010, "mode": "train"}
[12/04 20:27:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "42", "cur_iter": "1", "dt": 1.30131, "dt_data": 0.76256, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.30521, "lr": 0.00010, "mode": "train"}
[12/04 20:27:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "43", "cur_iter": "1", "dt": 1.30370, "dt_data": 0.76475, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.29240, "lr": 0.00010, "mode": "train"}
[12/04 20:27:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "44", "cur_iter": "1", "dt": 1.30530, "dt_data": 0.76610, "dt_net": 0.53919, "eta": "0:00:01", "loss": 0.31800, "lr": 0.00010, "mode": "train"}
[12/04 20:27:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 1.30710, "dt_data": 0.76730, "dt_net": 0.53980, "eta": "0:00:01", "loss": 0.29374, "lr": 0.00010, "mode": "train"}
[12/04 20:27:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 0.87506, "dt_data": 0.80102, "dt_net": 0.07403, "eta": "0:00:00", "mode": "val"}
[12/04 20:27:41][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:27:41][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:27:41][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:27:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:41][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:27:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:41][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:27:41][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003027 seconds.
[12/04 20:27:41][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "45", "gpu_mem": "1.74G", "map": 0.57354, "mode": "val"}
[12/04 20:27:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "46", "cur_iter": "1", "dt": 1.31103, "dt_data": 0.77093, "dt_net": 0.54011, "eta": "0:00:01", "loss": 0.28242, "lr": 0.00010, "mode": "train"}
[12/04 20:27:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "47", "cur_iter": "1", "dt": 1.30457, "dt_data": 0.76417, "dt_net": 0.54040, "eta": "0:00:01", "loss": 0.29390, "lr": 0.00010, "mode": "train"}
[12/04 20:27:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "48", "cur_iter": "1", "dt": 1.30500, "dt_data": 0.76423, "dt_net": 0.54077, "eta": "0:00:01", "loss": 0.28954, "lr": 0.00010, "mode": "train"}
[12/04 20:27:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "49", "cur_iter": "1", "dt": 1.30760, "dt_data": 0.76734, "dt_net": 0.54026, "eta": "0:00:01", "loss": 0.28541, "lr": 0.00010, "mode": "train"}
[12/04 20:27:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 1.30467, "dt_data": 0.76391, "dt_net": 0.54076, "eta": "0:00:01", "loss": 0.28547, "lr": 0.00010, "mode": "train"}
[12/04 20:27:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 0.84703, "dt_data": 0.77291, "dt_net": 0.07412, "eta": "0:00:00", "mode": "val"}
[12/04 20:27:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:27:49][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:27:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:27:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:27:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:49][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:27:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002978 seconds.
[12/04 20:27:49][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "50", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:27:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "51", "cur_iter": "1", "dt": 1.30551, "dt_data": 0.76687, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.28218, "lr": 0.00010, "mode": "train"}
[12/04 20:27:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "52", "cur_iter": "1", "dt": 1.30083, "dt_data": 0.76260, "dt_net": 0.53823, "eta": "0:00:01", "loss": 0.28711, "lr": 0.00010, "mode": "train"}
[12/04 20:27:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "53", "cur_iter": "1", "dt": 1.30371, "dt_data": 0.76522, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.27256, "lr": 0.00010, "mode": "train"}
[12/04 20:27:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "54", "cur_iter": "1", "dt": 1.30190, "dt_data": 0.76286, "dt_net": 0.53904, "eta": "0:00:01", "loss": 0.28594, "lr": 0.00010, "mode": "train"}
[12/04 20:27:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 1.30331, "dt_data": 0.76482, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.28222, "lr": 0.00010, "mode": "train"}
[12/04 20:27:58][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 0.87612, "dt_data": 0.80202, "dt_net": 0.07410, "eta": "0:00:00", "mode": "val"}
[12/04 20:27:58][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:27:58][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:27:58][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:27:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:58][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:27:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:27:58][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:27:58][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003066 seconds.
[12/04 20:27:58][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "55", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:27:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "56", "cur_iter": "1", "dt": 1.30676, "dt_data": 0.76798, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.29341, "lr": 0.00010, "mode": "train"}
[12/04 20:28:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "57", "cur_iter": "1", "dt": 1.30275, "dt_data": 0.76383, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.27743, "lr": 0.00010, "mode": "train"}
[12/04 20:28:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "58", "cur_iter": "1", "dt": 1.30426, "dt_data": 0.76523, "dt_net": 0.53903, "eta": "0:00:01", "loss": 0.27838, "lr": 0.00010, "mode": "train"}
[12/04 20:28:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "59", "cur_iter": "1", "dt": 1.30292, "dt_data": 0.76426, "dt_net": 0.53865, "eta": "0:00:01", "loss": 0.28041, "lr": 0.00010, "mode": "train"}
[12/04 20:28:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 1.30542, "dt_data": 0.76631, "dt_net": 0.53911, "eta": "0:00:01", "loss": 0.28494, "lr": 0.00010, "mode": "train"}
[12/04 20:28:06][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 0.84927, "dt_data": 0.77550, "dt_net": 0.07377, "eta": "0:00:00", "mode": "val"}
[12/04 20:28:06][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:28:06][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:28:06][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:28:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:06][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:28:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:06][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:28:06][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003144 seconds.
[12/04 20:28:06][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "60", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:28:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "61", "cur_iter": "1", "dt": 1.30665, "dt_data": 0.76749, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.28242, "lr": 0.00010, "mode": "train"}
[12/04 20:28:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "62", "cur_iter": "1", "dt": 1.30675, "dt_data": 0.76832, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.29414, "lr": 0.00010, "mode": "train"}
[12/04 20:28:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "63", "cur_iter": "1", "dt": 1.30246, "dt_data": 0.76382, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.28382, "lr": 0.00010, "mode": "train"}
[12/04 20:28:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "64", "cur_iter": "1", "dt": 1.32749, "dt_data": 0.78854, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.30564, "lr": 0.00010, "mode": "train"}
[12/04 20:28:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 1.30765, "dt_data": 0.76901, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.29869, "lr": 0.00010, "mode": "train"}
[12/04 20:28:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 0.87121, "dt_data": 0.79705, "dt_net": 0.07416, "eta": "0:00:00", "mode": "val"}
[12/04 20:28:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:28:15][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:28:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:28:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:28:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:15][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:28:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002870 seconds.
[12/04 20:28:15][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "65", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:28:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "66", "cur_iter": "1", "dt": 1.31295, "dt_data": 0.77404, "dt_net": 0.53890, "eta": "0:00:01", "loss": 0.27807, "lr": 0.00010, "mode": "train"}
[12/04 20:28:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "67", "cur_iter": "1", "dt": 1.30574, "dt_data": 0.76686, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.28032, "lr": 0.00010, "mode": "train"}
[12/04 20:28:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "68", "cur_iter": "1", "dt": 1.30680, "dt_data": 0.76823, "dt_net": 0.53856, "eta": "0:00:01", "loss": 0.29186, "lr": 0.00010, "mode": "train"}
[12/04 20:28:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "69", "cur_iter": "1", "dt": 1.30056, "dt_data": 0.76235, "dt_net": 0.53821, "eta": "0:00:01", "loss": 0.29210, "lr": 0.00010, "mode": "train"}
[12/04 20:28:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 1.30428, "dt_data": 0.76549, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.29157, "lr": 0.00010, "mode": "train"}
[12/04 20:28:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 0.86579, "dt_data": 0.79200, "dt_net": 0.07378, "eta": "0:00:00", "mode": "val"}
[12/04 20:28:24][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:28:24][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:28:24][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:28:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:24][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:28:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:24][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:28:24][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003127 seconds.
[12/04 20:28:24][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "70", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:28:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "71", "cur_iter": "1", "dt": 1.32821, "dt_data": 0.78862, "dt_net": 0.53959, "eta": "0:00:01", "loss": 0.29681, "lr": 0.00010, "mode": "train"}
[12/04 20:28:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "72", "cur_iter": "1", "dt": 1.30112, "dt_data": 0.76294, "dt_net": 0.53818, "eta": "0:00:01", "loss": 0.27391, "lr": 0.00010, "mode": "train"}
[12/04 20:28:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "73", "cur_iter": "1", "dt": 1.30328, "dt_data": 0.76434, "dt_net": 0.53894, "eta": "0:00:01", "loss": 0.30442, "lr": 0.00010, "mode": "train"}
[12/04 20:28:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "74", "cur_iter": "1", "dt": 1.30434, "dt_data": 0.76562, "dt_net": 0.53871, "eta": "0:00:01", "loss": 0.27922, "lr": 0.00010, "mode": "train"}
[12/04 20:28:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 1.30835, "dt_data": 0.76958, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27664, "lr": 0.00010, "mode": "train"}
[12/04 20:28:32][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 0.85597, "dt_data": 0.78218, "dt_net": 0.07378, "eta": "0:00:00", "mode": "val"}
[12/04 20:28:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:28:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:28:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:28:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:28:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:28:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003165 seconds.
[12/04 20:28:32][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "75", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:28:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "76", "cur_iter": "1", "dt": 1.30476, "dt_data": 0.76608, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.30506, "lr": 0.00010, "mode": "train"}
[12/04 20:28:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "77", "cur_iter": "1", "dt": 1.30359, "dt_data": 0.76463, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.27730, "lr": 0.00010, "mode": "train"}
[12/04 20:28:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "78", "cur_iter": "1", "dt": 1.30180, "dt_data": 0.76343, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.29431, "lr": 0.00010, "mode": "train"}
[12/04 20:28:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "79", "cur_iter": "1", "dt": 1.30190, "dt_data": 0.76330, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.28052, "lr": 0.00010, "mode": "train"}
[12/04 20:28:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 1.30329, "dt_data": 0.76448, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.27714, "lr": 0.00010, "mode": "train"}
[12/04 20:28:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 0.87295, "dt_data": 0.79861, "dt_net": 0.07433, "eta": "0:00:00", "mode": "val"}
[12/04 20:28:41][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:28:41][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:28:41][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:28:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:41][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:28:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:41][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:28:41][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003006 seconds.
[12/04 20:28:41][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "80", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:28:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "81", "cur_iter": "1", "dt": 1.31045, "dt_data": 0.77148, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27989, "lr": 0.00010, "mode": "train"}
[12/04 20:28:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "82", "cur_iter": "1", "dt": 1.30369, "dt_data": 0.76525, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.27239, "lr": 0.00010, "mode": "train"}
[12/04 20:28:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "83", "cur_iter": "1", "dt": 1.30386, "dt_data": 0.76522, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.28054, "lr": 0.00010, "mode": "train"}
[12/04 20:28:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "84", "cur_iter": "1", "dt": 1.30378, "dt_data": 0.76503, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27811, "lr": 0.00010, "mode": "train"}
[12/04 20:28:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 1.30743, "dt_data": 0.76896, "dt_net": 0.53847, "eta": "0:00:01", "loss": 0.27757, "lr": 0.00010, "mode": "train"}
[12/04 20:28:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 0.87138, "dt_data": 0.79747, "dt_net": 0.07390, "eta": "0:00:00", "mode": "val"}
[12/04 20:28:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:28:49][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:28:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:28:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:28:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:49][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:28:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003211 seconds.
[12/04 20:28:49][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "85", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:28:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "86", "cur_iter": "1", "dt": 1.32339, "dt_data": 0.78453, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27090, "lr": 0.00010, "mode": "train"}
[12/04 20:28:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "87", "cur_iter": "1", "dt": 1.34468, "dt_data": 0.80552, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.27566, "lr": 0.00010, "mode": "train"}
[12/04 20:28:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "88", "cur_iter": "1", "dt": 1.30462, "dt_data": 0.76581, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.27364, "lr": 0.00010, "mode": "train"}
[12/04 20:28:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "89", "cur_iter": "1", "dt": 1.30701, "dt_data": 0.76826, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27977, "lr": 0.00010, "mode": "train"}
[12/04 20:28:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 1.30571, "dt_data": 0.76682, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.28567, "lr": 0.00010, "mode": "train"}
[12/04 20:28:58][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 0.86808, "dt_data": 0.79432, "dt_net": 0.07376, "eta": "0:00:00", "mode": "val"}
[12/04 20:28:58][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:28:58][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:28:58][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:28:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:58][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:28:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:28:58][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:28:58][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003076 seconds.
[12/04 20:28:58][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "90", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:28:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "91", "cur_iter": "1", "dt": 1.30552, "dt_data": 0.76669, "dt_net": 0.53883, "eta": "0:00:01", "loss": 0.28614, "lr": 0.00010, "mode": "train"}
[12/04 20:29:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "92", "cur_iter": "1", "dt": 1.30461, "dt_data": 0.76608, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.28159, "lr": 0.00010, "mode": "train"}
[12/04 20:29:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "93", "cur_iter": "1", "dt": 1.30438, "dt_data": 0.76554, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.27526, "lr": 0.00010, "mode": "train"}
[12/04 20:29:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "94", "cur_iter": "1", "dt": 1.30644, "dt_data": 0.76790, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.28042, "lr": 0.00010, "mode": "train"}
[12/04 20:29:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 1.30346, "dt_data": 0.76494, "dt_net": 0.53852, "eta": "0:00:01", "loss": 0.27936, "lr": 0.00010, "mode": "train"}
[12/04 20:29:06][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 0.87450, "dt_data": 0.80073, "dt_net": 0.07376, "eta": "0:00:00", "mode": "val"}
[12/04 20:29:06][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:29:06][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:29:06][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:29:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:06][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:29:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:06][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:29:06][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003072 seconds.
[12/04 20:29:06][INFO] logging.py:  96: json_stats: {"RAM": "2.57/15.59G", "_type": "val_epoch", "cur_epoch": "95", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:29:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "96", "cur_iter": "1", "dt": 1.30523, "dt_data": 0.76634, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.27842, "lr": 0.00010, "mode": "train"}
[12/04 20:29:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "97", "cur_iter": "1", "dt": 1.31989, "dt_data": 0.78106, "dt_net": 0.53883, "eta": "0:00:01", "loss": 0.28211, "lr": 0.00010, "mode": "train"}
[12/04 20:29:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "98", "cur_iter": "1", "dt": 1.30734, "dt_data": 0.76818, "dt_net": 0.53915, "eta": "0:00:01", "loss": 0.27962, "lr": 0.00010, "mode": "train"}
[12/04 20:29:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "99", "cur_iter": "1", "dt": 1.30275, "dt_data": 0.76397, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.28270, "lr": 0.00010, "mode": "train"}
[12/04 20:29:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 1.30373, "dt_data": 0.76487, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27802, "lr": 0.00010, "mode": "train"}
[12/04 20:29:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 0.86938, "dt_data": 0.79542, "dt_net": 0.07396, "eta": "0:00:00", "mode": "val"}
[12/04 20:29:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:29:15][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:29:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:29:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:29:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:15][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:29:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003073 seconds.
[12/04 20:29:15][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "100", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:29:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "101", "cur_iter": "1", "dt": 1.30482, "dt_data": 0.76619, "dt_net": 0.53863, "eta": "0:00:01", "loss": 0.27789, "lr": 0.00010, "mode": "train"}
[12/04 20:29:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "102", "cur_iter": "1", "dt": 1.30364, "dt_data": 0.76511, "dt_net": 0.53852, "eta": "0:00:01", "loss": 0.27276, "lr": 0.00010, "mode": "train"}
[12/04 20:29:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "103", "cur_iter": "1", "dt": 1.30765, "dt_data": 0.76884, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.28379, "lr": 0.00010, "mode": "train"}
[12/04 20:29:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "104", "cur_iter": "1", "dt": 1.30650, "dt_data": 0.76799, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.27801, "lr": 0.00010, "mode": "train"}
[12/04 20:29:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 1.30412, "dt_data": 0.76498, "dt_net": 0.53913, "eta": "0:00:01", "loss": 0.28340, "lr": 0.00010, "mode": "train"}
[12/04 20:29:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 0.86852, "dt_data": 0.79470, "dt_net": 0.07382, "eta": "0:00:00", "mode": "val"}
[12/04 20:29:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:29:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:29:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:29:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:29:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:29:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003117 seconds.
[12/04 20:29:23][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "105", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:29:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "106", "cur_iter": "1", "dt": 1.30688, "dt_data": 0.76798, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.28234, "lr": 0.00010, "mode": "train"}
[12/04 20:29:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "107", "cur_iter": "1", "dt": 1.30355, "dt_data": 0.76443, "dt_net": 0.53912, "eta": "0:00:01", "loss": 0.29960, "lr": 0.00010, "mode": "train"}
[12/04 20:29:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "108", "cur_iter": "1", "dt": 1.30926, "dt_data": 0.77108, "dt_net": 0.53819, "eta": "0:00:01", "loss": 0.27567, "lr": 0.00010, "mode": "train"}
[12/04 20:29:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "109", "cur_iter": "1", "dt": 1.30352, "dt_data": 0.76476, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27013, "lr": 0.00010, "mode": "train"}
[12/04 20:29:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 1.30484, "dt_data": 0.76635, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.27222, "lr": 0.00010, "mode": "train"}
[12/04 20:29:32][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 0.86977, "dt_data": 0.79596, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/04 20:29:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:29:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:29:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:29:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:29:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:29:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003071 seconds.
[12/04 20:29:32][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "110", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:29:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "111", "cur_iter": "1", "dt": 1.30403, "dt_data": 0.76587, "dt_net": 0.53817, "eta": "0:00:01", "loss": 0.27634, "lr": 0.00010, "mode": "train"}
[12/04 20:29:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "112", "cur_iter": "1", "dt": 1.30349, "dt_data": 0.76443, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.27478, "lr": 0.00010, "mode": "train"}
[12/04 20:29:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "113", "cur_iter": "1", "dt": 1.30344, "dt_data": 0.76451, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.28402, "lr": 0.00010, "mode": "train"}
[12/04 20:29:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "114", "cur_iter": "1", "dt": 1.30226, "dt_data": 0.76395, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.27134, "lr": 0.00010, "mode": "train"}
[12/04 20:29:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 1.30358, "dt_data": 0.76431, "dt_net": 0.53927, "eta": "0:00:01", "loss": 0.28600, "lr": 0.00010, "mode": "train"}
[12/04 20:29:40][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 0.86577, "dt_data": 0.79192, "dt_net": 0.07384, "eta": "0:00:00", "mode": "val"}
[12/04 20:29:40][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:29:40][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:29:40][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:29:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:40][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:29:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:40][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:29:40][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002879 seconds.
[12/04 20:29:40][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "115", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:29:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "116", "cur_iter": "1", "dt": 1.30363, "dt_data": 0.76483, "dt_net": 0.53880, "eta": "0:00:01", "loss": 0.31793, "lr": 0.00010, "mode": "train"}
[12/04 20:29:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "117", "cur_iter": "1", "dt": 1.30370, "dt_data": 0.76538, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.28320, "lr": 0.00010, "mode": "train"}
[12/04 20:29:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "118", "cur_iter": "1", "dt": 1.30347, "dt_data": 0.76463, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.26895, "lr": 0.00010, "mode": "train"}
[12/04 20:29:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "119", "cur_iter": "1", "dt": 1.30236, "dt_data": 0.76352, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.28677, "lr": 0.00010, "mode": "train"}
[12/04 20:29:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 1.30296, "dt_data": 0.76455, "dt_net": 0.53841, "eta": "0:00:01", "loss": 0.28646, "lr": 0.00010, "mode": "train"}
[12/04 20:29:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 0.86786, "dt_data": 0.79400, "dt_net": 0.07386, "eta": "0:00:00", "mode": "val"}
[12/04 20:29:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:29:49][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:29:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:29:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:29:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:49][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:29:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002815 seconds.
[12/04 20:29:49][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "120", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:29:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "121", "cur_iter": "1", "dt": 1.30406, "dt_data": 0.76566, "dt_net": 0.53840, "eta": "0:00:01", "loss": 0.27388, "lr": 0.00010, "mode": "train"}
[12/04 20:29:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "122", "cur_iter": "1", "dt": 1.30410, "dt_data": 0.76551, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.27326, "lr": 0.00010, "mode": "train"}
[12/04 20:29:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "123", "cur_iter": "1", "dt": 1.30335, "dt_data": 0.76468, "dt_net": 0.53867, "eta": "0:00:01", "loss": 0.27066, "lr": 0.00010, "mode": "train"}
[12/04 20:29:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "124", "cur_iter": "1", "dt": 1.30314, "dt_data": 0.76448, "dt_net": 0.53866, "eta": "0:00:01", "loss": 0.27880, "lr": 0.00010, "mode": "train"}
[12/04 20:29:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 1.30507, "dt_data": 0.76620, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27782, "lr": 0.00010, "mode": "train"}
[12/04 20:29:58][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 0.86473, "dt_data": 0.79047, "dt_net": 0.07426, "eta": "0:00:00", "mode": "val"}
[12/04 20:29:58][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:29:58][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:29:58][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:29:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:58][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:29:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:29:58][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:29:58][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003013 seconds.
[12/04 20:29:58][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "125", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:29:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "126", "cur_iter": "1", "dt": 1.30661, "dt_data": 0.76752, "dt_net": 0.53909, "eta": "0:00:01", "loss": 0.27547, "lr": 0.00010, "mode": "train"}
[12/04 20:30:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "127", "cur_iter": "1", "dt": 1.30465, "dt_data": 0.76610, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.28082, "lr": 0.00010, "mode": "train"}
[12/04 20:30:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "128", "cur_iter": "1", "dt": 1.30395, "dt_data": 0.76511, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.28171, "lr": 0.00010, "mode": "train"}
[12/04 20:30:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "129", "cur_iter": "1", "dt": 1.30255, "dt_data": 0.76368, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27742, "lr": 0.00010, "mode": "train"}
[12/04 20:30:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 1.30316, "dt_data": 0.76480, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27329, "lr": 0.00010, "mode": "train"}
[12/04 20:30:06][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 0.86835, "dt_data": 0.79454, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/04 20:30:06][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:30:06][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:30:06][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:30:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:06][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:30:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:06][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:30:06][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002947 seconds.
[12/04 20:30:06][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "130", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:30:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "131", "cur_iter": "1", "dt": 1.30557, "dt_data": 0.76720, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27211, "lr": 0.00010, "mode": "train"}
[12/04 20:30:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "132", "cur_iter": "1", "dt": 1.30388, "dt_data": 0.76508, "dt_net": 0.53880, "eta": "0:00:01", "loss": 0.27343, "lr": 0.00010, "mode": "train"}
[12/04 20:30:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "133", "cur_iter": "1", "dt": 1.30277, "dt_data": 0.76429, "dt_net": 0.53847, "eta": "0:00:01", "loss": 0.27505, "lr": 0.00010, "mode": "train"}
[12/04 20:30:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "134", "cur_iter": "1", "dt": 1.30665, "dt_data": 0.76764, "dt_net": 0.53901, "eta": "0:00:01", "loss": 0.28969, "lr": 0.00010, "mode": "train"}
[12/04 20:30:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 1.30457, "dt_data": 0.76531, "dt_net": 0.53925, "eta": "0:00:01", "loss": 0.27370, "lr": 0.00010, "mode": "train"}
[12/04 20:30:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 0.87065, "dt_data": 0.79671, "dt_net": 0.07393, "eta": "0:00:00", "mode": "val"}
[12/04 20:30:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:30:15][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:30:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:30:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:30:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:15][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:30:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003072 seconds.
[12/04 20:30:15][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "135", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:30:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "136", "cur_iter": "1", "dt": 1.30537, "dt_data": 0.76667, "dt_net": 0.53870, "eta": "0:00:01", "loss": 0.27658, "lr": 0.00010, "mode": "train"}
[12/04 20:30:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "137", "cur_iter": "1", "dt": 1.30404, "dt_data": 0.76536, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.27594, "lr": 0.00010, "mode": "train"}
[12/04 20:30:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "138", "cur_iter": "1", "dt": 1.30372, "dt_data": 0.76495, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27749, "lr": 0.00010, "mode": "train"}
[12/04 20:30:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "139", "cur_iter": "1", "dt": 1.30237, "dt_data": 0.76351, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.28345, "lr": 0.00010, "mode": "train"}
[12/04 20:30:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 1.30230, "dt_data": 0.76389, "dt_net": 0.53841, "eta": "0:00:01", "loss": 0.28250, "lr": 0.00010, "mode": "train"}
[12/04 20:30:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 0.85720, "dt_data": 0.78339, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/04 20:30:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:30:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:30:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:30:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:30:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:30:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002955 seconds.
[12/04 20:30:23][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "140", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:30:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "141", "cur_iter": "1", "dt": 1.30590, "dt_data": 0.76718, "dt_net": 0.53872, "eta": "0:00:01", "loss": 0.27971, "lr": 0.00010, "mode": "train"}
[12/04 20:30:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "142", "cur_iter": "1", "dt": 1.30426, "dt_data": 0.76543, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.27945, "lr": 0.00010, "mode": "train"}
[12/04 20:30:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "143", "cur_iter": "1", "dt": 1.30736, "dt_data": 0.76879, "dt_net": 0.53856, "eta": "0:00:01", "loss": 0.27546, "lr": 0.00010, "mode": "train"}
[12/04 20:30:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "144", "cur_iter": "1", "dt": 1.30311, "dt_data": 0.76430, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.27689, "lr": 0.00010, "mode": "train"}
[12/04 20:30:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 1.30319, "dt_data": 0.76439, "dt_net": 0.53880, "eta": "0:00:01", "loss": 0.27201, "lr": 0.00010, "mode": "train"}
[12/04 20:30:32][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 0.86743, "dt_data": 0.79354, "dt_net": 0.07388, "eta": "0:00:00", "mode": "val"}
[12/04 20:30:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:30:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:30:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:30:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:30:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:30:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003000 seconds.
[12/04 20:30:32][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "145", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:30:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "146", "cur_iter": "1", "dt": 1.30648, "dt_data": 0.76752, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.28870, "lr": 0.00010, "mode": "train"}
[12/04 20:30:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "147", "cur_iter": "1", "dt": 1.30421, "dt_data": 0.76564, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.28361, "lr": 0.00010, "mode": "train"}
[12/04 20:30:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "148", "cur_iter": "1", "dt": 1.30389, "dt_data": 0.76512, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27732, "lr": 0.00010, "mode": "train"}
[12/04 20:30:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "149", "cur_iter": "1", "dt": 1.30677, "dt_data": 0.76825, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.26734, "lr": 0.00010, "mode": "train"}
[12/04 20:30:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 1.30407, "dt_data": 0.76570, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.28558, "lr": 0.00010, "mode": "train"}
[12/04 20:30:40][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 0.87094, "dt_data": 0.79715, "dt_net": 0.07378, "eta": "0:00:00", "mode": "val"}
[12/04 20:30:40][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:30:40][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:30:40][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:30:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:40][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:30:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:40][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:30:40][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003025 seconds.
[12/04 20:30:40][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "150", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:30:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "151", "cur_iter": "1", "dt": 1.30611, "dt_data": 0.76735, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.29187, "lr": 0.00010, "mode": "train"}
[12/04 20:30:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "152", "cur_iter": "1", "dt": 1.30395, "dt_data": 0.76505, "dt_net": 0.53890, "eta": "0:00:01", "loss": 0.27698, "lr": 0.00010, "mode": "train"}
[12/04 20:30:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "153", "cur_iter": "1", "dt": 1.30604, "dt_data": 0.76721, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.28599, "lr": 0.00010, "mode": "train"}
[12/04 20:30:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "154", "cur_iter": "1", "dt": 1.30391, "dt_data": 0.76523, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.27502, "lr": 0.00010, "mode": "train"}
[12/04 20:30:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 1.30358, "dt_data": 0.76476, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.27323, "lr": 0.00010, "mode": "train"}
[12/04 20:30:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 0.86328, "dt_data": 0.78925, "dt_net": 0.07403, "eta": "0:00:00", "mode": "val"}
[12/04 20:30:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:30:49][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:30:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:30:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:30:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:49][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:30:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003099 seconds.
[12/04 20:30:49][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "155", "gpu_mem": "1.74G", "map": 0.56104, "mode": "val"}
[12/04 20:30:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "156", "cur_iter": "1", "dt": 1.30551, "dt_data": 0.76666, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.27101, "lr": 0.00010, "mode": "train"}
[12/04 20:30:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "157", "cur_iter": "1", "dt": 1.30291, "dt_data": 0.76441, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.29177, "lr": 0.00010, "mode": "train"}
[12/04 20:30:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "158", "cur_iter": "1", "dt": 1.30343, "dt_data": 0.76423, "dt_net": 0.53919, "eta": "0:00:01", "loss": 0.28505, "lr": 0.00010, "mode": "train"}
[12/04 20:30:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "159", "cur_iter": "1", "dt": 1.30353, "dt_data": 0.76502, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.27475, "lr": 0.00010, "mode": "train"}
[12/04 20:30:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 1.30468, "dt_data": 0.76556, "dt_net": 0.53912, "eta": "0:00:01", "loss": 0.26979, "lr": 0.00010, "mode": "train"}
[12/04 20:30:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 0.86204, "dt_data": 0.78816, "dt_net": 0.07387, "eta": "0:00:00", "mode": "val"}
[12/04 20:30:57][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:30:57][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:30:57][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:30:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:57][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:30:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:30:57][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:30:57][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003026 seconds.
[12/04 20:30:57][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "160", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:30:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "161", "cur_iter": "1", "dt": 1.30639, "dt_data": 0.76751, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.29273, "lr": 0.00010, "mode": "train"}
[12/04 20:31:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "162", "cur_iter": "1", "dt": 1.30365, "dt_data": 0.76477, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.26962, "lr": 0.00010, "mode": "train"}
[12/04 20:31:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "163", "cur_iter": "1", "dt": 1.30819, "dt_data": 0.76964, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.28100, "lr": 0.00010, "mode": "train"}
[12/04 20:31:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "164", "cur_iter": "1", "dt": 1.30606, "dt_data": 0.76714, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.27444, "lr": 0.00010, "mode": "train"}
[12/04 20:31:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 1.30522, "dt_data": 0.76683, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.28246, "lr": 0.00010, "mode": "train"}
[12/04 20:31:06][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 0.86453, "dt_data": 0.79063, "dt_net": 0.07390, "eta": "0:00:00", "mode": "val"}
[12/04 20:31:06][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:31:06][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:31:06][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:31:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:06][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:31:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:06][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:31:06][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003073 seconds.
[12/04 20:31:06][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "165", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:31:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "166", "cur_iter": "1", "dt": 1.30478, "dt_data": 0.76643, "dt_net": 0.53834, "eta": "0:00:01", "loss": 0.27093, "lr": 0.00010, "mode": "train"}
[12/04 20:31:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "167", "cur_iter": "1", "dt": 1.30345, "dt_data": 0.76453, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.27840, "lr": 0.00010, "mode": "train"}
[12/04 20:31:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "168", "cur_iter": "1", "dt": 1.30440, "dt_data": 0.76540, "dt_net": 0.53900, "eta": "0:00:01", "loss": 0.27287, "lr": 0.00010, "mode": "train"}
[12/04 20:31:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "169", "cur_iter": "1", "dt": 1.30562, "dt_data": 0.76726, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.28527, "lr": 0.00010, "mode": "train"}
[12/04 20:31:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 1.30742, "dt_data": 0.76855, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27511, "lr": 0.00010, "mode": "train"}
[12/04 20:31:14][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 0.86960, "dt_data": 0.79578, "dt_net": 0.07381, "eta": "0:00:00", "mode": "val"}
[12/04 20:31:14][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:31:14][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:31:14][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:31:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:14][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:31:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:14][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:31:14][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003026 seconds.
[12/04 20:31:14][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "170", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:31:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "171", "cur_iter": "1", "dt": 1.30881, "dt_data": 0.76960, "dt_net": 0.53921, "eta": "0:00:01", "loss": 0.27696, "lr": 0.00010, "mode": "train"}
[12/04 20:31:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "172", "cur_iter": "1", "dt": 1.30827, "dt_data": 0.76958, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.27548, "lr": 0.00010, "mode": "train"}
[12/04 20:31:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "173", "cur_iter": "1", "dt": 1.30793, "dt_data": 0.76950, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.27090, "lr": 0.00010, "mode": "train"}
[12/04 20:31:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "174", "cur_iter": "1", "dt": 1.30259, "dt_data": 0.76369, "dt_net": 0.53890, "eta": "0:00:01", "loss": 0.26704, "lr": 0.00010, "mode": "train"}
[12/04 20:31:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 1.30656, "dt_data": 0.76787, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.27450, "lr": 0.00010, "mode": "train"}
[12/04 20:31:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 0.87140, "dt_data": 0.79753, "dt_net": 0.07386, "eta": "0:00:00", "mode": "val"}
[12/04 20:31:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:31:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:31:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:31:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:31:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:31:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003052 seconds.
[12/04 20:31:23][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "175", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:31:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "176", "cur_iter": "1", "dt": 1.30584, "dt_data": 0.76698, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.26935, "lr": 0.00010, "mode": "train"}
[12/04 20:31:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "177", "cur_iter": "1", "dt": 1.30392, "dt_data": 0.76490, "dt_net": 0.53901, "eta": "0:00:01", "loss": 0.28543, "lr": 0.00010, "mode": "train"}
[12/04 20:31:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "178", "cur_iter": "1", "dt": 1.30395, "dt_data": 0.76489, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.27056, "lr": 0.00010, "mode": "train"}
[12/04 20:31:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "179", "cur_iter": "1", "dt": 1.30861, "dt_data": 0.76901, "dt_net": 0.53960, "eta": "0:00:01", "loss": 0.28473, "lr": 0.00010, "mode": "train"}
[12/04 20:31:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 1.30933, "dt_data": 0.76868, "dt_net": 0.54065, "eta": "0:00:01", "loss": 0.27135, "lr": 0.00010, "mode": "train"}
[12/04 20:31:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 0.86889, "dt_data": 0.79487, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/04 20:31:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:31:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:31:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:31:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:31:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:31:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002895 seconds.
[12/04 20:31:31][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "180", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:31:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "181", "cur_iter": "1", "dt": 1.30624, "dt_data": 0.76670, "dt_net": 0.53954, "eta": "0:00:01", "loss": 0.28034, "lr": 0.00010, "mode": "train"}
[12/04 20:31:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "182", "cur_iter": "1", "dt": 1.30313, "dt_data": 0.76443, "dt_net": 0.53870, "eta": "0:00:01", "loss": 0.27631, "lr": 0.00010, "mode": "train"}
[12/04 20:31:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "183", "cur_iter": "1", "dt": 1.30331, "dt_data": 0.76485, "dt_net": 0.53846, "eta": "0:00:01", "loss": 0.27547, "lr": 0.00010, "mode": "train"}
[12/04 20:31:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "184", "cur_iter": "1", "dt": 1.30640, "dt_data": 0.76738, "dt_net": 0.53902, "eta": "0:00:01", "loss": 0.27512, "lr": 0.00010, "mode": "train"}
[12/04 20:31:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 1.30300, "dt_data": 0.76413, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27045, "lr": 0.00010, "mode": "train"}
[12/04 20:31:40][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 0.84872, "dt_data": 0.77470, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/04 20:31:40][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:31:40][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:31:40][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:31:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:40][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:31:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:40][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:31:40][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003076 seconds.
[12/04 20:31:40][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "185", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:31:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "186", "cur_iter": "1", "dt": 1.30513, "dt_data": 0.76646, "dt_net": 0.53867, "eta": "0:00:01", "loss": 0.27916, "lr": 0.00010, "mode": "train"}
[12/04 20:31:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "187", "cur_iter": "1", "dt": 1.30323, "dt_data": 0.76399, "dt_net": 0.53923, "eta": "0:00:01", "loss": 0.27639, "lr": 0.00010, "mode": "train"}
[12/04 20:31:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "188", "cur_iter": "1", "dt": 1.30504, "dt_data": 0.76574, "dt_net": 0.53930, "eta": "0:00:01", "loss": 0.28826, "lr": 0.00010, "mode": "train"}
[12/04 20:31:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "189", "cur_iter": "1", "dt": 1.30173, "dt_data": 0.76313, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.27330, "lr": 0.00010, "mode": "train"}
[12/04 20:31:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 1.30841, "dt_data": 0.76930, "dt_net": 0.53911, "eta": "0:00:01", "loss": 0.27066, "lr": 0.00010, "mode": "train"}
[12/04 20:31:48][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 0.86473, "dt_data": 0.79080, "dt_net": 0.07392, "eta": "0:00:00", "mode": "val"}
[12/04 20:31:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:31:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:31:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:31:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:31:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:31:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003062 seconds.
[12/04 20:31:48][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "190", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:31:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "191", "cur_iter": "1", "dt": 1.30594, "dt_data": 0.76723, "dt_net": 0.53871, "eta": "0:00:01", "loss": 0.27473, "lr": 0.00010, "mode": "train"}
[12/04 20:31:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "192", "cur_iter": "1", "dt": 1.30695, "dt_data": 0.76827, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.27575, "lr": 0.00010, "mode": "train"}
[12/04 20:31:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "193", "cur_iter": "1", "dt": 1.30501, "dt_data": 0.76611, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.29500, "lr": 0.00010, "mode": "train"}
[12/04 20:31:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "194", "cur_iter": "1", "dt": 1.30817, "dt_data": 0.76908, "dt_net": 0.53909, "eta": "0:00:01", "loss": 0.27310, "lr": 0.00010, "mode": "train"}
[12/04 20:31:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 1.30354, "dt_data": 0.76496, "dt_net": 0.53858, "eta": "0:00:01", "loss": 0.26823, "lr": 0.00010, "mode": "train"}
[12/04 20:31:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 0.86174, "dt_data": 0.78786, "dt_net": 0.07387, "eta": "0:00:00", "mode": "val"}
[12/04 20:31:57][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:31:57][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:31:57][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:31:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:57][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:31:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:31:57][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:31:57][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003106 seconds.
[12/04 20:31:57][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "195", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:31:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "196", "cur_iter": "1", "dt": 1.30695, "dt_data": 0.76841, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.26772, "lr": 0.00010, "mode": "train"}
[12/04 20:32:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "197", "cur_iter": "1", "dt": 1.30803, "dt_data": 0.76890, "dt_net": 0.53913, "eta": "0:00:01", "loss": 0.27722, "lr": 0.00010, "mode": "train"}
[12/04 20:32:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "198", "cur_iter": "1", "dt": 1.30385, "dt_data": 0.76527, "dt_net": 0.53858, "eta": "0:00:01", "loss": 0.27892, "lr": 0.00010, "mode": "train"}
[12/04 20:32:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "199", "cur_iter": "1", "dt": 1.30677, "dt_data": 0.76812, "dt_net": 0.53865, "eta": "0:00:01", "loss": 0.27109, "lr": 0.00010, "mode": "train"}
[12/04 20:32:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 1.30416, "dt_data": 0.76509, "dt_net": 0.53907, "eta": "0:00:01", "loss": 0.28298, "lr": 0.00010, "mode": "train"}
[12/04 20:32:05][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 0.86454, "dt_data": 0.79078, "dt_net": 0.07376, "eta": "0:00:00", "mode": "val"}
[12/04 20:32:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:32:05][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:32:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:32:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:32:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:05][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:32:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003031 seconds.
[12/04 20:32:05][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "200", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:32:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "201", "cur_iter": "1", "dt": 1.30680, "dt_data": 0.76780, "dt_net": 0.53901, "eta": "0:00:01", "loss": 0.27466, "lr": 0.00010, "mode": "train"}
[12/04 20:32:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "202", "cur_iter": "1", "dt": 1.30305, "dt_data": 0.76451, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.28030, "lr": 0.00010, "mode": "train"}
[12/04 20:32:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "203", "cur_iter": "1", "dt": 1.30359, "dt_data": 0.76474, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.26714, "lr": 0.00010, "mode": "train"}
[12/04 20:32:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "204", "cur_iter": "1", "dt": 1.30381, "dt_data": 0.76504, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.26800, "lr": 0.00010, "mode": "train"}
[12/04 20:32:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 1.30506, "dt_data": 0.76654, "dt_net": 0.53852, "eta": "0:00:01", "loss": 0.27528, "lr": 0.00010, "mode": "train"}
[12/04 20:32:14][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 0.86303, "dt_data": 0.78921, "dt_net": 0.07382, "eta": "0:00:00", "mode": "val"}
[12/04 20:32:14][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:32:14][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:32:14][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:32:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:14][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:32:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:14][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:32:14][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002920 seconds.
[12/04 20:32:14][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "205", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:32:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "206", "cur_iter": "1", "dt": 1.30367, "dt_data": 0.76511, "dt_net": 0.53856, "eta": "0:00:01", "loss": 0.27379, "lr": 0.00010, "mode": "train"}
[12/04 20:32:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "207", "cur_iter": "1", "dt": 1.30321, "dt_data": 0.76440, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.27826, "lr": 0.00010, "mode": "train"}
[12/04 20:32:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "208", "cur_iter": "1", "dt": 1.30322, "dt_data": 0.76446, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27743, "lr": 0.00010, "mode": "train"}
[12/04 20:32:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "209", "cur_iter": "1", "dt": 1.30670, "dt_data": 0.76842, "dt_net": 0.53828, "eta": "0:00:01", "loss": 0.26846, "lr": 0.00010, "mode": "train"}
[12/04 20:32:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 1.30685, "dt_data": 0.76787, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27854, "lr": 0.00010, "mode": "train"}
[12/04 20:32:22][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 0.87322, "dt_data": 0.79879, "dt_net": 0.07442, "eta": "0:00:00", "mode": "val"}
[12/04 20:32:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:32:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:32:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:32:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:32:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:32:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003107 seconds.
[12/04 20:32:23][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "210", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:32:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "211", "cur_iter": "1", "dt": 1.30649, "dt_data": 0.76746, "dt_net": 0.53903, "eta": "0:00:01", "loss": 0.26968, "lr": 0.00010, "mode": "train"}
[12/04 20:32:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "212", "cur_iter": "1", "dt": 1.30626, "dt_data": 0.76749, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27528, "lr": 0.00010, "mode": "train"}
[12/04 20:32:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "213", "cur_iter": "1", "dt": 1.30520, "dt_data": 0.76647, "dt_net": 0.53872, "eta": "0:00:01", "loss": 0.28064, "lr": 0.00010, "mode": "train"}
[12/04 20:32:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "214", "cur_iter": "1", "dt": 1.30277, "dt_data": 0.76379, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27348, "lr": 0.00010, "mode": "train"}
[12/04 20:32:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 1.30354, "dt_data": 0.76536, "dt_net": 0.53819, "eta": "0:00:01", "loss": 0.27127, "lr": 0.00010, "mode": "train"}
[12/04 20:32:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 0.85200, "dt_data": 0.77785, "dt_net": 0.07414, "eta": "0:00:00", "mode": "val"}
[12/04 20:32:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:32:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:32:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:32:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:32:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:32:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003219 seconds.
[12/04 20:32:31][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "215", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:32:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "216", "cur_iter": "1", "dt": 1.30543, "dt_data": 0.76719, "dt_net": 0.53823, "eta": "0:00:01", "loss": 0.27609, "lr": 0.00010, "mode": "train"}
[12/04 20:32:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "217", "cur_iter": "1", "dt": 1.30369, "dt_data": 0.76488, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.26983, "lr": 0.00010, "mode": "train"}
[12/04 20:32:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "218", "cur_iter": "1", "dt": 1.30377, "dt_data": 0.76529, "dt_net": 0.53848, "eta": "0:00:01", "loss": 0.27321, "lr": 0.00010, "mode": "train"}
[12/04 20:32:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "219", "cur_iter": "1", "dt": 1.30613, "dt_data": 0.76754, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.26992, "lr": 0.00010, "mode": "train"}
[12/04 20:32:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 1.30393, "dt_data": 0.76504, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.26898, "lr": 0.00010, "mode": "train"}
[12/04 20:32:40][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 0.87134, "dt_data": 0.79750, "dt_net": 0.07384, "eta": "0:00:00", "mode": "val"}
[12/04 20:32:40][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:32:40][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:32:40][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:32:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:40][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:32:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:40][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:32:40][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003036 seconds.
[12/04 20:32:40][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "220", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:32:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "221", "cur_iter": "1", "dt": 1.30747, "dt_data": 0.76842, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.27963, "lr": 0.00010, "mode": "train"}
[12/04 20:32:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "222", "cur_iter": "1", "dt": 1.30338, "dt_data": 0.76474, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.28144, "lr": 0.00010, "mode": "train"}
[12/04 20:32:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "223", "cur_iter": "1", "dt": 1.30976, "dt_data": 0.77090, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27245, "lr": 0.00010, "mode": "train"}
[12/04 20:32:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "224", "cur_iter": "1", "dt": 1.30405, "dt_data": 0.76549, "dt_net": 0.53856, "eta": "0:00:01", "loss": 0.27981, "lr": 0.00010, "mode": "train"}
[12/04 20:32:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 1.30508, "dt_data": 0.76651, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.26848, "lr": 0.00010, "mode": "train"}
[12/04 20:32:48][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 0.87602, "dt_data": 0.80194, "dt_net": 0.07407, "eta": "0:00:00", "mode": "val"}
[12/04 20:32:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:32:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:32:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:32:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:32:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:32:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003057 seconds.
[12/04 20:32:48][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "225", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:32:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "226", "cur_iter": "1", "dt": 1.30687, "dt_data": 0.76788, "dt_net": 0.53899, "eta": "0:00:01", "loss": 0.27102, "lr": 0.00010, "mode": "train"}
[12/04 20:32:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "227", "cur_iter": "1", "dt": 1.30305, "dt_data": 0.76393, "dt_net": 0.53912, "eta": "0:00:01", "loss": 0.27062, "lr": 0.00010, "mode": "train"}
[12/04 20:32:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "228", "cur_iter": "1", "dt": 1.30520, "dt_data": 0.76666, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.27537, "lr": 0.00010, "mode": "train"}
[12/04 20:32:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "229", "cur_iter": "1", "dt": 1.30691, "dt_data": 0.76831, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.27540, "lr": 0.00010, "mode": "train"}
[12/04 20:32:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 1.30581, "dt_data": 0.76676, "dt_net": 0.53905, "eta": "0:00:01", "loss": 0.27072, "lr": 0.00010, "mode": "train"}
[12/04 20:32:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 0.87190, "dt_data": 0.79814, "dt_net": 0.07375, "eta": "0:00:00", "mode": "val"}
[12/04 20:32:57][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:32:57][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:32:57][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:32:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:57][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:32:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:32:57][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:32:57][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003070 seconds.
[12/04 20:32:57][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "230", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:32:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "231", "cur_iter": "1", "dt": 1.30995, "dt_data": 0.77120, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.26689, "lr": 0.00010, "mode": "train"}
[12/04 20:32:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "232", "cur_iter": "1", "dt": 1.30354, "dt_data": 0.76499, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.26867, "lr": 0.00010, "mode": "train"}
[12/04 20:33:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "233", "cur_iter": "1", "dt": 1.30662, "dt_data": 0.76786, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27166, "lr": 0.00010, "mode": "train"}
[12/04 20:33:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "234", "cur_iter": "1", "dt": 1.30434, "dt_data": 0.76572, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.26646, "lr": 0.00010, "mode": "train"}
[12/04 20:33:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 1.30566, "dt_data": 0.76642, "dt_net": 0.53924, "eta": "0:00:01", "loss": 0.27581, "lr": 0.00010, "mode": "train"}
[12/04 20:33:05][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 0.85682, "dt_data": 0.78255, "dt_net": 0.07427, "eta": "0:00:00", "mode": "val"}
[12/04 20:33:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:33:05][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:33:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:33:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:33:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:05][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:33:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003061 seconds.
[12/04 20:33:05][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "235", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:33:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "236", "cur_iter": "1", "dt": 1.30611, "dt_data": 0.76711, "dt_net": 0.53900, "eta": "0:00:01", "loss": 0.26900, "lr": 0.00010, "mode": "train"}
[12/04 20:33:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "237", "cur_iter": "1", "dt": 1.30833, "dt_data": 0.76927, "dt_net": 0.53905, "eta": "0:00:01", "loss": 0.26990, "lr": 0.00010, "mode": "train"}
[12/04 20:33:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "238", "cur_iter": "1", "dt": 1.30410, "dt_data": 0.76534, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27597, "lr": 0.00010, "mode": "train"}
[12/04 20:33:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "239", "cur_iter": "1", "dt": 1.30746, "dt_data": 0.76850, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.26877, "lr": 0.00010, "mode": "train"}
[12/04 20:33:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 1.30838, "dt_data": 0.77002, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27603, "lr": 0.00010, "mode": "train"}
[12/04 20:33:14][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 0.87765, "dt_data": 0.80384, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/04 20:33:14][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:33:14][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:33:14][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:33:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:14][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:33:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:14][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:33:14][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003049 seconds.
[12/04 20:33:14][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "240", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:33:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "241", "cur_iter": "1", "dt": 1.30765, "dt_data": 0.76911, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.27887, "lr": 0.00010, "mode": "train"}
[12/04 20:33:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "242", "cur_iter": "1", "dt": 1.30405, "dt_data": 0.76554, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.27063, "lr": 0.00010, "mode": "train"}
[12/04 20:33:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "243", "cur_iter": "1", "dt": 1.30516, "dt_data": 0.76619, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.26803, "lr": 0.00010, "mode": "train"}
[12/04 20:33:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "244", "cur_iter": "1", "dt": 1.30613, "dt_data": 0.76770, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.26623, "lr": 0.00010, "mode": "train"}
[12/04 20:33:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 1.30625, "dt_data": 0.76709, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.27812, "lr": 0.00010, "mode": "train"}
[12/04 20:33:22][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 0.86840, "dt_data": 0.79437, "dt_net": 0.07402, "eta": "0:00:00", "mode": "val"}
[12/04 20:33:22][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:33:22][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:33:22][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:33:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:22][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:33:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:22][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:33:22][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003106 seconds.
[12/04 20:33:22][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "245", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:33:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "246", "cur_iter": "1", "dt": 1.30512, "dt_data": 0.76610, "dt_net": 0.53901, "eta": "0:00:01", "loss": 0.27658, "lr": 0.00010, "mode": "train"}
[12/04 20:33:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "247", "cur_iter": "1", "dt": 1.30428, "dt_data": 0.76599, "dt_net": 0.53828, "eta": "0:00:01", "loss": 0.26457, "lr": 0.00010, "mode": "train"}
[12/04 20:33:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "248", "cur_iter": "1", "dt": 1.30885, "dt_data": 0.77041, "dt_net": 0.53844, "eta": "0:00:01", "loss": 0.27150, "lr": 0.00010, "mode": "train"}
[12/04 20:33:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "249", "cur_iter": "1", "dt": 1.30427, "dt_data": 0.76578, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.27115, "lr": 0.00010, "mode": "train"}
[12/04 20:33:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 1.30444, "dt_data": 0.76632, "dt_net": 0.53811, "eta": "0:00:01", "loss": 0.26870, "lr": 0.00010, "mode": "train"}
[12/04 20:33:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 0.87150, "dt_data": 0.79744, "dt_net": 0.07405, "eta": "0:00:00", "mode": "val"}
[12/04 20:33:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:33:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:33:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:33:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:33:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:33:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003083 seconds.
[12/04 20:33:31][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "250", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:33:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "251", "cur_iter": "1", "dt": 1.30623, "dt_data": 0.76766, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.27548, "lr": 0.00010, "mode": "train"}
[12/04 20:33:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "252", "cur_iter": "1", "dt": 1.30745, "dt_data": 0.76882, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.27577, "lr": 0.00010, "mode": "train"}
[12/04 20:33:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "253", "cur_iter": "1", "dt": 1.30386, "dt_data": 0.76501, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.29117, "lr": 0.00010, "mode": "train"}
[12/04 20:33:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "254", "cur_iter": "1", "dt": 1.30278, "dt_data": 0.76430, "dt_net": 0.53848, "eta": "0:00:01", "loss": 0.26458, "lr": 0.00010, "mode": "train"}
[12/04 20:33:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 1.30864, "dt_data": 0.76948, "dt_net": 0.53915, "eta": "0:00:01", "loss": 0.27062, "lr": 0.00010, "mode": "train"}
[12/04 20:33:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 0.86974, "dt_data": 0.79597, "dt_net": 0.07376, "eta": "0:00:00", "mode": "val"}
[12/04 20:33:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:33:39][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:33:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:33:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:33:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:39][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:33:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003081 seconds.
[12/04 20:33:39][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "255", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:33:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "256", "cur_iter": "1", "dt": 1.30540, "dt_data": 0.76645, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.27409, "lr": 0.00010, "mode": "train"}
[12/04 20:33:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "257", "cur_iter": "1", "dt": 1.30433, "dt_data": 0.76568, "dt_net": 0.53865, "eta": "0:00:01", "loss": 0.26784, "lr": 0.00010, "mode": "train"}
[12/04 20:33:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "258", "cur_iter": "1", "dt": 1.30498, "dt_data": 0.76675, "dt_net": 0.53822, "eta": "0:00:01", "loss": 0.26592, "lr": 0.00010, "mode": "train"}
[12/04 20:33:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "259", "cur_iter": "1", "dt": 1.30385, "dt_data": 0.76472, "dt_net": 0.53912, "eta": "0:00:01", "loss": 0.26818, "lr": 0.00010, "mode": "train"}
[12/04 20:33:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 1.30427, "dt_data": 0.76583, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.27846, "lr": 0.00010, "mode": "train"}
[12/04 20:33:48][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 0.86807, "dt_data": 0.79390, "dt_net": 0.07417, "eta": "0:00:00", "mode": "val"}
[12/04 20:33:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:33:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:33:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:33:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:33:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:33:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003067 seconds.
[12/04 20:33:48][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "260", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:33:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "261", "cur_iter": "1", "dt": 1.30876, "dt_data": 0.77032, "dt_net": 0.53844, "eta": "0:00:01", "loss": 0.27246, "lr": 0.00010, "mode": "train"}
[12/04 20:33:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "262", "cur_iter": "1", "dt": 1.30479, "dt_data": 0.76591, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.28242, "lr": 0.00010, "mode": "train"}
[12/04 20:33:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "263", "cur_iter": "1", "dt": 1.30539, "dt_data": 0.76661, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.28124, "lr": 0.00010, "mode": "train"}
[12/04 20:33:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "264", "cur_iter": "1", "dt": 1.30516, "dt_data": 0.76671, "dt_net": 0.53845, "eta": "0:00:01", "loss": 0.26764, "lr": 0.00010, "mode": "train"}
[12/04 20:33:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 1.30524, "dt_data": 0.76648, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.26911, "lr": 0.00010, "mode": "train"}
[12/04 20:33:56][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 0.86169, "dt_data": 0.78794, "dt_net": 0.07375, "eta": "0:00:00", "mode": "val"}
[12/04 20:33:56][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:33:56][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:33:56][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:33:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:56][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:33:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:33:56][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:33:56][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003097 seconds.
[12/04 20:33:56][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "265", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:33:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "266", "cur_iter": "1", "dt": 1.30283, "dt_data": 0.76415, "dt_net": 0.53867, "eta": "0:00:01", "loss": 0.27632, "lr": 0.00010, "mode": "train"}
[12/04 20:33:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "267", "cur_iter": "1", "dt": 1.30478, "dt_data": 0.76623, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.26438, "lr": 0.00010, "mode": "train"}
[12/04 20:34:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "268", "cur_iter": "1", "dt": 1.30318, "dt_data": 0.76443, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27243, "lr": 0.00010, "mode": "train"}
[12/04 20:34:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "269", "cur_iter": "1", "dt": 1.30358, "dt_data": 0.76476, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.27098, "lr": 0.00010, "mode": "train"}
[12/04 20:34:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 1.30315, "dt_data": 0.76493, "dt_net": 0.53821, "eta": "0:00:01", "loss": 0.26642, "lr": 0.00010, "mode": "train"}
[12/04 20:34:05][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 0.87189, "dt_data": 0.79789, "dt_net": 0.07398, "eta": "0:00:00", "mode": "val"}
[12/04 20:34:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:34:05][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:34:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:34:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:34:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:05][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:34:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003020 seconds.
[12/04 20:34:05][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "270", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:34:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "271", "cur_iter": "1", "dt": 1.30528, "dt_data": 0.76691, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.26467, "lr": 0.00010, "mode": "train"}
[12/04 20:34:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "272", "cur_iter": "1", "dt": 1.30456, "dt_data": 0.76561, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.27505, "lr": 0.00010, "mode": "train"}
[12/04 20:34:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "273", "cur_iter": "1", "dt": 1.30397, "dt_data": 0.76511, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.28068, "lr": 0.00010, "mode": "train"}
[12/04 20:34:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "274", "cur_iter": "1", "dt": 1.30273, "dt_data": 0.76436, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27068, "lr": 0.00010, "mode": "train"}
[12/04 20:34:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 1.30395, "dt_data": 0.76506, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.27723, "lr": 0.00010, "mode": "train"}
[12/04 20:34:13][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 0.87254, "dt_data": 0.79852, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/04 20:34:13][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:34:13][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:34:13][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:34:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:13][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:34:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:13][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:34:13][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003091 seconds.
[12/04 20:34:13][INFO] logging.py:  96: json_stats: {"RAM": "2.59/15.59G", "_type": "val_epoch", "cur_epoch": "275", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:34:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "276", "cur_iter": "1", "dt": 1.30732, "dt_data": 0.76857, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.27452, "lr": 0.00010, "mode": "train"}
[12/04 20:34:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "277", "cur_iter": "1", "dt": 1.30238, "dt_data": 0.76399, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.26789, "lr": 0.00010, "mode": "train"}
[12/04 20:34:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "278", "cur_iter": "1", "dt": 1.30662, "dt_data": 0.76787, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27064, "lr": 0.00010, "mode": "train"}
[12/04 20:34:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "279", "cur_iter": "1", "dt": 1.30417, "dt_data": 0.76529, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.26840, "lr": 0.00010, "mode": "train"}
[12/04 20:34:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 1.30349, "dt_data": 0.76529, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.27842, "lr": 0.00010, "mode": "train"}
[12/04 20:34:22][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 0.87346, "dt_data": 0.79941, "dt_net": 0.07404, "eta": "0:00:00", "mode": "val"}
[12/04 20:34:22][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:34:22][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:34:22][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:34:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:22][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:34:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:22][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:34:22][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002995 seconds.
[12/04 20:34:22][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "280", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:34:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "281", "cur_iter": "1", "dt": 1.30640, "dt_data": 0.76771, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.26558, "lr": 0.00010, "mode": "train"}
[12/04 20:34:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "282", "cur_iter": "1", "dt": 1.30799, "dt_data": 0.76903, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.28205, "lr": 0.00010, "mode": "train"}
[12/04 20:34:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "283", "cur_iter": "1", "dt": 1.30933, "dt_data": 0.77079, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.27481, "lr": 0.00010, "mode": "train"}
[12/04 20:34:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "284", "cur_iter": "1", "dt": 1.30815, "dt_data": 0.76955, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.27004, "lr": 0.00010, "mode": "train"}
[12/04 20:34:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 1.30453, "dt_data": 0.76576, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.26677, "lr": 0.00010, "mode": "train"}
[12/04 20:34:30][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 0.87073, "dt_data": 0.79634, "dt_net": 0.07439, "eta": "0:00:00", "mode": "val"}
[12/04 20:34:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:34:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:34:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:34:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:34:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:34:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003070 seconds.
[12/04 20:34:31][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "285", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:34:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "286", "cur_iter": "1", "dt": 1.30456, "dt_data": 0.76570, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27007, "lr": 0.00010, "mode": "train"}
[12/04 20:34:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "287", "cur_iter": "1", "dt": 1.30704, "dt_data": 0.76847, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.26766, "lr": 0.00010, "mode": "train"}
[12/04 20:34:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "288", "cur_iter": "1", "dt": 1.30507, "dt_data": 0.76624, "dt_net": 0.53883, "eta": "0:00:01", "loss": 0.26946, "lr": 0.00010, "mode": "train"}
[12/04 20:34:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "289", "cur_iter": "1", "dt": 1.30299, "dt_data": 0.76410, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.27488, "lr": 0.00010, "mode": "train"}
[12/04 20:34:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 1.30852, "dt_data": 0.76997, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.27512, "lr": 0.00010, "mode": "train"}
[12/04 20:34:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 0.86496, "dt_data": 0.79118, "dt_net": 0.07378, "eta": "0:00:00", "mode": "val"}
[12/04 20:34:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:34:39][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:34:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:34:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:34:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:39][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:34:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003071 seconds.
[12/04 20:34:39][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "290", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:34:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "291", "cur_iter": "1", "dt": 1.30633, "dt_data": 0.76772, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.26754, "lr": 0.00010, "mode": "train"}
[12/04 20:34:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "292", "cur_iter": "1", "dt": 1.30397, "dt_data": 0.76492, "dt_net": 0.53905, "eta": "0:00:01", "loss": 0.27445, "lr": 0.00010, "mode": "train"}
[12/04 20:34:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "293", "cur_iter": "1", "dt": 1.30366, "dt_data": 0.76484, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.27144, "lr": 0.00010, "mode": "train"}
[12/04 20:34:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "294", "cur_iter": "1", "dt": 1.30607, "dt_data": 0.76720, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.26513, "lr": 0.00010, "mode": "train"}
[12/04 20:34:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 1.30832, "dt_data": 0.76946, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27512, "lr": 0.00010, "mode": "train"}
[12/04 20:34:48][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 0.87218, "dt_data": 0.79833, "dt_net": 0.07385, "eta": "0:00:00", "mode": "val"}
[12/04 20:34:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:34:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:34:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:34:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:34:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:34:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003028 seconds.
[12/04 20:34:48][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "295", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/04 20:34:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "296", "cur_iter": "1", "dt": 1.30737, "dt_data": 0.76841, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.26896, "lr": 0.00010, "mode": "train"}
[12/04 20:34:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "297", "cur_iter": "1", "dt": 1.30685, "dt_data": 0.76841, "dt_net": 0.53844, "eta": "0:00:01", "loss": 0.26896, "lr": 0.00010, "mode": "train"}
[12/04 20:34:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "298", "cur_iter": "1", "dt": 1.30807, "dt_data": 0.76928, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.27408, "lr": 0.00010, "mode": "train"}
[12/04 20:34:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "299", "cur_iter": "1", "dt": 1.30639, "dt_data": 0.76804, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.26718, "lr": 0.00010, "mode": "train"}
[12/04 20:34:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 1.30412, "dt_data": 0.76575, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.26920, "lr": 0.00010, "mode": "train"}
[12/04 20:34:56][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 0.87136, "dt_data": 0.79731, "dt_net": 0.07404, "eta": "0:00:00", "mode": "val"}
[12/04 20:34:56][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/04 20:34:56][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/04 20:34:56][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/04 20:34:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:56][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/04 20:34:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/04 20:34:56][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/04 20:34:56][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002993 seconds.
[12/04 20:34:56][INFO] logging.py:  96: json_stats: {"RAM": "2.58/15.59G", "_type": "val_epoch", "cur_epoch": "300", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/05 12:19:15][INFO] train_net.py: 377: Train with config:
[12/05 12:19:15][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/05 12:19:17][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/05 12:19:17][INFO] misc.py: 170: Params: 33,653,708
[12/05 12:19:17][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/05 12:19:17][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/05 12:19:17][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/05 12:19:17][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/05 12:19:17][INFO] misc.py: 177: Activations: 155.545604 M
[12/05 12:19:17][INFO] misc.py: 182: nvidia-smi
[12/05 12:19:17][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/05 12:19:17][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/05 12:19:17][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/05 12:19:17][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/05 12:19:17][INFO] ava_helper.py: 111: Number of annotations: 15
[12/05 12:19:17][INFO] ava_helper.py: 157: 1 keyframes used.
[12/05 12:19:17][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/05 12:19:17][INFO] ava_dataset.py:  89: Split: train
[12/05 12:19:17][INFO] ava_dataset.py:  90: Number of videos: 1
[12/05 12:19:17][INFO] ava_dataset.py:  94: Number of frames: 5
[12/05 12:19:17][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/05 12:19:17][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/05 12:19:17][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/05 12:19:17][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/05 12:19:17][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/05 12:19:17][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/05 12:19:17][INFO] ava_helper.py: 111: Number of annotations: 11
[12/05 12:19:17][INFO] ava_helper.py: 157: 1 keyframes used.
[12/05 12:19:17][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/05 12:19:17][INFO] ava_dataset.py:  89: Split: val
[12/05 12:19:17][INFO] ava_dataset.py:  90: Number of videos: 1
[12/05 12:19:17][INFO] ava_dataset.py:  94: Number of frames: 4
[12/05 12:19:17][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/05 12:19:17][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/05 12:19:17][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/05 12:19:17][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/05 12:19:18][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/05 12:19:18][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/05 12:19:18][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/05 12:19:18][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/05 12:19:18][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/05 12:19:18][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/05 12:19:18][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/05 12:19:18][INFO] train_net.py: 417: Start epoch: 1
[12/05 12:19:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.33251, "dt_data": 0.80307, "dt_net": 0.52944, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/05 12:19:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.29802, "dt_data": 0.76551, "dt_net": 0.53251, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/05 12:19:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.29927, "dt_data": 0.76699, "dt_net": 0.53227, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/05 12:19:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.30262, "dt_data": 0.76964, "dt_net": 0.53298, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/05 12:19:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.30188, "dt_data": 0.76911, "dt_net": 0.53277, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/05 12:19:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.84399, "dt_data": 0.77089, "dt_net": 0.07309, "eta": "0:00:00", "mode": "val"}
[12/05 12:19:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:19:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:19:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:19:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:19:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:19:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003574 seconds.
[12/05 12:19:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/05 12:19:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.30311, "dt_data": 0.77052, "dt_net": 0.53259, "eta": "0:00:01", "loss": 0.92414, "lr": 0.10000, "mode": "train"}
[12/05 12:19:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.30349, "dt_data": 0.77139, "dt_net": 0.53209, "eta": "0:00:01", "loss": 0.72938, "lr": 0.10000, "mode": "train"}
[12/05 12:19:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.30516, "dt_data": 0.77225, "dt_net": 0.53290, "eta": "0:00:01", "loss": 0.70012, "lr": 0.10000, "mode": "train"}
[12/05 12:19:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.30791, "dt_data": 0.77569, "dt_net": 0.53222, "eta": "0:00:01", "loss": 0.48058, "lr": 0.10000, "mode": "train"}
[12/05 12:19:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.30317, "dt_data": 0.77060, "dt_net": 0.53257, "eta": "0:00:01", "loss": 0.77291, "lr": 0.10000, "mode": "train"}
[12/05 12:19:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.87820, "dt_data": 0.80491, "dt_net": 0.07328, "eta": "0:00:00", "mode": "val"}
[12/05 12:19:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:19:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:19:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:19:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:19:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:19:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003013 seconds.
[12/05 12:19:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.78661, "mode": "val"}
[12/05 12:19:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.30938, "dt_data": 0.77628, "dt_net": 0.53310, "eta": "0:00:01", "loss": 2.80025, "lr": 0.01000, "mode": "train"}
[12/05 12:19:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.31010, "dt_data": 0.77618, "dt_net": 0.53392, "eta": "0:00:01", "loss": 0.97025, "lr": 0.01000, "mode": "train"}
[12/05 12:19:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.30968, "dt_data": 0.77685, "dt_net": 0.53282, "eta": "0:00:01", "loss": 0.43444, "lr": 0.01000, "mode": "train"}
[12/05 12:19:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.30993, "dt_data": 0.77611, "dt_net": 0.53382, "eta": "0:00:01", "loss": 0.33755, "lr": 0.01000, "mode": "train"}
[12/05 12:19:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.31124, "dt_data": 0.77663, "dt_net": 0.53460, "eta": "0:00:01", "loss": 0.28890, "lr": 0.01000, "mode": "train"}
[12/05 12:19:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.87936, "dt_data": 0.80604, "dt_net": 0.07331, "eta": "0:00:00", "mode": "val"}
[12/05 12:19:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:19:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:19:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:19:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:19:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:19:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002949 seconds.
[12/05 12:19:44][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.60101, "mode": "val"}
[12/05 12:19:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.30646, "dt_data": 0.77197, "dt_net": 0.53448, "eta": "0:00:01", "loss": 0.38577, "lr": 0.00100, "mode": "train"}
[12/05 12:19:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.30755, "dt_data": 0.77303, "dt_net": 0.53452, "eta": "0:00:01", "loss": 0.35372, "lr": 0.00100, "mode": "train"}
[12/05 12:19:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.30998, "dt_data": 0.77543, "dt_net": 0.53454, "eta": "0:00:01", "loss": 0.36021, "lr": 0.00100, "mode": "train"}
[12/05 12:19:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.30736, "dt_data": 0.77333, "dt_net": 0.53403, "eta": "0:00:01", "loss": 0.36207, "lr": 0.00100, "mode": "train"}
[12/05 12:19:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.30887, "dt_data": 0.77426, "dt_net": 0.53461, "eta": "0:00:01", "loss": 0.34552, "lr": 0.00100, "mode": "train"}
[12/05 12:19:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.87330, "dt_data": 0.79971, "dt_net": 0.07359, "eta": "0:00:00", "mode": "val"}
[12/05 12:19:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:19:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:19:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:19:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:19:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:19:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:19:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003050 seconds.
[12/05 12:19:52][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.57879, "mode": "val"}
[12/05 12:19:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "21", "cur_iter": "1", "dt": 1.30649, "dt_data": 0.77203, "dt_net": 0.53446, "eta": "0:00:01", "loss": 0.30668, "lr": 0.00010, "mode": "train"}
[12/05 12:19:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "22", "cur_iter": "1", "dt": 1.30551, "dt_data": 0.77132, "dt_net": 0.53418, "eta": "0:00:01", "loss": 0.34643, "lr": 0.00010, "mode": "train"}
[12/05 12:19:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "23", "cur_iter": "1", "dt": 1.31651, "dt_data": 0.78255, "dt_net": 0.53395, "eta": "0:00:01", "loss": 0.33136, "lr": 0.00010, "mode": "train"}
[12/05 12:19:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "24", "cur_iter": "1", "dt": 1.30797, "dt_data": 0.77353, "dt_net": 0.53444, "eta": "0:00:01", "loss": 0.32023, "lr": 0.00010, "mode": "train"}
[12/05 12:19:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 1.30902, "dt_data": 0.77486, "dt_net": 0.53417, "eta": "0:00:01", "loss": 0.34776, "lr": 0.00010, "mode": "train"}
[12/05 12:20:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 0.86546, "dt_data": 0.79212, "dt_net": 0.07333, "eta": "0:00:00", "mode": "val"}
[12/05 12:20:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:20:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:20:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:20:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:20:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:20:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003074 seconds.
[12/05 12:20:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "25", "gpu_mem": "1.74G", "map": 0.55498, "mode": "val"}
[12/05 12:20:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "26", "cur_iter": "1", "dt": 1.30405, "dt_data": 0.76960, "dt_net": 0.53445, "eta": "0:00:01", "loss": 0.32255, "lr": 0.00010, "mode": "train"}
[12/05 12:20:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "27", "cur_iter": "1", "dt": 1.30568, "dt_data": 0.77099, "dt_net": 0.53469, "eta": "0:00:01", "loss": 0.32096, "lr": 0.00010, "mode": "train"}
[12/05 12:20:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "28", "cur_iter": "1", "dt": 1.30455, "dt_data": 0.77005, "dt_net": 0.53450, "eta": "0:00:01", "loss": 0.31041, "lr": 0.00010, "mode": "train"}
[12/05 12:20:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "29", "cur_iter": "1", "dt": 1.30479, "dt_data": 0.77074, "dt_net": 0.53405, "eta": "0:00:01", "loss": 0.29848, "lr": 0.00010, "mode": "train"}
[12/05 12:20:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.31003, "dt_data": 0.77529, "dt_net": 0.53474, "eta": "0:00:01", "loss": 0.28725, "lr": 0.00010, "mode": "train"}
[12/05 12:20:09][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 0.87325, "dt_data": 0.79985, "dt_net": 0.07339, "eta": "0:00:00", "mode": "val"}
[12/05 12:20:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:20:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:20:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:20:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:20:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:20:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003101 seconds.
[12/05 12:20:10][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "30", "gpu_mem": "1.74G", "map": 0.57143, "mode": "val"}
[12/05 12:20:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "31", "cur_iter": "1", "dt": 1.30680, "dt_data": 0.77199, "dt_net": 0.53481, "eta": "0:00:01", "loss": 0.29408, "lr": 0.00010, "mode": "train"}
[12/05 12:20:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "32", "cur_iter": "1", "dt": 1.30594, "dt_data": 0.77176, "dt_net": 0.53418, "eta": "0:00:01", "loss": 0.32117, "lr": 0.00010, "mode": "train"}
[12/05 12:20:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "33", "cur_iter": "1", "dt": 1.30563, "dt_data": 0.77003, "dt_net": 0.53560, "eta": "0:00:01", "loss": 0.33797, "lr": 0.00010, "mode": "train"}
[12/05 12:20:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "34", "cur_iter": "1", "dt": 1.30921, "dt_data": 0.77273, "dt_net": 0.53648, "eta": "0:00:01", "loss": 0.30947, "lr": 0.00010, "mode": "train"}
[12/05 12:20:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 1.30817, "dt_data": 0.77212, "dt_net": 0.53605, "eta": "0:00:01", "loss": 0.31167, "lr": 0.00010, "mode": "train"}
[12/05 12:20:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 0.87238, "dt_data": 0.79845, "dt_net": 0.07393, "eta": "0:00:00", "mode": "val"}
[12/05 12:20:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:20:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:20:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:20:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:20:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:20:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003158 seconds.
[12/05 12:20:18][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "35", "gpu_mem": "1.74G", "map": 0.62998, "mode": "val"}
[12/05 12:20:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "36", "cur_iter": "1", "dt": 1.30816, "dt_data": 0.77206, "dt_net": 0.53610, "eta": "0:00:01", "loss": 0.28429, "lr": 0.00010, "mode": "train"}
[12/05 12:20:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "37", "cur_iter": "1", "dt": 1.30957, "dt_data": 0.77285, "dt_net": 0.53672, "eta": "0:00:01", "loss": 0.36107, "lr": 0.00010, "mode": "train"}
[12/05 12:20:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "38", "cur_iter": "1", "dt": 1.31099, "dt_data": 0.77471, "dt_net": 0.53628, "eta": "0:00:01", "loss": 0.33687, "lr": 0.00010, "mode": "train"}
[12/05 12:20:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "39", "cur_iter": "1", "dt": 1.30904, "dt_data": 0.77247, "dt_net": 0.53656, "eta": "0:00:01", "loss": 0.29935, "lr": 0.00010, "mode": "train"}
[12/05 12:20:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 1.31084, "dt_data": 0.77413, "dt_net": 0.53671, "eta": "0:00:01", "loss": 0.30433, "lr": 0.00010, "mode": "train"}
[12/05 12:20:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 0.86099, "dt_data": 0.78694, "dt_net": 0.07404, "eta": "0:00:00", "mode": "val"}
[12/05 12:20:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:20:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:20:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:20:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:20:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:20:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003098 seconds.
[12/05 12:20:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "40", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:20:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "41", "cur_iter": "1", "dt": 1.30720, "dt_data": 0.77029, "dt_net": 0.53692, "eta": "0:00:01", "loss": 0.29757, "lr": 0.00010, "mode": "train"}
[12/05 12:20:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "42", "cur_iter": "1", "dt": 1.30948, "dt_data": 0.77320, "dt_net": 0.53628, "eta": "0:00:01", "loss": 0.30718, "lr": 0.00010, "mode": "train"}
[12/05 12:20:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "43", "cur_iter": "1", "dt": 1.31210, "dt_data": 0.77526, "dt_net": 0.53684, "eta": "0:00:01", "loss": 0.31991, "lr": 0.00010, "mode": "train"}
[12/05 12:20:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "44", "cur_iter": "1", "dt": 1.31014, "dt_data": 0.77380, "dt_net": 0.53634, "eta": "0:00:01", "loss": 0.32944, "lr": 0.00010, "mode": "train"}
[12/05 12:20:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 1.31103, "dt_data": 0.77499, "dt_net": 0.53604, "eta": "0:00:01", "loss": 0.32609, "lr": 0.00010, "mode": "train"}
[12/05 12:20:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 0.86247, "dt_data": 0.78874, "dt_net": 0.07372, "eta": "0:00:00", "mode": "val"}
[12/05 12:20:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:20:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:20:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:20:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:20:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:20:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003188 seconds.
[12/05 12:20:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "45", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:20:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "46", "cur_iter": "1", "dt": 1.30600, "dt_data": 0.76930, "dt_net": 0.53669, "eta": "0:00:01", "loss": 0.28949, "lr": 0.00010, "mode": "train"}
[12/05 12:20:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "47", "cur_iter": "1", "dt": 1.30837, "dt_data": 0.77151, "dt_net": 0.53686, "eta": "0:00:01", "loss": 0.32790, "lr": 0.00010, "mode": "train"}
[12/05 12:20:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "48", "cur_iter": "1", "dt": 1.30957, "dt_data": 0.77302, "dt_net": 0.53654, "eta": "0:00:01", "loss": 0.30481, "lr": 0.00010, "mode": "train"}
[12/05 12:20:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "49", "cur_iter": "1", "dt": 1.30878, "dt_data": 0.77209, "dt_net": 0.53668, "eta": "0:00:01", "loss": 0.31342, "lr": 0.00010, "mode": "train"}
[12/05 12:20:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 1.30666, "dt_data": 0.77017, "dt_net": 0.53649, "eta": "0:00:01", "loss": 0.29098, "lr": 0.00010, "mode": "train"}
[12/05 12:20:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 0.87001, "dt_data": 0.79647, "dt_net": 0.07353, "eta": "0:00:00", "mode": "val"}
[12/05 12:20:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:20:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:20:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:20:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:20:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:20:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003148 seconds.
[12/05 12:20:44][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "50", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:20:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "51", "cur_iter": "1", "dt": 1.30922, "dt_data": 0.77232, "dt_net": 0.53689, "eta": "0:00:01", "loss": 0.29126, "lr": 0.00010, "mode": "train"}
[12/05 12:20:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "52", "cur_iter": "1", "dt": 1.30456, "dt_data": 0.76875, "dt_net": 0.53581, "eta": "0:00:01", "loss": 0.32144, "lr": 0.00010, "mode": "train"}
[12/05 12:20:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "53", "cur_iter": "1", "dt": 1.30817, "dt_data": 0.77157, "dt_net": 0.53660, "eta": "0:00:01", "loss": 0.27877, "lr": 0.00010, "mode": "train"}
[12/05 12:20:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "54", "cur_iter": "1", "dt": 1.30398, "dt_data": 0.76783, "dt_net": 0.53615, "eta": "0:00:01", "loss": 0.29545, "lr": 0.00010, "mode": "train"}
[12/05 12:20:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 1.30689, "dt_data": 0.77064, "dt_net": 0.53625, "eta": "0:00:01", "loss": 0.28935, "lr": 0.00010, "mode": "train"}
[12/05 12:20:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 0.87087, "dt_data": 0.79739, "dt_net": 0.07347, "eta": "0:00:00", "mode": "val"}
[12/05 12:20:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:20:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:20:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:20:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:20:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:20:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:20:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003043 seconds.
[12/05 12:20:52][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "55", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:20:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "56", "cur_iter": "1", "dt": 1.30697, "dt_data": 0.77062, "dt_net": 0.53635, "eta": "0:00:01", "loss": 0.29810, "lr": 0.00010, "mode": "train"}
[12/05 12:20:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "57", "cur_iter": "1", "dt": 1.30463, "dt_data": 0.76837, "dt_net": 0.53625, "eta": "0:00:01", "loss": 0.28040, "lr": 0.00010, "mode": "train"}
[12/05 12:20:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "58", "cur_iter": "1", "dt": 1.30727, "dt_data": 0.77125, "dt_net": 0.53601, "eta": "0:00:01", "loss": 0.28247, "lr": 0.00010, "mode": "train"}
[12/05 12:20:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "59", "cur_iter": "1", "dt": 1.30891, "dt_data": 0.77267, "dt_net": 0.53624, "eta": "0:00:01", "loss": 0.28785, "lr": 0.00010, "mode": "train"}
[12/05 12:20:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 1.30706, "dt_data": 0.77081, "dt_net": 0.53625, "eta": "0:00:01", "loss": 0.29867, "lr": 0.00010, "mode": "train"}
[12/05 12:21:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 0.87828, "dt_data": 0.80456, "dt_net": 0.07371, "eta": "0:00:00", "mode": "val"}
[12/05 12:21:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:21:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:21:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:21:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:21:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:21:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003046 seconds.
[12/05 12:21:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "60", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:21:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "61", "cur_iter": "1", "dt": 1.30822, "dt_data": 0.77211, "dt_net": 0.53611, "eta": "0:00:01", "loss": 0.29699, "lr": 0.00010, "mode": "train"}
[12/05 12:21:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "62", "cur_iter": "1", "dt": 1.31058, "dt_data": 0.77439, "dt_net": 0.53618, "eta": "0:00:01", "loss": 0.31681, "lr": 0.00010, "mode": "train"}
[12/05 12:21:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "63", "cur_iter": "1", "dt": 1.30623, "dt_data": 0.77001, "dt_net": 0.53623, "eta": "0:00:01", "loss": 0.29680, "lr": 0.00010, "mode": "train"}
[12/05 12:21:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "64", "cur_iter": "1", "dt": 1.30572, "dt_data": 0.76975, "dt_net": 0.53596, "eta": "0:00:01", "loss": 0.32063, "lr": 0.00010, "mode": "train"}
[12/05 12:21:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 1.31165, "dt_data": 0.77527, "dt_net": 0.53638, "eta": "0:00:01", "loss": 0.35482, "lr": 0.00010, "mode": "train"}
[12/05 12:21:09][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 0.87848, "dt_data": 0.80487, "dt_net": 0.07361, "eta": "0:00:00", "mode": "val"}
[12/05 12:21:09][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:21:09][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:21:09][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:21:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:09][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:21:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:09][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:21:09][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003110 seconds.
[12/05 12:21:09][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "65", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:21:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "66", "cur_iter": "1", "dt": 1.30967, "dt_data": 0.77357, "dt_net": 0.53609, "eta": "0:00:01", "loss": 0.29030, "lr": 0.00010, "mode": "train"}
[12/05 12:21:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "67", "cur_iter": "1", "dt": 1.31117, "dt_data": 0.77496, "dt_net": 0.53621, "eta": "0:00:01", "loss": 0.28556, "lr": 0.00010, "mode": "train"}
[12/05 12:21:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "68", "cur_iter": "1", "dt": 1.30714, "dt_data": 0.77129, "dt_net": 0.53585, "eta": "0:00:01", "loss": 0.29927, "lr": 0.00010, "mode": "train"}
[12/05 12:21:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "69", "cur_iter": "1", "dt": 1.30625, "dt_data": 0.77011, "dt_net": 0.53614, "eta": "0:00:01", "loss": 0.29988, "lr": 0.00010, "mode": "train"}
[12/05 12:21:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 1.30760, "dt_data": 0.77182, "dt_net": 0.53578, "eta": "0:00:01", "loss": 0.29862, "lr": 0.00010, "mode": "train"}
[12/05 12:21:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 0.86846, "dt_data": 0.79468, "dt_net": 0.07378, "eta": "0:00:00", "mode": "val"}
[12/05 12:21:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:21:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:21:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:21:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:21:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:21:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003056 seconds.
[12/05 12:21:18][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "70", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:21:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "71", "cur_iter": "1", "dt": 1.30665, "dt_data": 0.77031, "dt_net": 0.53634, "eta": "0:00:01", "loss": 0.30350, "lr": 0.00010, "mode": "train"}
[12/05 12:21:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "72", "cur_iter": "1", "dt": 1.30888, "dt_data": 0.77245, "dt_net": 0.53643, "eta": "0:00:01", "loss": 0.28601, "lr": 0.00010, "mode": "train"}
[12/05 12:21:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "73", "cur_iter": "1", "dt": 1.30681, "dt_data": 0.77085, "dt_net": 0.53596, "eta": "0:00:01", "loss": 0.32015, "lr": 0.00010, "mode": "train"}
[12/05 12:21:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "74", "cur_iter": "1", "dt": 1.30977, "dt_data": 0.77320, "dt_net": 0.53657, "eta": "0:00:01", "loss": 0.28917, "lr": 0.00010, "mode": "train"}
[12/05 12:21:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 1.31025, "dt_data": 0.77398, "dt_net": 0.53627, "eta": "0:00:01", "loss": 0.28148, "lr": 0.00010, "mode": "train"}
[12/05 12:21:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 0.87417, "dt_data": 0.80033, "dt_net": 0.07384, "eta": "0:00:00", "mode": "val"}
[12/05 12:21:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:21:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:21:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:21:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:21:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:21:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003083 seconds.
[12/05 12:21:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "75", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:21:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "76", "cur_iter": "1", "dt": 1.30796, "dt_data": 0.77175, "dt_net": 0.53621, "eta": "0:00:01", "loss": 0.31886, "lr": 0.00010, "mode": "train"}
[12/05 12:21:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "77", "cur_iter": "1", "dt": 1.30491, "dt_data": 0.76929, "dt_net": 0.53562, "eta": "0:00:01", "loss": 0.28301, "lr": 0.00010, "mode": "train"}
[12/05 12:21:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "78", "cur_iter": "1", "dt": 1.31057, "dt_data": 0.77452, "dt_net": 0.53605, "eta": "0:00:01", "loss": 0.31181, "lr": 0.00010, "mode": "train"}
[12/05 12:21:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "79", "cur_iter": "1", "dt": 1.30753, "dt_data": 0.76934, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.28993, "lr": 0.00010, "mode": "train"}
[12/05 12:21:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 1.31034, "dt_data": 0.77054, "dt_net": 0.53980, "eta": "0:00:01", "loss": 0.28340, "lr": 0.00010, "mode": "train"}
[12/05 12:21:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 0.87074, "dt_data": 0.79677, "dt_net": 0.07397, "eta": "0:00:00", "mode": "val"}
[12/05 12:21:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:21:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:21:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:21:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:21:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:21:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003081 seconds.
[12/05 12:21:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "80", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:21:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "81", "cur_iter": "1", "dt": 1.31292, "dt_data": 0.77239, "dt_net": 0.54053, "eta": "0:00:01", "loss": 0.28887, "lr": 0.00010, "mode": "train"}
[12/05 12:21:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "82", "cur_iter": "1", "dt": 1.30923, "dt_data": 0.76922, "dt_net": 0.54001, "eta": "0:00:01", "loss": 0.27606, "lr": 0.00010, "mode": "train"}
[12/05 12:21:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "83", "cur_iter": "1", "dt": 1.30966, "dt_data": 0.76974, "dt_net": 0.53991, "eta": "0:00:01", "loss": 0.28977, "lr": 0.00010, "mode": "train"}
[12/05 12:21:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "84", "cur_iter": "1", "dt": 1.30993, "dt_data": 0.77006, "dt_net": 0.53986, "eta": "0:00:01", "loss": 0.30076, "lr": 0.00010, "mode": "train"}
[12/05 12:21:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 1.31372, "dt_data": 0.77317, "dt_net": 0.54055, "eta": "0:00:01", "loss": 0.28142, "lr": 0.00010, "mode": "train"}
[12/05 12:21:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 0.86939, "dt_data": 0.79530, "dt_net": 0.07408, "eta": "0:00:00", "mode": "val"}
[12/05 12:21:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:21:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:21:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:21:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:21:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:21:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003111 seconds.
[12/05 12:21:44][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "85", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:21:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "86", "cur_iter": "1", "dt": 1.31007, "dt_data": 0.77025, "dt_net": 0.53982, "eta": "0:00:01", "loss": 0.27370, "lr": 0.00010, "mode": "train"}
[12/05 12:21:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "87", "cur_iter": "1", "dt": 1.30840, "dt_data": 0.76871, "dt_net": 0.53969, "eta": "0:00:01", "loss": 0.27918, "lr": 0.00010, "mode": "train"}
[12/05 12:21:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "88", "cur_iter": "1", "dt": 1.31333, "dt_data": 0.77298, "dt_net": 0.54035, "eta": "0:00:01", "loss": 0.27949, "lr": 0.00010, "mode": "train"}
[12/05 12:21:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "89", "cur_iter": "1", "dt": 1.31203, "dt_data": 0.77229, "dt_net": 0.53975, "eta": "0:00:01", "loss": 0.28732, "lr": 0.00010, "mode": "train"}
[12/05 12:21:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 1.31064, "dt_data": 0.77019, "dt_net": 0.54045, "eta": "0:00:01", "loss": 0.28873, "lr": 0.00010, "mode": "train"}
[12/05 12:21:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 0.87537, "dt_data": 0.80123, "dt_net": 0.07413, "eta": "0:00:00", "mode": "val"}
[12/05 12:21:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:21:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:21:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:21:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:21:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:21:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:21:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003009 seconds.
[12/05 12:21:52][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "90", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:21:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "91", "cur_iter": "1", "dt": 1.31291, "dt_data": 0.77255, "dt_net": 0.54036, "eta": "0:00:01", "loss": 0.29162, "lr": 0.00010, "mode": "train"}
[12/05 12:21:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "92", "cur_iter": "1", "dt": 1.31263, "dt_data": 0.77277, "dt_net": 0.53986, "eta": "0:00:01", "loss": 0.28549, "lr": 0.00010, "mode": "train"}
[12/05 12:21:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "93", "cur_iter": "1", "dt": 1.31491, "dt_data": 0.77475, "dt_net": 0.54016, "eta": "0:00:01", "loss": 0.28282, "lr": 0.00010, "mode": "train"}
[12/05 12:21:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "94", "cur_iter": "1", "dt": 1.31037, "dt_data": 0.77024, "dt_net": 0.54012, "eta": "0:00:01", "loss": 0.28025, "lr": 0.00010, "mode": "train"}
[12/05 12:21:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 1.31508, "dt_data": 0.77524, "dt_net": 0.53985, "eta": "0:00:01", "loss": 0.28401, "lr": 0.00010, "mode": "train"}
[12/05 12:22:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 0.86943, "dt_data": 0.79517, "dt_net": 0.07426, "eta": "0:00:00", "mode": "val"}
[12/05 12:22:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:22:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:22:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:22:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:22:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:22:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003032 seconds.
[12/05 12:22:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "95", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:22:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "96", "cur_iter": "1", "dt": 1.31153, "dt_data": 0.77135, "dt_net": 0.54018, "eta": "0:00:01", "loss": 0.27979, "lr": 0.00010, "mode": "train"}
[12/05 12:22:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "97", "cur_iter": "1", "dt": 1.31266, "dt_data": 0.77238, "dt_net": 0.54028, "eta": "0:00:01", "loss": 0.28674, "lr": 0.00010, "mode": "train"}
[12/05 12:22:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "98", "cur_iter": "1", "dt": 1.31397, "dt_data": 0.77377, "dt_net": 0.54019, "eta": "0:00:01", "loss": 0.28763, "lr": 0.00010, "mode": "train"}
[12/05 12:22:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "99", "cur_iter": "1", "dt": 1.30939, "dt_data": 0.76949, "dt_net": 0.53990, "eta": "0:00:01", "loss": 0.29057, "lr": 0.00010, "mode": "train"}
[12/05 12:22:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 1.31423, "dt_data": 0.77383, "dt_net": 0.54041, "eta": "0:00:01", "loss": 0.28500, "lr": 0.00010, "mode": "train"}
[12/05 12:22:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 0.87843, "dt_data": 0.80379, "dt_net": 0.07463, "eta": "0:00:00", "mode": "val"}
[12/05 12:22:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:22:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:22:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:22:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:22:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:22:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003069 seconds.
[12/05 12:22:10][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "100", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:22:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "101", "cur_iter": "1", "dt": 1.31731, "dt_data": 0.77700, "dt_net": 0.54030, "eta": "0:00:01", "loss": 0.28465, "lr": 0.00010, "mode": "train"}
[12/05 12:22:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "102", "cur_iter": "1", "dt": 1.31367, "dt_data": 0.77412, "dt_net": 0.53954, "eta": "0:00:01", "loss": 0.27319, "lr": 0.00010, "mode": "train"}
[12/05 12:22:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "103", "cur_iter": "1", "dt": 1.31166, "dt_data": 0.77123, "dt_net": 0.54043, "eta": "0:00:01", "loss": 0.29695, "lr": 0.00010, "mode": "train"}
[12/05 12:22:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "104", "cur_iter": "1", "dt": 1.31298, "dt_data": 0.77302, "dt_net": 0.53995, "eta": "0:00:01", "loss": 0.27856, "lr": 0.00010, "mode": "train"}
[12/05 12:22:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 1.31126, "dt_data": 0.77133, "dt_net": 0.53992, "eta": "0:00:01", "loss": 0.28944, "lr": 0.00010, "mode": "train"}
[12/05 12:22:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 0.87049, "dt_data": 0.79629, "dt_net": 0.07420, "eta": "0:00:00", "mode": "val"}
[12/05 12:22:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:22:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:22:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:22:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:22:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:22:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003139 seconds.
[12/05 12:22:18][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "105", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:22:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "106", "cur_iter": "1", "dt": 1.31270, "dt_data": 0.77237, "dt_net": 0.54033, "eta": "0:00:01", "loss": 0.28534, "lr": 0.00010, "mode": "train"}
[12/05 12:22:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "107", "cur_iter": "1", "dt": 1.31183, "dt_data": 0.77153, "dt_net": 0.54030, "eta": "0:00:01", "loss": 0.30028, "lr": 0.00010, "mode": "train"}
[12/05 12:22:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "108", "cur_iter": "1", "dt": 1.31021, "dt_data": 0.77039, "dt_net": 0.53983, "eta": "0:00:01", "loss": 0.27901, "lr": 0.00010, "mode": "train"}
[12/05 12:22:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "109", "cur_iter": "1", "dt": 1.30794, "dt_data": 0.76773, "dt_net": 0.54021, "eta": "0:00:01", "loss": 0.27493, "lr": 0.00010, "mode": "train"}
[12/05 12:22:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 1.31064, "dt_data": 0.77038, "dt_net": 0.54026, "eta": "0:00:01", "loss": 0.27670, "lr": 0.00010, "mode": "train"}
[12/05 12:22:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 0.86259, "dt_data": 0.78840, "dt_net": 0.07418, "eta": "0:00:00", "mode": "val"}
[12/05 12:22:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:22:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:22:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:22:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:22:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:22:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002993 seconds.
[12/05 12:22:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "110", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:22:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "111", "cur_iter": "1", "dt": 1.31124, "dt_data": 0.77143, "dt_net": 0.53981, "eta": "0:00:01", "loss": 0.28124, "lr": 0.00010, "mode": "train"}
[12/05 12:22:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "112", "cur_iter": "1", "dt": 1.31430, "dt_data": 0.77397, "dt_net": 0.54033, "eta": "0:00:01", "loss": 0.28616, "lr": 0.00010, "mode": "train"}
[12/05 12:22:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "113", "cur_iter": "1", "dt": 1.31270, "dt_data": 0.77220, "dt_net": 0.54049, "eta": "0:00:01", "loss": 0.28971, "lr": 0.00010, "mode": "train"}
[12/05 12:22:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "114", "cur_iter": "1", "dt": 1.30977, "dt_data": 0.77004, "dt_net": 0.53972, "eta": "0:00:01", "loss": 0.27474, "lr": 0.00010, "mode": "train"}
[12/05 12:22:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 1.31207, "dt_data": 0.77180, "dt_net": 0.54027, "eta": "0:00:01", "loss": 0.28694, "lr": 0.00010, "mode": "train"}
[12/05 12:22:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 0.87281, "dt_data": 0.79880, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/05 12:22:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:22:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:22:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:22:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:22:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:22:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003057 seconds.
[12/05 12:22:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "115", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:22:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "116", "cur_iter": "1", "dt": 1.30973, "dt_data": 0.77124, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.34557, "lr": 0.00010, "mode": "train"}
[12/05 12:22:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "117", "cur_iter": "1", "dt": 1.31062, "dt_data": 0.77262, "dt_net": 0.53800, "eta": "0:00:01", "loss": 0.28824, "lr": 0.00010, "mode": "train"}
[12/05 12:22:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "118", "cur_iter": "1", "dt": 1.30574, "dt_data": 0.76816, "dt_net": 0.53758, "eta": "0:00:01", "loss": 0.27780, "lr": 0.00010, "mode": "train"}
[12/05 12:22:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "119", "cur_iter": "1", "dt": 1.31021, "dt_data": 0.77209, "dt_net": 0.53811, "eta": "0:00:01", "loss": 0.29137, "lr": 0.00010, "mode": "train"}
[12/05 12:22:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 1.30850, "dt_data": 0.77088, "dt_net": 0.53762, "eta": "0:00:01", "loss": 0.28543, "lr": 0.00010, "mode": "train"}
[12/05 12:22:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 0.85819, "dt_data": 0.78401, "dt_net": 0.07418, "eta": "0:00:00", "mode": "val"}
[12/05 12:22:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:22:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:22:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:22:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:22:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:22:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003148 seconds.
[12/05 12:22:44][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "120", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:22:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "121", "cur_iter": "1", "dt": 1.31063, "dt_data": 0.77279, "dt_net": 0.53784, "eta": "0:00:01", "loss": 0.27793, "lr": 0.00010, "mode": "train"}
[12/05 12:22:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "122", "cur_iter": "1", "dt": 1.31126, "dt_data": 0.77306, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.28301, "lr": 0.00010, "mode": "train"}
[12/05 12:22:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "123", "cur_iter": "1", "dt": 1.30816, "dt_data": 0.76974, "dt_net": 0.53841, "eta": "0:00:01", "loss": 0.27133, "lr": 0.00010, "mode": "train"}
[12/05 12:22:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "124", "cur_iter": "1", "dt": 1.30683, "dt_data": 0.76918, "dt_net": 0.53765, "eta": "0:00:01", "loss": 0.28597, "lr": 0.00010, "mode": "train"}
[12/05 12:22:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 1.30836, "dt_data": 0.77028, "dt_net": 0.53807, "eta": "0:00:01", "loss": 0.28178, "lr": 0.00010, "mode": "train"}
[12/05 12:22:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 0.87078, "dt_data": 0.79677, "dt_net": 0.07400, "eta": "0:00:00", "mode": "val"}
[12/05 12:22:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:22:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:22:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:22:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:22:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:22:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:22:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003055 seconds.
[12/05 12:22:52][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "125", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:22:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "126", "cur_iter": "1", "dt": 1.31046, "dt_data": 0.77212, "dt_net": 0.53834, "eta": "0:00:01", "loss": 0.29856, "lr": 0.00010, "mode": "train"}
[12/05 12:22:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "127", "cur_iter": "1", "dt": 1.31003, "dt_data": 0.77249, "dt_net": 0.53754, "eta": "0:00:01", "loss": 0.28183, "lr": 0.00010, "mode": "train"}
[12/05 12:22:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "128", "cur_iter": "1", "dt": 1.30880, "dt_data": 0.77047, "dt_net": 0.53833, "eta": "0:00:01", "loss": 0.28772, "lr": 0.00010, "mode": "train"}
[12/05 12:22:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "129", "cur_iter": "1", "dt": 1.31118, "dt_data": 0.77261, "dt_net": 0.53856, "eta": "0:00:01", "loss": 0.28515, "lr": 0.00010, "mode": "train"}
[12/05 12:22:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 1.31298, "dt_data": 0.77499, "dt_net": 0.53799, "eta": "0:00:01", "loss": 0.27888, "lr": 0.00010, "mode": "train"}
[12/05 12:23:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 0.87739, "dt_data": 0.80346, "dt_net": 0.07392, "eta": "0:00:00", "mode": "val"}
[12/05 12:23:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:23:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:23:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:23:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:23:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:23:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003042 seconds.
[12/05 12:23:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "130", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:23:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "131", "cur_iter": "1", "dt": 1.30836, "dt_data": 0.77057, "dt_net": 0.53778, "eta": "0:00:01", "loss": 0.27336, "lr": 0.00010, "mode": "train"}
[12/05 12:23:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "132", "cur_iter": "1", "dt": 1.30750, "dt_data": 0.76959, "dt_net": 0.53790, "eta": "0:00:01", "loss": 0.27891, "lr": 0.00010, "mode": "train"}
[12/05 12:23:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "133", "cur_iter": "1", "dt": 1.30852, "dt_data": 0.77072, "dt_net": 0.53780, "eta": "0:00:01", "loss": 0.27835, "lr": 0.00010, "mode": "train"}
[12/05 12:23:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "134", "cur_iter": "1", "dt": 1.31055, "dt_data": 0.77291, "dt_net": 0.53765, "eta": "0:00:01", "loss": 0.29218, "lr": 0.00010, "mode": "train"}
[12/05 12:23:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 1.30833, "dt_data": 0.76992, "dt_net": 0.53841, "eta": "0:00:01", "loss": 0.27327, "lr": 0.00010, "mode": "train"}
[12/05 12:23:09][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 0.86068, "dt_data": 0.78663, "dt_net": 0.07405, "eta": "0:00:00", "mode": "val"}
[12/05 12:23:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:23:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:23:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:23:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:23:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:23:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003142 seconds.
[12/05 12:23:10][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "135", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:23:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "136", "cur_iter": "1", "dt": 1.30903, "dt_data": 0.77064, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.27485, "lr": 0.00010, "mode": "train"}
[12/05 12:23:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "137", "cur_iter": "1", "dt": 1.30657, "dt_data": 0.76879, "dt_net": 0.53778, "eta": "0:00:01", "loss": 0.27743, "lr": 0.00010, "mode": "train"}
[12/05 12:23:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "138", "cur_iter": "1", "dt": 1.30840, "dt_data": 0.77037, "dt_net": 0.53803, "eta": "0:00:01", "loss": 0.28987, "lr": 0.00010, "mode": "train"}
[12/05 12:23:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "139", "cur_iter": "1", "dt": 1.30596, "dt_data": 0.76813, "dt_net": 0.53783, "eta": "0:00:01", "loss": 0.29229, "lr": 0.00010, "mode": "train"}
[12/05 12:23:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 1.31179, "dt_data": 0.77411, "dt_net": 0.53768, "eta": "0:00:01", "loss": 0.28854, "lr": 0.00010, "mode": "train"}
[12/05 12:23:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 0.87485, "dt_data": 0.80113, "dt_net": 0.07371, "eta": "0:00:00", "mode": "val"}
[12/05 12:23:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:23:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:23:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:23:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:23:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:23:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003025 seconds.
[12/05 12:23:18][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "140", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:23:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "141", "cur_iter": "1", "dt": 1.31108, "dt_data": 0.77339, "dt_net": 0.53768, "eta": "0:00:01", "loss": 0.28185, "lr": 0.00010, "mode": "train"}
[12/05 12:23:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "142", "cur_iter": "1", "dt": 1.30789, "dt_data": 0.76938, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.28375, "lr": 0.00010, "mode": "train"}
[12/05 12:23:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "143", "cur_iter": "1", "dt": 1.31051, "dt_data": 0.77250, "dt_net": 0.53801, "eta": "0:00:01", "loss": 0.28120, "lr": 0.00010, "mode": "train"}
[12/05 12:23:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "144", "cur_iter": "1", "dt": 1.30737, "dt_data": 0.76932, "dt_net": 0.53804, "eta": "0:00:01", "loss": 0.28535, "lr": 0.00010, "mode": "train"}
[12/05 12:23:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 1.30859, "dt_data": 0.77014, "dt_net": 0.53845, "eta": "0:00:01", "loss": 0.27353, "lr": 0.00010, "mode": "train"}
[12/05 12:23:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 0.87027, "dt_data": 0.79621, "dt_net": 0.07405, "eta": "0:00:00", "mode": "val"}
[12/05 12:23:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:23:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:23:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:23:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:23:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:23:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003193 seconds.
[12/05 12:23:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "145", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:23:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "146", "cur_iter": "1", "dt": 1.30926, "dt_data": 0.77089, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.30733, "lr": 0.00010, "mode": "train"}
[12/05 12:23:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "147", "cur_iter": "1", "dt": 1.30657, "dt_data": 0.76868, "dt_net": 0.53789, "eta": "0:00:01", "loss": 0.28460, "lr": 0.00010, "mode": "train"}
[12/05 12:23:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "148", "cur_iter": "1", "dt": 1.30894, "dt_data": 0.77026, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.28167, "lr": 0.00010, "mode": "train"}
[12/05 12:23:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "149", "cur_iter": "1", "dt": 1.30923, "dt_data": 0.76952, "dt_net": 0.53970, "eta": "0:00:01", "loss": 0.26952, "lr": 0.00010, "mode": "train"}
[12/05 12:23:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 1.31067, "dt_data": 0.77068, "dt_net": 0.54000, "eta": "0:00:01", "loss": 0.29056, "lr": 0.00010, "mode": "train"}
[12/05 12:23:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 0.87720, "dt_data": 0.80324, "dt_net": 0.07395, "eta": "0:00:00", "mode": "val"}
[12/05 12:23:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:23:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:23:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:23:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:23:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:23:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003094 seconds.
[12/05 12:23:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "150", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:23:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "151", "cur_iter": "1", "dt": 1.31405, "dt_data": 0.77404, "dt_net": 0.54001, "eta": "0:00:01", "loss": 0.30488, "lr": 0.00010, "mode": "train"}
[12/05 12:23:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "152", "cur_iter": "1", "dt": 1.31117, "dt_data": 0.77079, "dt_net": 0.54038, "eta": "0:00:01", "loss": 0.29542, "lr": 0.00010, "mode": "train"}
[12/05 12:23:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "153", "cur_iter": "1", "dt": 1.31328, "dt_data": 0.77281, "dt_net": 0.54047, "eta": "0:00:01", "loss": 0.28872, "lr": 0.00010, "mode": "train"}
[12/05 12:23:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "154", "cur_iter": "1", "dt": 1.31152, "dt_data": 0.77094, "dt_net": 0.54058, "eta": "0:00:01", "loss": 0.27463, "lr": 0.00010, "mode": "train"}
[12/05 12:23:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 1.31131, "dt_data": 0.77130, "dt_net": 0.54001, "eta": "0:00:01", "loss": 0.27471, "lr": 0.00010, "mode": "train"}
[12/05 12:23:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 0.87866, "dt_data": 0.80472, "dt_net": 0.07394, "eta": "0:00:00", "mode": "val"}
[12/05 12:23:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:23:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:23:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:23:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:23:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:23:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003007 seconds.
[12/05 12:23:44][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "155", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:23:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "156", "cur_iter": "1", "dt": 1.31131, "dt_data": 0.77157, "dt_net": 0.53974, "eta": "0:00:01", "loss": 0.27527, "lr": 0.00010, "mode": "train"}
[12/05 12:23:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "157", "cur_iter": "1", "dt": 1.31332, "dt_data": 0.77306, "dt_net": 0.54026, "eta": "0:00:01", "loss": 0.30098, "lr": 0.00010, "mode": "train"}
[12/05 12:23:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "158", "cur_iter": "1", "dt": 1.31097, "dt_data": 0.77058, "dt_net": 0.54039, "eta": "0:00:01", "loss": 0.28629, "lr": 0.00010, "mode": "train"}
[12/05 12:23:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "159", "cur_iter": "1", "dt": 1.31183, "dt_data": 0.77221, "dt_net": 0.53962, "eta": "0:00:01", "loss": 0.28121, "lr": 0.00010, "mode": "train"}
[12/05 12:23:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 1.31341, "dt_data": 0.77325, "dt_net": 0.54016, "eta": "0:00:01", "loss": 0.27500, "lr": 0.00010, "mode": "train"}
[12/05 12:23:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 0.87228, "dt_data": 0.79790, "dt_net": 0.07437, "eta": "0:00:00", "mode": "val"}
[12/05 12:23:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:23:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:23:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:23:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:23:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:23:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:23:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003125 seconds.
[12/05 12:23:52][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "160", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:23:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "161", "cur_iter": "1", "dt": 1.30884, "dt_data": 0.76857, "dt_net": 0.54027, "eta": "0:00:01", "loss": 0.29371, "lr": 0.00010, "mode": "train"}
[12/05 12:23:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "162", "cur_iter": "1", "dt": 1.30905, "dt_data": 0.76933, "dt_net": 0.53972, "eta": "0:00:01", "loss": 0.27327, "lr": 0.00010, "mode": "train"}
[12/05 12:23:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "163", "cur_iter": "1", "dt": 1.31110, "dt_data": 0.77108, "dt_net": 0.54002, "eta": "0:00:01", "loss": 0.29019, "lr": 0.00010, "mode": "train"}
[12/05 12:23:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "164", "cur_iter": "1", "dt": 1.31275, "dt_data": 0.77237, "dt_net": 0.54038, "eta": "0:00:01", "loss": 0.27735, "lr": 0.00010, "mode": "train"}
[12/05 12:23:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 1.31440, "dt_data": 0.77430, "dt_net": 0.54010, "eta": "0:00:01", "loss": 0.28208, "lr": 0.00010, "mode": "train"}
[12/05 12:24:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 0.87824, "dt_data": 0.80413, "dt_net": 0.07410, "eta": "0:00:00", "mode": "val"}
[12/05 12:24:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:24:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:24:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:24:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:24:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:24:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003087 seconds.
[12/05 12:24:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "165", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:24:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "166", "cur_iter": "1", "dt": 1.31361, "dt_data": 0.77371, "dt_net": 0.53990, "eta": "0:00:01", "loss": 0.27074, "lr": 0.00010, "mode": "train"}
[12/05 12:24:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "167", "cur_iter": "1", "dt": 1.31298, "dt_data": 0.77283, "dt_net": 0.54015, "eta": "0:00:01", "loss": 0.28305, "lr": 0.00010, "mode": "train"}
[12/05 12:24:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "168", "cur_iter": "1", "dt": 1.31456, "dt_data": 0.77463, "dt_net": 0.53992, "eta": "0:00:01", "loss": 0.27935, "lr": 0.00010, "mode": "train"}
[12/05 12:24:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "169", "cur_iter": "1", "dt": 1.30876, "dt_data": 0.76909, "dt_net": 0.53968, "eta": "0:00:01", "loss": 0.28983, "lr": 0.00010, "mode": "train"}
[12/05 12:24:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 1.31335, "dt_data": 0.77294, "dt_net": 0.54041, "eta": "0:00:01", "loss": 0.27828, "lr": 0.00010, "mode": "train"}
[12/05 12:24:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 0.87036, "dt_data": 0.79641, "dt_net": 0.07395, "eta": "0:00:00", "mode": "val"}
[12/05 12:24:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:24:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:24:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:24:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:24:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:24:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003023 seconds.
[12/05 12:24:10][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "170", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:24:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "171", "cur_iter": "1", "dt": 1.31128, "dt_data": 0.77075, "dt_net": 0.54053, "eta": "0:00:01", "loss": 0.27802, "lr": 0.00010, "mode": "train"}
[12/05 12:24:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "172", "cur_iter": "1", "dt": 1.31216, "dt_data": 0.77246, "dt_net": 0.53970, "eta": "0:00:01", "loss": 0.27716, "lr": 0.00010, "mode": "train"}
[12/05 12:24:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "173", "cur_iter": "1", "dt": 1.31088, "dt_data": 0.77077, "dt_net": 0.54011, "eta": "0:00:01", "loss": 0.28231, "lr": 0.00010, "mode": "train"}
[12/05 12:24:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "174", "cur_iter": "1", "dt": 1.31186, "dt_data": 0.77217, "dt_net": 0.53969, "eta": "0:00:01", "loss": 0.27037, "lr": 0.00010, "mode": "train"}
[12/05 12:24:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 1.31378, "dt_data": 0.77400, "dt_net": 0.53977, "eta": "0:00:01", "loss": 0.27426, "lr": 0.00010, "mode": "train"}
[12/05 12:24:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 0.87808, "dt_data": 0.80416, "dt_net": 0.07392, "eta": "0:00:00", "mode": "val"}
[12/05 12:24:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:24:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:24:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:24:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:24:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:24:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003006 seconds.
[12/05 12:24:18][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "175", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:24:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "176", "cur_iter": "1", "dt": 1.31426, "dt_data": 0.77401, "dt_net": 0.54025, "eta": "0:00:01", "loss": 0.27540, "lr": 0.00010, "mode": "train"}
[12/05 12:24:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "177", "cur_iter": "1", "dt": 1.31058, "dt_data": 0.77045, "dt_net": 0.54013, "eta": "0:00:01", "loss": 0.28408, "lr": 0.00010, "mode": "train"}
[12/05 12:24:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "178", "cur_iter": "1", "dt": 1.31147, "dt_data": 0.77149, "dt_net": 0.53997, "eta": "0:00:01", "loss": 0.27329, "lr": 0.00010, "mode": "train"}
[12/05 12:24:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "179", "cur_iter": "1", "dt": 1.31145, "dt_data": 0.77104, "dt_net": 0.54041, "eta": "0:00:01", "loss": 0.28810, "lr": 0.00010, "mode": "train"}
[12/05 12:24:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 1.31697, "dt_data": 0.77639, "dt_net": 0.54058, "eta": "0:00:01", "loss": 0.27444, "lr": 0.00010, "mode": "train"}
[12/05 12:24:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 0.87879, "dt_data": 0.80477, "dt_net": 0.07402, "eta": "0:00:00", "mode": "val"}
[12/05 12:24:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:24:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:24:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:24:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:24:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:24:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003131 seconds.
[12/05 12:24:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "180", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:24:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "181", "cur_iter": "1", "dt": 1.31088, "dt_data": 0.77068, "dt_net": 0.54020, "eta": "0:00:01", "loss": 0.27949, "lr": 0.00010, "mode": "train"}
[12/05 12:24:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "182", "cur_iter": "1", "dt": 1.31034, "dt_data": 0.77050, "dt_net": 0.53984, "eta": "0:00:01", "loss": 0.27712, "lr": 0.00010, "mode": "train"}
[12/05 12:24:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "183", "cur_iter": "1", "dt": 1.31214, "dt_data": 0.77181, "dt_net": 0.54033, "eta": "0:00:01", "loss": 0.28321, "lr": 0.00010, "mode": "train"}
[12/05 12:24:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "184", "cur_iter": "1", "dt": 1.31034, "dt_data": 0.77004, "dt_net": 0.54030, "eta": "0:00:01", "loss": 0.28119, "lr": 0.00010, "mode": "train"}
[12/05 12:24:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 1.31267, "dt_data": 0.77244, "dt_net": 0.54022, "eta": "0:00:01", "loss": 0.27287, "lr": 0.00010, "mode": "train"}
[12/05 12:24:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 0.87405, "dt_data": 0.80008, "dt_net": 0.07396, "eta": "0:00:00", "mode": "val"}
[12/05 12:24:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:24:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:24:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:24:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:24:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:24:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003065 seconds.
[12/05 12:24:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "185", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:24:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "186", "cur_iter": "1", "dt": 1.31161, "dt_data": 0.77351, "dt_net": 0.53810, "eta": "0:00:01", "loss": 0.28020, "lr": 0.00010, "mode": "train"}
[12/05 12:24:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "187", "cur_iter": "1", "dt": 1.31016, "dt_data": 0.77232, "dt_net": 0.53784, "eta": "0:00:01", "loss": 0.28263, "lr": 0.00010, "mode": "train"}
[12/05 12:24:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "188", "cur_iter": "1", "dt": 1.30975, "dt_data": 0.77161, "dt_net": 0.53814, "eta": "0:00:01", "loss": 0.30450, "lr": 0.00010, "mode": "train"}
[12/05 12:24:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "189", "cur_iter": "1", "dt": 1.30830, "dt_data": 0.77033, "dt_net": 0.53796, "eta": "0:00:01", "loss": 0.27486, "lr": 0.00010, "mode": "train"}
[12/05 12:24:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 1.30922, "dt_data": 0.77097, "dt_net": 0.53825, "eta": "0:00:01", "loss": 0.27323, "lr": 0.00010, "mode": "train"}
[12/05 12:24:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 0.87140, "dt_data": 0.79754, "dt_net": 0.07385, "eta": "0:00:00", "mode": "val"}
[12/05 12:24:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:24:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:24:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:24:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:24:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:24:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003128 seconds.
[12/05 12:24:44][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "190", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:24:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "191", "cur_iter": "1", "dt": 1.31196, "dt_data": 0.77400, "dt_net": 0.53796, "eta": "0:00:01", "loss": 0.27791, "lr": 0.00010, "mode": "train"}
[12/05 12:24:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "192", "cur_iter": "1", "dt": 1.30758, "dt_data": 0.76940, "dt_net": 0.53818, "eta": "0:00:01", "loss": 0.27453, "lr": 0.00010, "mode": "train"}
[12/05 12:24:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "193", "cur_iter": "1", "dt": 1.31003, "dt_data": 0.77179, "dt_net": 0.53824, "eta": "0:00:01", "loss": 0.29928, "lr": 0.00010, "mode": "train"}
[12/05 12:24:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "194", "cur_iter": "1", "dt": 1.30805, "dt_data": 0.77016, "dt_net": 0.53789, "eta": "0:00:01", "loss": 0.27297, "lr": 0.00010, "mode": "train"}
[12/05 12:24:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 1.30967, "dt_data": 0.77150, "dt_net": 0.53817, "eta": "0:00:01", "loss": 0.27285, "lr": 0.00010, "mode": "train"}
[12/05 12:24:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 0.87208, "dt_data": 0.79836, "dt_net": 0.07372, "eta": "0:00:00", "mode": "val"}
[12/05 12:24:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:24:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:24:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:24:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:24:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:24:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:24:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003079 seconds.
[12/05 12:24:52][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "195", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:24:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "196", "cur_iter": "1", "dt": 1.31145, "dt_data": 0.77314, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.26932, "lr": 0.00010, "mode": "train"}
[12/05 12:24:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "197", "cur_iter": "1", "dt": 1.30962, "dt_data": 0.77167, "dt_net": 0.53794, "eta": "0:00:01", "loss": 0.28152, "lr": 0.00010, "mode": "train"}
[12/05 12:24:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "198", "cur_iter": "1", "dt": 1.30848, "dt_data": 0.76991, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.28333, "lr": 0.00010, "mode": "train"}
[12/05 12:24:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "199", "cur_iter": "1", "dt": 1.30663, "dt_data": 0.76870, "dt_net": 0.53793, "eta": "0:00:01", "loss": 0.27765, "lr": 0.00010, "mode": "train"}
[12/05 12:24:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 1.30862, "dt_data": 0.77095, "dt_net": 0.53767, "eta": "0:00:01", "loss": 0.28411, "lr": 0.00010, "mode": "train"}
[12/05 12:25:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 0.87498, "dt_data": 0.80116, "dt_net": 0.07382, "eta": "0:00:00", "mode": "val"}
[12/05 12:25:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:25:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:25:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:25:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:25:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:25:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003130 seconds.
[12/05 12:25:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "200", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:25:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "201", "cur_iter": "1", "dt": 1.31125, "dt_data": 0.77334, "dt_net": 0.53791, "eta": "0:00:01", "loss": 0.27387, "lr": 0.00010, "mode": "train"}
[12/05 12:25:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "202", "cur_iter": "1", "dt": 1.30820, "dt_data": 0.76991, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.28001, "lr": 0.00010, "mode": "train"}
[12/05 12:25:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "203", "cur_iter": "1", "dt": 1.30973, "dt_data": 0.77196, "dt_net": 0.53777, "eta": "0:00:01", "loss": 0.26882, "lr": 0.00010, "mode": "train"}
[12/05 12:25:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "204", "cur_iter": "1", "dt": 1.31255, "dt_data": 0.77483, "dt_net": 0.53772, "eta": "0:00:01", "loss": 0.27247, "lr": 0.00010, "mode": "train"}
[12/05 12:25:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 1.31330, "dt_data": 0.77499, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.28145, "lr": 0.00010, "mode": "train"}
[12/05 12:25:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 0.87846, "dt_data": 0.80432, "dt_net": 0.07413, "eta": "0:00:00", "mode": "val"}
[12/05 12:25:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:25:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:25:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:25:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:25:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:25:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003099 seconds.
[12/05 12:25:10][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "205", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:25:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "206", "cur_iter": "1", "dt": 1.31364, "dt_data": 0.77537, "dt_net": 0.53826, "eta": "0:00:01", "loss": 0.27343, "lr": 0.00010, "mode": "train"}
[12/05 12:25:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "207", "cur_iter": "1", "dt": 1.30851, "dt_data": 0.77069, "dt_net": 0.53782, "eta": "0:00:01", "loss": 0.28946, "lr": 0.00010, "mode": "train"}
[12/05 12:25:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "208", "cur_iter": "1", "dt": 1.30978, "dt_data": 0.77128, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.27834, "lr": 0.00010, "mode": "train"}
[12/05 12:25:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "209", "cur_iter": "1", "dt": 1.30696, "dt_data": 0.76940, "dt_net": 0.53756, "eta": "0:00:01", "loss": 0.27598, "lr": 0.00010, "mode": "train"}
[12/05 12:25:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 1.31352, "dt_data": 0.77579, "dt_net": 0.53773, "eta": "0:00:01", "loss": 0.28068, "lr": 0.00010, "mode": "train"}
[12/05 12:25:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 0.87051, "dt_data": 0.79680, "dt_net": 0.07370, "eta": "0:00:00", "mode": "val"}
[12/05 12:25:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:25:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:25:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:25:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:25:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:25:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003136 seconds.
[12/05 12:25:18][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "210", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:25:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "211", "cur_iter": "1", "dt": 1.31127, "dt_data": 0.77297, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.27182, "lr": 0.00010, "mode": "train"}
[12/05 12:25:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "212", "cur_iter": "1", "dt": 1.30925, "dt_data": 0.77063, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.27776, "lr": 0.00010, "mode": "train"}
[12/05 12:25:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "213", "cur_iter": "1", "dt": 1.30842, "dt_data": 0.77034, "dt_net": 0.53807, "eta": "0:00:01", "loss": 0.28032, "lr": 0.00010, "mode": "train"}
[12/05 12:25:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "214", "cur_iter": "1", "dt": 1.30816, "dt_data": 0.76986, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.27923, "lr": 0.00010, "mode": "train"}
[12/05 12:25:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 1.30829, "dt_data": 0.77016, "dt_net": 0.53813, "eta": "0:00:01", "loss": 0.27590, "lr": 0.00010, "mode": "train"}
[12/05 12:25:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 0.87416, "dt_data": 0.80033, "dt_net": 0.07382, "eta": "0:00:00", "mode": "val"}
[12/05 12:25:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:25:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:25:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:25:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:25:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:25:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003197 seconds.
[12/05 12:25:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "215", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:25:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "216", "cur_iter": "1", "dt": 1.30978, "dt_data": 0.77125, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.27695, "lr": 0.00010, "mode": "train"}
[12/05 12:25:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "217", "cur_iter": "1", "dt": 1.31036, "dt_data": 0.77038, "dt_net": 0.53998, "eta": "0:00:01", "loss": 0.27534, "lr": 0.00010, "mode": "train"}
[12/05 12:25:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "218", "cur_iter": "1", "dt": 1.31209, "dt_data": 0.77185, "dt_net": 0.54024, "eta": "0:00:01", "loss": 0.28062, "lr": 0.00010, "mode": "train"}
[12/05 12:25:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "219", "cur_iter": "1", "dt": 1.31023, "dt_data": 0.77051, "dt_net": 0.53972, "eta": "0:00:01", "loss": 0.27160, "lr": 0.00010, "mode": "train"}
[12/05 12:25:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 1.31662, "dt_data": 0.77609, "dt_net": 0.54052, "eta": "0:00:01", "loss": 0.26970, "lr": 0.00010, "mode": "train"}
[12/05 12:25:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 0.87172, "dt_data": 0.79774, "dt_net": 0.07398, "eta": "0:00:00", "mode": "val"}
[12/05 12:25:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:25:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:25:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:25:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:25:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:25:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003061 seconds.
[12/05 12:25:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "220", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:25:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "221", "cur_iter": "1", "dt": 1.31424, "dt_data": 0.77417, "dt_net": 0.54007, "eta": "0:00:01", "loss": 0.28428, "lr": 0.00010, "mode": "train"}
[12/05 12:25:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "222", "cur_iter": "1", "dt": 1.31045, "dt_data": 0.76995, "dt_net": 0.54050, "eta": "0:00:01", "loss": 0.30382, "lr": 0.00010, "mode": "train"}
[12/05 12:25:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "223", "cur_iter": "1", "dt": 1.31127, "dt_data": 0.77141, "dt_net": 0.53985, "eta": "0:00:01", "loss": 0.27617, "lr": 0.00010, "mode": "train"}
[12/05 12:25:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "224", "cur_iter": "1", "dt": 1.30968, "dt_data": 0.76953, "dt_net": 0.54015, "eta": "0:00:01", "loss": 0.28101, "lr": 0.00010, "mode": "train"}
[12/05 12:25:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 1.31085, "dt_data": 0.77121, "dt_net": 0.53963, "eta": "0:00:01", "loss": 0.27434, "lr": 0.00010, "mode": "train"}
[12/05 12:25:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 0.86638, "dt_data": 0.79238, "dt_net": 0.07399, "eta": "0:00:00", "mode": "val"}
[12/05 12:25:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:25:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:25:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:25:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:25:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:25:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003043 seconds.
[12/05 12:25:44][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "225", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:25:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "226", "cur_iter": "1", "dt": 1.30896, "dt_data": 0.76897, "dt_net": 0.53999, "eta": "0:00:01", "loss": 0.27031, "lr": 0.00010, "mode": "train"}
[12/05 12:25:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "227", "cur_iter": "1", "dt": 1.31257, "dt_data": 0.77212, "dt_net": 0.54045, "eta": "0:00:01", "loss": 0.27252, "lr": 0.00010, "mode": "train"}
[12/05 12:25:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "228", "cur_iter": "1", "dt": 1.31016, "dt_data": 0.76988, "dt_net": 0.54028, "eta": "0:00:01", "loss": 0.27709, "lr": 0.00010, "mode": "train"}
[12/05 12:25:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "229", "cur_iter": "1", "dt": 1.31004, "dt_data": 0.76999, "dt_net": 0.54005, "eta": "0:00:01", "loss": 0.28339, "lr": 0.00010, "mode": "train"}
[12/05 12:25:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 1.31091, "dt_data": 0.77086, "dt_net": 0.54005, "eta": "0:00:01", "loss": 0.27383, "lr": 0.00010, "mode": "train"}
[12/05 12:25:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 0.87410, "dt_data": 0.80011, "dt_net": 0.07398, "eta": "0:00:00", "mode": "val"}
[12/05 12:25:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:25:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:25:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:25:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:25:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:25:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:25:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003111 seconds.
[12/05 12:25:52][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "230", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:25:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "231", "cur_iter": "1", "dt": 1.31261, "dt_data": 0.77227, "dt_net": 0.54034, "eta": "0:00:01", "loss": 0.26937, "lr": 0.00010, "mode": "train"}
[12/05 12:25:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "232", "cur_iter": "1", "dt": 1.30908, "dt_data": 0.76917, "dt_net": 0.53991, "eta": "0:00:01", "loss": 0.27085, "lr": 0.00010, "mode": "train"}
[12/05 12:25:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "233", "cur_iter": "1", "dt": 1.31137, "dt_data": 0.77116, "dt_net": 0.54021, "eta": "0:00:01", "loss": 0.27643, "lr": 0.00010, "mode": "train"}
[12/05 12:25:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "234", "cur_iter": "1", "dt": 1.30931, "dt_data": 0.76915, "dt_net": 0.54016, "eta": "0:00:01", "loss": 0.27030, "lr": 0.00010, "mode": "train"}
[12/05 12:25:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 1.31032, "dt_data": 0.77042, "dt_net": 0.53990, "eta": "0:00:01", "loss": 0.27750, "lr": 0.00010, "mode": "train"}
[12/05 12:26:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 0.88198, "dt_data": 0.80783, "dt_net": 0.07414, "eta": "0:00:00", "mode": "val"}
[12/05 12:26:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:26:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:26:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:26:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:26:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:26:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003003 seconds.
[12/05 12:26:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "235", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:26:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "236", "cur_iter": "1", "dt": 1.31479, "dt_data": 0.77476, "dt_net": 0.54002, "eta": "0:00:01", "loss": 0.26965, "lr": 0.00010, "mode": "train"}
[12/05 12:26:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "237", "cur_iter": "1", "dt": 1.31146, "dt_data": 0.77108, "dt_net": 0.54037, "eta": "0:00:01", "loss": 0.27344, "lr": 0.00010, "mode": "train"}
[12/05 12:26:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "238", "cur_iter": "1", "dt": 1.31229, "dt_data": 0.77226, "dt_net": 0.54003, "eta": "0:00:01", "loss": 0.28403, "lr": 0.00010, "mode": "train"}
[12/05 12:26:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "239", "cur_iter": "1", "dt": 1.31571, "dt_data": 0.77582, "dt_net": 0.53988, "eta": "0:00:01", "loss": 0.27159, "lr": 0.00010, "mode": "train"}
[12/05 12:26:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 1.31599, "dt_data": 0.77582, "dt_net": 0.54017, "eta": "0:00:01", "loss": 0.27871, "lr": 0.00010, "mode": "train"}
[12/05 12:26:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 0.87520, "dt_data": 0.80115, "dt_net": 0.07404, "eta": "0:00:00", "mode": "val"}
[12/05 12:26:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:26:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:26:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:26:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:26:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:26:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003013 seconds.
[12/05 12:26:10][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "240", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:26:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "241", "cur_iter": "1", "dt": 1.31295, "dt_data": 0.77268, "dt_net": 0.54026, "eta": "0:00:01", "loss": 0.28356, "lr": 0.00010, "mode": "train"}
[12/05 12:26:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "242", "cur_iter": "1", "dt": 1.30968, "dt_data": 0.76981, "dt_net": 0.53987, "eta": "0:00:01", "loss": 0.28100, "lr": 0.00010, "mode": "train"}
[12/05 12:26:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "243", "cur_iter": "1", "dt": 1.31131, "dt_data": 0.77077, "dt_net": 0.54054, "eta": "0:00:01", "loss": 0.26717, "lr": 0.00010, "mode": "train"}
[12/05 12:26:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "244", "cur_iter": "1", "dt": 1.31341, "dt_data": 0.77355, "dt_net": 0.53986, "eta": "0:00:01", "loss": 0.26867, "lr": 0.00010, "mode": "train"}
[12/05 12:26:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 1.31451, "dt_data": 0.77410, "dt_net": 0.54041, "eta": "0:00:01", "loss": 0.29255, "lr": 0.00010, "mode": "train"}
[12/05 12:26:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 0.87320, "dt_data": 0.79891, "dt_net": 0.07428, "eta": "0:00:00", "mode": "val"}
[12/05 12:26:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:26:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:26:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:26:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:26:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:26:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003110 seconds.
[12/05 12:26:18][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "245", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:26:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "246", "cur_iter": "1", "dt": 1.31119, "dt_data": 0.77070, "dt_net": 0.54048, "eta": "0:00:01", "loss": 0.28201, "lr": 0.00010, "mode": "train"}
[12/05 12:26:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "247", "cur_iter": "1", "dt": 1.30830, "dt_data": 0.76847, "dt_net": 0.53983, "eta": "0:00:01", "loss": 0.26833, "lr": 0.00010, "mode": "train"}
[12/05 12:26:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "248", "cur_iter": "1", "dt": 1.31507, "dt_data": 0.77506, "dt_net": 0.54000, "eta": "0:00:01", "loss": 0.27743, "lr": 0.00010, "mode": "train"}
[12/05 12:26:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "249", "cur_iter": "1", "dt": 1.30935, "dt_data": 0.76926, "dt_net": 0.54009, "eta": "0:00:01", "loss": 0.27150, "lr": 0.00010, "mode": "train"}
[12/05 12:26:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 1.31052, "dt_data": 0.77092, "dt_net": 0.53960, "eta": "0:00:01", "loss": 0.27052, "lr": 0.00010, "mode": "train"}
[12/05 12:26:27][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 0.85977, "dt_data": 0.78571, "dt_net": 0.07406, "eta": "0:00:00", "mode": "val"}
[12/05 12:26:27][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:26:27][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:26:27][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:26:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:27][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:26:27][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:27][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:26:27][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002989 seconds.
[12/05 12:26:27][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "250", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:26:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "251", "cur_iter": "1", "dt": 1.31844, "dt_data": 0.77865, "dt_net": 0.53979, "eta": "0:00:01", "loss": 0.27984, "lr": 0.00010, "mode": "train"}
[12/05 12:26:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "252", "cur_iter": "1", "dt": 1.31005, "dt_data": 0.76959, "dt_net": 0.54046, "eta": "0:00:01", "loss": 0.27858, "lr": 0.00010, "mode": "train"}
[12/05 12:26:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "253", "cur_iter": "1", "dt": 1.31170, "dt_data": 0.77170, "dt_net": 0.54000, "eta": "0:00:01", "loss": 0.28563, "lr": 0.00010, "mode": "train"}
[12/05 12:26:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "254", "cur_iter": "1", "dt": 1.31473, "dt_data": 0.77459, "dt_net": 0.54015, "eta": "0:00:01", "loss": 0.26860, "lr": 0.00010, "mode": "train"}
[12/05 12:26:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 1.31170, "dt_data": 0.77111, "dt_net": 0.54058, "eta": "0:00:01", "loss": 0.27479, "lr": 0.00010, "mode": "train"}
[12/05 12:26:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 0.85299, "dt_data": 0.77880, "dt_net": 0.07419, "eta": "0:00:00", "mode": "val"}
[12/05 12:26:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:26:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:26:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:26:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:26:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:26:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002981 seconds.
[12/05 12:26:35][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "255", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:26:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "256", "cur_iter": "1", "dt": 1.31215, "dt_data": 0.77346, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.27839, "lr": 0.00010, "mode": "train"}
[12/05 12:26:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "257", "cur_iter": "1", "dt": 1.30831, "dt_data": 0.77049, "dt_net": 0.53781, "eta": "0:00:01", "loss": 0.27576, "lr": 0.00010, "mode": "train"}
[12/05 12:26:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "258", "cur_iter": "1", "dt": 1.31483, "dt_data": 0.77733, "dt_net": 0.53749, "eta": "0:00:01", "loss": 0.26591, "lr": 0.00010, "mode": "train"}
[12/05 12:26:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "259", "cur_iter": "1", "dt": 1.30883, "dt_data": 0.77036, "dt_net": 0.53847, "eta": "0:00:01", "loss": 0.28202, "lr": 0.00010, "mode": "train"}
[12/05 12:26:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 1.30925, "dt_data": 0.77133, "dt_net": 0.53792, "eta": "0:00:01", "loss": 0.29436, "lr": 0.00010, "mode": "train"}
[12/05 12:26:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 0.86667, "dt_data": 0.79294, "dt_net": 0.07372, "eta": "0:00:00", "mode": "val"}
[12/05 12:26:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:26:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:26:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:26:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:26:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:26:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002937 seconds.
[12/05 12:26:44][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "260", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:26:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "261", "cur_iter": "1", "dt": 1.30982, "dt_data": 0.77189, "dt_net": 0.53793, "eta": "0:00:01", "loss": 0.27348, "lr": 0.00010, "mode": "train"}
[12/05 12:26:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "262", "cur_iter": "1", "dt": 1.30648, "dt_data": 0.76839, "dt_net": 0.53809, "eta": "0:00:01", "loss": 0.28738, "lr": 0.00010, "mode": "train"}
[12/05 12:26:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "263", "cur_iter": "1", "dt": 1.30782, "dt_data": 0.76969, "dt_net": 0.53813, "eta": "0:00:01", "loss": 0.28807, "lr": 0.00010, "mode": "train"}
[12/05 12:26:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "264", "cur_iter": "1", "dt": 1.30621, "dt_data": 0.76837, "dt_net": 0.53784, "eta": "0:00:01", "loss": 0.26948, "lr": 0.00010, "mode": "train"}
[12/05 12:26:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 1.31195, "dt_data": 0.77403, "dt_net": 0.53792, "eta": "0:00:01", "loss": 0.27123, "lr": 0.00010, "mode": "train"}
[12/05 12:26:53][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 0.89196, "dt_data": 0.81733, "dt_net": 0.07462, "eta": "0:00:00", "mode": "val"}
[12/05 12:26:53][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:26:53][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:26:53][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:26:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:53][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:26:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:26:53][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:26:53][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003343 seconds.
[12/05 12:26:53][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "265", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:26:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "266", "cur_iter": "1", "dt": 1.33074, "dt_data": 0.79206, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.28136, "lr": 0.00010, "mode": "train"}
[12/05 12:26:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "267", "cur_iter": "1", "dt": 1.33787, "dt_data": 0.79962, "dt_net": 0.53826, "eta": "0:00:01", "loss": 0.26827, "lr": 0.00010, "mode": "train"}
[12/05 12:26:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "268", "cur_iter": "1", "dt": 1.35879, "dt_data": 0.82009, "dt_net": 0.53870, "eta": "0:00:01", "loss": 0.27661, "lr": 0.00010, "mode": "train"}
[12/05 12:26:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "269", "cur_iter": "1", "dt": 1.32184, "dt_data": 0.78395, "dt_net": 0.53788, "eta": "0:00:01", "loss": 0.27457, "lr": 0.00010, "mode": "train"}
[12/05 12:27:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 1.33364, "dt_data": 0.79529, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.26919, "lr": 0.00010, "mode": "train"}
[12/05 12:27:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 0.88754, "dt_data": 0.81348, "dt_net": 0.07405, "eta": "0:00:00", "mode": "val"}
[12/05 12:27:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:27:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:27:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:27:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:27:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:27:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002968 seconds.
[12/05 12:27:01][INFO] logging.py:  96: json_stats: {"RAM": "2.37/15.59G", "_type": "val_epoch", "cur_epoch": "270", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:27:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "271", "cur_iter": "1", "dt": 1.33081, "dt_data": 0.79195, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.26598, "lr": 0.00010, "mode": "train"}
[12/05 12:27:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "272", "cur_iter": "1", "dt": 1.34098, "dt_data": 0.80290, "dt_net": 0.53807, "eta": "0:00:01", "loss": 0.28510, "lr": 0.00010, "mode": "train"}
[12/05 12:27:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "273", "cur_iter": "1", "dt": 1.33977, "dt_data": 0.80133, "dt_net": 0.53844, "eta": "0:00:01", "loss": 0.28176, "lr": 0.00010, "mode": "train"}
[12/05 12:27:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "274", "cur_iter": "1", "dt": 1.33752, "dt_data": 0.79925, "dt_net": 0.53827, "eta": "0:00:01", "loss": 0.27512, "lr": 0.00010, "mode": "train"}
[12/05 12:27:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 1.34296, "dt_data": 0.80282, "dt_net": 0.54013, "eta": "0:00:01", "loss": 0.28066, "lr": 0.00010, "mode": "train"}
[12/05 12:27:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 0.86931, "dt_data": 0.79530, "dt_net": 0.07400, "eta": "0:00:00", "mode": "val"}
[12/05 12:27:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:27:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:27:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:27:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:27:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:27:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003359 seconds.
[12/05 12:27:10][INFO] logging.py:  96: json_stats: {"RAM": "2.39/15.59G", "_type": "val_epoch", "cur_epoch": "275", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:27:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "276", "cur_iter": "1", "dt": 1.33835, "dt_data": 0.79807, "dt_net": 0.54028, "eta": "0:00:01", "loss": 0.27701, "lr": 0.00010, "mode": "train"}
[12/05 12:27:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "277", "cur_iter": "1", "dt": 1.32466, "dt_data": 0.78412, "dt_net": 0.54054, "eta": "0:00:01", "loss": 0.26824, "lr": 0.00010, "mode": "train"}
[12/05 12:27:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "278", "cur_iter": "1", "dt": 1.32438, "dt_data": 0.78443, "dt_net": 0.53994, "eta": "0:00:01", "loss": 0.27151, "lr": 0.00010, "mode": "train"}
[12/05 12:27:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "279", "cur_iter": "1", "dt": 1.34005, "dt_data": 0.79915, "dt_net": 0.54090, "eta": "0:00:01", "loss": 0.27230, "lr": 0.00010, "mode": "train"}
[12/05 12:27:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 1.33229, "dt_data": 0.79235, "dt_net": 0.53993, "eta": "0:00:01", "loss": 0.28429, "lr": 0.00010, "mode": "train"}
[12/05 12:27:19][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 0.90865, "dt_data": 0.83457, "dt_net": 0.07407, "eta": "0:00:00", "mode": "val"}
[12/05 12:27:19][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:27:19][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:27:19][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:27:19][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:19][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:27:19][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:19][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:27:19][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002979 seconds.
[12/05 12:27:19][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "280", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:27:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "281", "cur_iter": "1", "dt": 1.33659, "dt_data": 0.79638, "dt_net": 0.54020, "eta": "0:00:01", "loss": 0.26869, "lr": 0.00010, "mode": "train"}
[12/05 12:27:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "282", "cur_iter": "1", "dt": 1.32910, "dt_data": 0.78817, "dt_net": 0.54093, "eta": "0:00:01", "loss": 0.28555, "lr": 0.00010, "mode": "train"}
[12/05 12:27:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "283", "cur_iter": "1", "dt": 1.34455, "dt_data": 0.80404, "dt_net": 0.54051, "eta": "0:00:01", "loss": 0.27787, "lr": 0.00010, "mode": "train"}
[12/05 12:27:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "284", "cur_iter": "1", "dt": 1.34434, "dt_data": 0.80426, "dt_net": 0.54008, "eta": "0:00:01", "loss": 0.27343, "lr": 0.00010, "mode": "train"}
[12/05 12:27:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 1.34123, "dt_data": 0.80094, "dt_net": 0.54028, "eta": "0:00:01", "loss": 0.26861, "lr": 0.00010, "mode": "train"}
[12/05 12:27:28][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 0.89097, "dt_data": 0.81685, "dt_net": 0.07411, "eta": "0:00:00", "mode": "val"}
[12/05 12:27:28][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:27:28][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:27:28][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:27:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:28][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:27:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:28][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:27:28][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003043 seconds.
[12/05 12:27:28][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "285", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:27:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "286", "cur_iter": "1", "dt": 1.34122, "dt_data": 0.80044, "dt_net": 0.54077, "eta": "0:00:01", "loss": 0.27135, "lr": 0.00010, "mode": "train"}
[12/05 12:27:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "287", "cur_iter": "1", "dt": 1.34692, "dt_data": 0.80619, "dt_net": 0.54072, "eta": "0:00:01", "loss": 0.26995, "lr": 0.00010, "mode": "train"}
[12/05 12:27:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "288", "cur_iter": "1", "dt": 1.34678, "dt_data": 0.80627, "dt_net": 0.54050, "eta": "0:00:01", "loss": 0.27633, "lr": 0.00010, "mode": "train"}
[12/05 12:27:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "289", "cur_iter": "1", "dt": 1.33177, "dt_data": 0.79154, "dt_net": 0.54022, "eta": "0:00:01", "loss": 0.28089, "lr": 0.00010, "mode": "train"}
[12/05 12:27:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 1.34065, "dt_data": 0.80000, "dt_net": 0.54065, "eta": "0:00:01", "loss": 0.27478, "lr": 0.00010, "mode": "train"}
[12/05 12:27:36][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 0.87494, "dt_data": 0.80086, "dt_net": 0.07408, "eta": "0:00:00", "mode": "val"}
[12/05 12:27:36][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:27:36][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:27:36][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:27:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:36][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:27:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:36][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:27:36][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003093 seconds.
[12/05 12:27:36][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "290", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:27:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "291", "cur_iter": "1", "dt": 1.32077, "dt_data": 0.78004, "dt_net": 0.54073, "eta": "0:00:01", "loss": 0.27086, "lr": 0.00010, "mode": "train"}
[12/05 12:27:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "292", "cur_iter": "1", "dt": 1.32659, "dt_data": 0.78631, "dt_net": 0.54028, "eta": "0:00:01", "loss": 0.27939, "lr": 0.00010, "mode": "train"}
[12/05 12:27:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "293", "cur_iter": "1", "dt": 1.34269, "dt_data": 0.80217, "dt_net": 0.54052, "eta": "0:00:01", "loss": 0.27185, "lr": 0.00010, "mode": "train"}
[12/05 12:27:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "294", "cur_iter": "1", "dt": 1.34413, "dt_data": 0.80373, "dt_net": 0.54039, "eta": "0:00:01", "loss": 0.26511, "lr": 0.00010, "mode": "train"}
[12/05 12:27:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 1.33861, "dt_data": 0.79839, "dt_net": 0.54022, "eta": "0:00:01", "loss": 0.27986, "lr": 0.00010, "mode": "train"}
[12/05 12:27:45][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 0.89334, "dt_data": 0.81936, "dt_net": 0.07397, "eta": "0:00:00", "mode": "val"}
[12/05 12:27:45][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:27:45][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:27:45][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:27:45][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:45][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:27:45][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:45][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:27:45][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002993 seconds.
[12/05 12:27:45][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "295", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/05 12:27:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "296", "cur_iter": "1", "dt": 1.34102, "dt_data": 0.80135, "dt_net": 0.53967, "eta": "0:00:01", "loss": 0.27534, "lr": 0.00010, "mode": "train"}
[12/05 12:27:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "297", "cur_iter": "1", "dt": 1.33993, "dt_data": 0.79978, "dt_net": 0.54015, "eta": "0:00:01", "loss": 0.27036, "lr": 0.00010, "mode": "train"}
[12/05 12:27:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "298", "cur_iter": "1", "dt": 1.34727, "dt_data": 0.80709, "dt_net": 0.54017, "eta": "0:00:01", "loss": 0.28031, "lr": 0.00010, "mode": "train"}
[12/05 12:27:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "299", "cur_iter": "1", "dt": 1.34004, "dt_data": 0.79913, "dt_net": 0.54091, "eta": "0:00:01", "loss": 0.26995, "lr": 0.00010, "mode": "train"}
[12/05 12:27:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 1.33706, "dt_data": 0.79699, "dt_net": 0.54007, "eta": "0:00:01", "loss": 0.27208, "lr": 0.00010, "mode": "train"}
[12/05 12:27:54][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 0.88411, "dt_data": 0.81012, "dt_net": 0.07398, "eta": "0:00:00", "mode": "val"}
[12/05 12:27:54][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/05 12:27:54][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/05 12:27:54][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/05 12:27:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:54][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/05 12:27:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/05 12:27:54][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/05 12:27:54][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003045 seconds.
[12/05 12:27:54][INFO] logging.py:  96: json_stats: {"RAM": "2.38/15.59G", "_type": "val_epoch", "cur_epoch": "300", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:31:55][INFO] train_net.py: 377: Train with config:
[12/07 18:31:55][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/07 18:31:59][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/07 18:31:59][INFO] misc.py: 170: Params: 33,653,708
[12/07 18:31:59][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/07 18:31:59][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/07 18:31:59][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/07 18:31:59][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/07 18:31:59][INFO] misc.py: 177: Activations: 155.545604 M
[12/07 18:31:59][INFO] misc.py: 182: nvidia-smi
[12/07 18:31:59][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/07 18:31:59][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/07 18:31:59][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/07 18:31:59][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/07 18:31:59][INFO] ava_helper.py: 111: Number of annotations: 15
[12/07 18:31:59][INFO] ava_helper.py: 157: 1 keyframes used.
[12/07 18:31:59][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/07 18:31:59][INFO] ava_dataset.py:  89: Split: train
[12/07 18:31:59][INFO] ava_dataset.py:  90: Number of videos: 1
[12/07 18:31:59][INFO] ava_dataset.py:  94: Number of frames: 5
[12/07 18:31:59][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/07 18:31:59][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/07 18:31:59][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/07 18:31:59][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/07 18:31:59][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/07 18:31:59][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/07 18:31:59][INFO] ava_helper.py: 111: Number of annotations: 11
[12/07 18:31:59][INFO] ava_helper.py: 157: 1 keyframes used.
[12/07 18:31:59][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/07 18:31:59][INFO] ava_dataset.py:  89: Split: val
[12/07 18:31:59][INFO] ava_dataset.py:  90: Number of videos: 1
[12/07 18:31:59][INFO] ava_dataset.py:  94: Number of frames: 4
[12/07 18:31:59][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/07 18:31:59][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/07 18:31:59][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/07 18:31:59][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/07 18:32:00][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/07 18:32:01][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/07 18:32:01][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/07 18:32:01][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/07 18:32:01][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/07 18:32:02][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/07 18:32:02][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/07 18:32:02][INFO] train_net.py: 417: Start epoch: 1
[12/07 18:32:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.42272, "dt_data": 0.85334, "dt_net": 0.56938, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/07 18:32:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.50111, "dt_data": 0.96625, "dt_net": 0.53485, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/07 18:32:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.32759, "dt_data": 0.79026, "dt_net": 0.53733, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/07 18:32:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.40428, "dt_data": 0.86777, "dt_net": 0.53650, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/07 18:32:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.41509, "dt_data": 0.87940, "dt_net": 0.53569, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/07 18:32:11][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.00092, "dt_data": 0.92648, "dt_net": 0.07444, "eta": "0:00:01", "mode": "val"}
[12/07 18:32:11][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:32:11][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:32:11][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:32:11][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:11][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:32:11][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:11][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:32:11][INFO] ava_eval_helper.py: 169: AVA eval done in 0.004660 seconds.
[12/07 18:32:11][INFO] logging.py:  96: json_stats: {"RAM": "6.64/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/07 18:32:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.40860, "dt_data": 0.87229, "dt_net": 0.53630, "eta": "0:00:01", "loss": 0.92423, "lr": 0.10000, "mode": "train"}
[12/07 18:32:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.42796, "dt_data": 0.89218, "dt_net": 0.53578, "eta": "0:00:01", "loss": 0.72823, "lr": 0.10000, "mode": "train"}
[12/07 18:32:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.32136, "dt_data": 0.78641, "dt_net": 0.53495, "eta": "0:00:01", "loss": 0.69546, "lr": 0.10000, "mode": "train"}
[12/07 18:32:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.40749, "dt_data": 0.87130, "dt_net": 0.53619, "eta": "0:00:01", "loss": 0.49756, "lr": 0.10000, "mode": "train"}
[12/07 18:32:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.49880, "dt_data": 0.96159, "dt_net": 0.53721, "eta": "0:00:01", "loss": 0.71194, "lr": 0.10000, "mode": "train"}
[12/07 18:32:20][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.92540, "dt_data": 0.85159, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/07 18:32:20][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:32:20][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:32:20][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:32:20][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:20][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:32:20][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:20][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:32:20][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002990 seconds.
[12/07 18:32:20][INFO] logging.py:  96: json_stats: {"RAM": "8.59/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.80747, "mode": "val"}
[12/07 18:32:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.31525, "dt_data": 0.78034, "dt_net": 0.53491, "eta": "0:00:01", "loss": 1.02014, "lr": 0.01000, "mode": "train"}
[12/07 18:32:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.42637, "dt_data": 0.89071, "dt_net": 0.53565, "eta": "0:00:01", "loss": 0.79109, "lr": 0.01000, "mode": "train"}
[12/07 18:32:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.51280, "dt_data": 0.97619, "dt_net": 0.53660, "eta": "0:00:01", "loss": 0.42103, "lr": 0.01000, "mode": "train"}
[12/07 18:32:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.41779, "dt_data": 0.88162, "dt_net": 0.53617, "eta": "0:00:01", "loss": 0.35781, "lr": 0.01000, "mode": "train"}
[12/07 18:32:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.42836, "dt_data": 0.89131, "dt_net": 0.53704, "eta": "0:00:01", "loss": 0.27903, "lr": 0.01000, "mode": "train"}
[12/07 18:32:29][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.84509, "dt_data": 0.77171, "dt_net": 0.07337, "eta": "0:00:00", "mode": "val"}
[12/07 18:32:29][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:32:29][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:32:29][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:32:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:29][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:32:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:29][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:32:29][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003053 seconds.
[12/07 18:32:29][INFO] logging.py:  96: json_stats: {"RAM": "10.18/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.62202, "mode": "val"}
[12/07 18:32:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.51391, "dt_data": 0.97717, "dt_net": 0.53674, "eta": "0:00:01", "loss": 0.31514, "lr": 0.00100, "mode": "train"}
[12/07 18:32:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.40833, "dt_data": 0.87271, "dt_net": 0.53562, "eta": "0:00:01", "loss": 0.32250, "lr": 0.00100, "mode": "train"}
[12/07 18:32:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.41533, "dt_data": 0.87931, "dt_net": 0.53601, "eta": "0:00:01", "loss": 0.30043, "lr": 0.00100, "mode": "train"}
[12/07 18:32:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.41930, "dt_data": 0.88334, "dt_net": 0.53596, "eta": "0:00:01", "loss": 0.30367, "lr": 0.00100, "mode": "train"}
[12/07 18:32:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.43280, "dt_data": 0.89676, "dt_net": 0.53604, "eta": "0:00:01", "loss": 0.31158, "lr": 0.00100, "mode": "train"}
[12/07 18:32:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.85854, "dt_data": 0.78516, "dt_net": 0.07337, "eta": "0:00:00", "mode": "val"}
[12/07 18:32:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:32:39][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:32:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:32:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:32:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:39][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:32:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003070 seconds.
[12/07 18:32:39][INFO] logging.py:  96: json_stats: {"RAM": "12.14/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.59668, "mode": "val"}
[12/07 18:32:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "21", "cur_iter": "1", "dt": 1.31346, "dt_data": 0.77885, "dt_net": 0.53461, "eta": "0:00:01", "loss": 0.31554, "lr": 0.00010, "mode": "train"}
[12/07 18:32:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "22", "cur_iter": "1", "dt": 1.43321, "dt_data": 0.89849, "dt_net": 0.53472, "eta": "0:00:01", "loss": 0.31074, "lr": 0.00010, "mode": "train"}
[12/07 18:32:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "23", "cur_iter": "1", "dt": 1.42608, "dt_data": 0.89072, "dt_net": 0.53536, "eta": "0:00:01", "loss": 0.31272, "lr": 0.00010, "mode": "train"}
[12/07 18:32:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "24", "cur_iter": "1", "dt": 1.42898, "dt_data": 0.89381, "dt_net": 0.53517, "eta": "0:00:01", "loss": 0.29337, "lr": 0.00010, "mode": "train"}
[12/07 18:32:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 1.43386, "dt_data": 0.89797, "dt_net": 0.53589, "eta": "0:00:01", "loss": 0.32626, "lr": 0.00010, "mode": "train"}
[12/07 18:32:48][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 0.95729, "dt_data": 0.88337, "dt_net": 0.07392, "eta": "0:00:00", "mode": "val"}
[12/07 18:32:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:32:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:32:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:32:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:32:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:32:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003117 seconds.
[12/07 18:32:48][INFO] logging.py:  96: json_stats: {"RAM": "14.27/15.59G", "_type": "val_epoch", "cur_epoch": "25", "gpu_mem": "1.74G", "map": 0.59235, "mode": "val"}
[12/07 18:32:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "26", "cur_iter": "1", "dt": 1.41601, "dt_data": 0.88082, "dt_net": 0.53518, "eta": "0:00:01", "loss": 0.30634, "lr": 0.00010, "mode": "train"}
[12/07 18:32:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "27", "cur_iter": "1", "dt": 1.33292, "dt_data": 0.79860, "dt_net": 0.53431, "eta": "0:00:01", "loss": 0.30093, "lr": 0.00010, "mode": "train"}
[12/07 18:32:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "28", "cur_iter": "1", "dt": 1.31707, "dt_data": 0.78257, "dt_net": 0.53450, "eta": "0:00:01", "loss": 0.29153, "lr": 0.00010, "mode": "train"}
[12/07 18:32:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "29", "cur_iter": "1", "dt": 1.39379, "dt_data": 0.85836, "dt_net": 0.53542, "eta": "0:00:01", "loss": 0.29550, "lr": 0.00010, "mode": "train"}
[12/07 18:32:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.48862, "dt_data": 0.95293, "dt_net": 0.53569, "eta": "0:00:01", "loss": 0.27876, "lr": 0.00010, "mode": "train"}
[12/07 18:32:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.14184, "dt_data": 1.02256, "dt_net": 0.11926, "eta": "0:00:01", "mode": "val"}
[12/07 18:32:57][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:32:57][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:32:57][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:32:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:57][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:32:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:32:57][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:32:57][INFO] ava_eval_helper.py: 169: AVA eval done in 0.005107 seconds.
[12/07 18:32:57][INFO] logging.py:  96: json_stats: {"RAM": "2.23/15.59G", "_type": "val_epoch", "cur_epoch": "30", "gpu_mem": "1.74G", "map": 0.61508, "mode": "val"}
[12/07 18:32:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "31", "cur_iter": "1", "dt": 1.33358, "dt_data": 0.77284, "dt_net": 0.56074, "eta": "0:00:01", "loss": 0.28518, "lr": 0.00010, "mode": "train"}
[12/07 18:33:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "32", "cur_iter": "1", "dt": 1.29079, "dt_data": 0.75694, "dt_net": 0.53384, "eta": "0:00:01", "loss": 0.30665, "lr": 0.00010, "mode": "train"}
[12/07 18:33:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "33", "cur_iter": "1", "dt": 1.29384, "dt_data": 0.75950, "dt_net": 0.53434, "eta": "0:00:01", "loss": 0.31563, "lr": 0.00010, "mode": "train"}
[12/07 18:33:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "34", "cur_iter": "1", "dt": 1.28997, "dt_data": 0.75566, "dt_net": 0.53431, "eta": "0:00:01", "loss": 0.29211, "lr": 0.00010, "mode": "train"}
[12/07 18:33:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 1.29116, "dt_data": 0.75757, "dt_net": 0.53359, "eta": "0:00:01", "loss": 0.29795, "lr": 0.00010, "mode": "train"}
[12/07 18:33:05][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 0.84476, "dt_data": 0.77145, "dt_net": 0.07330, "eta": "0:00:00", "mode": "val"}
[12/07 18:33:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:33:05][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:33:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:33:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:33:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:05][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:33:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003133 seconds.
[12/07 18:33:05][INFO] logging.py:  96: json_stats: {"RAM": "2.28/15.59G", "_type": "val_epoch", "cur_epoch": "35", "gpu_mem": "1.74G", "map": 0.59365, "mode": "val"}
[12/07 18:33:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "36", "cur_iter": "1", "dt": 1.28441, "dt_data": 0.75040, "dt_net": 0.53400, "eta": "0:00:01", "loss": 0.28257, "lr": 0.00010, "mode": "train"}
[12/07 18:33:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "37", "cur_iter": "1", "dt": 1.28923, "dt_data": 0.75515, "dt_net": 0.53407, "eta": "0:00:01", "loss": 0.31618, "lr": 0.00010, "mode": "train"}
[12/07 18:33:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "38", "cur_iter": "1", "dt": 1.28932, "dt_data": 0.75543, "dt_net": 0.53388, "eta": "0:00:01", "loss": 0.31883, "lr": 0.00010, "mode": "train"}
[12/07 18:33:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "39", "cur_iter": "1", "dt": 1.28810, "dt_data": 0.75356, "dt_net": 0.53453, "eta": "0:00:01", "loss": 0.28332, "lr": 0.00010, "mode": "train"}
[12/07 18:33:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 1.29027, "dt_data": 0.75450, "dt_net": 0.53577, "eta": "0:00:01", "loss": 0.29628, "lr": 0.00010, "mode": "train"}
[12/07 18:33:14][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 0.84210, "dt_data": 0.76853, "dt_net": 0.07356, "eta": "0:00:00", "mode": "val"}
[12/07 18:33:14][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:33:14][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:33:14][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:33:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:14][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:33:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:14][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:33:14][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002830 seconds.
[12/07 18:33:14][INFO] logging.py:  96: json_stats: {"RAM": "2.28/15.59G", "_type": "val_epoch", "cur_epoch": "40", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:33:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "41", "cur_iter": "1", "dt": 1.28840, "dt_data": 0.75298, "dt_net": 0.53542, "eta": "0:00:01", "loss": 0.28610, "lr": 0.00010, "mode": "train"}
[12/07 18:33:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "42", "cur_iter": "1", "dt": 1.28933, "dt_data": 0.75372, "dt_net": 0.53561, "eta": "0:00:01", "loss": 0.31014, "lr": 0.00010, "mode": "train"}
[12/07 18:33:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "43", "cur_iter": "1", "dt": 1.29036, "dt_data": 0.75504, "dt_net": 0.53531, "eta": "0:00:01", "loss": 0.31407, "lr": 0.00010, "mode": "train"}
[12/07 18:33:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "44", "cur_iter": "1", "dt": 1.28934, "dt_data": 0.75380, "dt_net": 0.53553, "eta": "0:00:01", "loss": 0.32062, "lr": 0.00010, "mode": "train"}
[12/07 18:33:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 1.29050, "dt_data": 0.75524, "dt_net": 0.53526, "eta": "0:00:01", "loss": 0.29111, "lr": 0.00010, "mode": "train"}
[12/07 18:33:22][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 0.84327, "dt_data": 0.76968, "dt_net": 0.07359, "eta": "0:00:00", "mode": "val"}
[12/07 18:33:22][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:33:22][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:33:22][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:33:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:22][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:33:22][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:22][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:33:22][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003109 seconds.
[12/07 18:33:22][INFO] logging.py:  96: json_stats: {"RAM": "2.29/15.59G", "_type": "val_epoch", "cur_epoch": "45", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:33:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "46", "cur_iter": "1", "dt": 1.28636, "dt_data": 0.75139, "dt_net": 0.53496, "eta": "0:00:01", "loss": 0.27990, "lr": 0.00010, "mode": "train"}
[12/07 18:33:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "47", "cur_iter": "1", "dt": 1.28879, "dt_data": 0.75346, "dt_net": 0.53533, "eta": "0:00:01", "loss": 0.31708, "lr": 0.00010, "mode": "train"}
[12/07 18:33:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "48", "cur_iter": "1", "dt": 1.28923, "dt_data": 0.75335, "dt_net": 0.53587, "eta": "0:00:01", "loss": 0.29657, "lr": 0.00010, "mode": "train"}
[12/07 18:33:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "49", "cur_iter": "1", "dt": 1.28849, "dt_data": 0.75338, "dt_net": 0.53510, "eta": "0:00:01", "loss": 0.30216, "lr": 0.00010, "mode": "train"}
[12/07 18:33:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 1.29077, "dt_data": 0.75539, "dt_net": 0.53538, "eta": "0:00:01", "loss": 0.27956, "lr": 0.00010, "mode": "train"}
[12/07 18:33:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 0.84628, "dt_data": 0.77287, "dt_net": 0.07340, "eta": "0:00:00", "mode": "val"}
[12/07 18:33:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:33:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:33:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:33:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:33:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:33:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003037 seconds.
[12/07 18:33:31][INFO] logging.py:  96: json_stats: {"RAM": "2.29/15.59G", "_type": "val_epoch", "cur_epoch": "50", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:33:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "51", "cur_iter": "1", "dt": 1.28365, "dt_data": 0.74826, "dt_net": 0.53538, "eta": "0:00:01", "loss": 0.29004, "lr": 0.00010, "mode": "train"}
[12/07 18:33:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "52", "cur_iter": "1", "dt": 1.28477, "dt_data": 0.74946, "dt_net": 0.53531, "eta": "0:00:01", "loss": 0.30185, "lr": 0.00010, "mode": "train"}
[12/07 18:33:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "53", "cur_iter": "1", "dt": 1.28823, "dt_data": 0.75301, "dt_net": 0.53522, "eta": "0:00:01", "loss": 0.27237, "lr": 0.00010, "mode": "train"}
[12/07 18:33:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "54", "cur_iter": "1", "dt": 1.28678, "dt_data": 0.75128, "dt_net": 0.53550, "eta": "0:00:01", "loss": 0.28946, "lr": 0.00010, "mode": "train"}
[12/07 18:33:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 1.28853, "dt_data": 0.75297, "dt_net": 0.53555, "eta": "0:00:01", "loss": 0.28065, "lr": 0.00010, "mode": "train"}
[12/07 18:33:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 0.83406, "dt_data": 0.76060, "dt_net": 0.07345, "eta": "0:00:00", "mode": "val"}
[12/07 18:33:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:33:39][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:33:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:33:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:33:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:39][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:33:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003154 seconds.
[12/07 18:33:39][INFO] logging.py:  96: json_stats: {"RAM": "2.30/15.59G", "_type": "val_epoch", "cur_epoch": "55", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:33:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "56", "cur_iter": "1", "dt": 1.28481, "dt_data": 0.74919, "dt_net": 0.53562, "eta": "0:00:01", "loss": 0.29442, "lr": 0.00010, "mode": "train"}
[12/07 18:33:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "57", "cur_iter": "1", "dt": 1.28441, "dt_data": 0.74921, "dt_net": 0.53519, "eta": "0:00:01", "loss": 0.27687, "lr": 0.00010, "mode": "train"}
[12/07 18:33:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "58", "cur_iter": "1", "dt": 1.28473, "dt_data": 0.74919, "dt_net": 0.53553, "eta": "0:00:01", "loss": 0.28400, "lr": 0.00010, "mode": "train"}
[12/07 18:33:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "59", "cur_iter": "1", "dt": 1.28443, "dt_data": 0.74897, "dt_net": 0.53545, "eta": "0:00:01", "loss": 0.28307, "lr": 0.00010, "mode": "train"}
[12/07 18:33:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 1.28979, "dt_data": 0.75262, "dt_net": 0.53717, "eta": "0:00:01", "loss": 0.28835, "lr": 0.00010, "mode": "train"}
[12/07 18:33:47][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 0.84529, "dt_data": 0.77151, "dt_net": 0.07377, "eta": "0:00:00", "mode": "val"}
[12/07 18:33:47][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:33:47][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:33:47][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:33:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:47][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:33:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:47][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:33:47][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003204 seconds.
[12/07 18:33:47][INFO] logging.py:  96: json_stats: {"RAM": "2.30/15.59G", "_type": "val_epoch", "cur_epoch": "60", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:33:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "61", "cur_iter": "1", "dt": 1.28931, "dt_data": 0.75104, "dt_net": 0.53827, "eta": "0:00:01", "loss": 0.30340, "lr": 0.00010, "mode": "train"}
[12/07 18:33:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "62", "cur_iter": "1", "dt": 1.29148, "dt_data": 0.75254, "dt_net": 0.53894, "eta": "0:00:01", "loss": 0.31148, "lr": 0.00010, "mode": "train"}
[12/07 18:33:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "63", "cur_iter": "1", "dt": 1.29084, "dt_data": 0.75186, "dt_net": 0.53898, "eta": "0:00:01", "loss": 0.28982, "lr": 0.00010, "mode": "train"}
[12/07 18:33:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "64", "cur_iter": "1", "dt": 1.28946, "dt_data": 0.75129, "dt_net": 0.53816, "eta": "0:00:01", "loss": 0.29763, "lr": 0.00010, "mode": "train"}
[12/07 18:33:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 1.29315, "dt_data": 0.75404, "dt_net": 0.53911, "eta": "0:00:01", "loss": 0.30471, "lr": 0.00010, "mode": "train"}
[12/07 18:33:56][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 0.83695, "dt_data": 0.76316, "dt_net": 0.07378, "eta": "0:00:00", "mode": "val"}
[12/07 18:33:56][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:33:56][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:33:56][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:33:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:56][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:33:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:33:56][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:33:56][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003146 seconds.
[12/07 18:33:56][INFO] logging.py:  96: json_stats: {"RAM": "2.30/15.59G", "_type": "val_epoch", "cur_epoch": "65", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:33:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "66", "cur_iter": "1", "dt": 1.29008, "dt_data": 0.75116, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.28123, "lr": 0.00010, "mode": "train"}
[12/07 18:33:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "67", "cur_iter": "1", "dt": 1.29035, "dt_data": 0.75195, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.27584, "lr": 0.00010, "mode": "train"}
[12/07 18:34:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "68", "cur_iter": "1", "dt": 1.28967, "dt_data": 0.75132, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.28614, "lr": 0.00010, "mode": "train"}
[12/07 18:34:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "69", "cur_iter": "1", "dt": 1.29114, "dt_data": 0.75261, "dt_net": 0.53852, "eta": "0:00:01", "loss": 0.29101, "lr": 0.00010, "mode": "train"}
[12/07 18:34:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 1.29109, "dt_data": 0.75269, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.29417, "lr": 0.00010, "mode": "train"}
[12/07 18:34:04][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 0.84586, "dt_data": 0.77200, "dt_net": 0.07385, "eta": "0:00:00", "mode": "val"}
[12/07 18:34:04][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:34:04][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:34:04][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:34:04][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:04][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:34:04][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:04][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:34:04][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002951 seconds.
[12/07 18:34:04][INFO] logging.py:  96: json_stats: {"RAM": "2.31/15.59G", "_type": "val_epoch", "cur_epoch": "70", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:34:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "71", "cur_iter": "1", "dt": 1.28885, "dt_data": 0.75026, "dt_net": 0.53858, "eta": "0:00:01", "loss": 0.30184, "lr": 0.00010, "mode": "train"}
[12/07 18:34:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "72", "cur_iter": "1", "dt": 1.29056, "dt_data": 0.75221, "dt_net": 0.53834, "eta": "0:00:01", "loss": 0.27720, "lr": 0.00010, "mode": "train"}
[12/07 18:34:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "73", "cur_iter": "1", "dt": 1.29084, "dt_data": 0.75214, "dt_net": 0.53870, "eta": "0:00:01", "loss": 0.29287, "lr": 0.00010, "mode": "train"}
[12/07 18:34:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "74", "cur_iter": "1", "dt": 1.28906, "dt_data": 0.75056, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.29065, "lr": 0.00010, "mode": "train"}
[12/07 18:34:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 1.29354, "dt_data": 0.75519, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.27564, "lr": 0.00010, "mode": "train"}
[12/07 18:34:12][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 0.84348, "dt_data": 0.76982, "dt_net": 0.07365, "eta": "0:00:00", "mode": "val"}
[12/07 18:34:13][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:34:13][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:34:13][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:34:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:13][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:34:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:13][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:34:13][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003006 seconds.
[12/07 18:34:13][INFO] logging.py:  96: json_stats: {"RAM": "2.31/15.59G", "_type": "val_epoch", "cur_epoch": "75", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:34:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "76", "cur_iter": "1", "dt": 1.28720, "dt_data": 0.74873, "dt_net": 0.53847, "eta": "0:00:01", "loss": 0.30860, "lr": 0.00010, "mode": "train"}
[12/07 18:34:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "77", "cur_iter": "1", "dt": 1.29124, "dt_data": 0.75266, "dt_net": 0.53858, "eta": "0:00:01", "loss": 0.28261, "lr": 0.00010, "mode": "train"}
[12/07 18:34:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "78", "cur_iter": "1", "dt": 1.29173, "dt_data": 0.75348, "dt_net": 0.53824, "eta": "0:00:01", "loss": 0.29279, "lr": 0.00010, "mode": "train"}
[12/07 18:34:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "79", "cur_iter": "1", "dt": 1.29069, "dt_data": 0.75238, "dt_net": 0.53830, "eta": "0:00:01", "loss": 0.28621, "lr": 0.00010, "mode": "train"}
[12/07 18:34:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 1.29078, "dt_data": 0.75176, "dt_net": 0.53902, "eta": "0:00:01", "loss": 0.27337, "lr": 0.00010, "mode": "train"}
[12/07 18:34:21][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 0.84284, "dt_data": 0.76897, "dt_net": 0.07386, "eta": "0:00:00", "mode": "val"}
[12/07 18:34:21][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:34:21][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:34:21][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:34:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:21][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:34:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:21][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:34:21][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003308 seconds.
[12/07 18:34:21][INFO] logging.py:  96: json_stats: {"RAM": "2.32/15.59G", "_type": "val_epoch", "cur_epoch": "80", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:34:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "81", "cur_iter": "1", "dt": 1.28619, "dt_data": 0.74722, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.28001, "lr": 0.00010, "mode": "train"}
[12/07 18:34:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "82", "cur_iter": "1", "dt": 1.29022, "dt_data": 0.75195, "dt_net": 0.53826, "eta": "0:00:01", "loss": 0.27750, "lr": 0.00010, "mode": "train"}
[12/07 18:34:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "83", "cur_iter": "1", "dt": 1.29100, "dt_data": 0.75264, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27929, "lr": 0.00010, "mode": "train"}
[12/07 18:34:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "84", "cur_iter": "1", "dt": 1.29060, "dt_data": 0.75180, "dt_net": 0.53880, "eta": "0:00:01", "loss": 0.28200, "lr": 0.00010, "mode": "train"}
[12/07 18:34:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 1.29178, "dt_data": 0.75262, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.27669, "lr": 0.00010, "mode": "train"}
[12/07 18:34:29][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 0.82586, "dt_data": 0.75184, "dt_net": 0.07402, "eta": "0:00:00", "mode": "val"}
[12/07 18:34:29][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:34:29][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:34:29][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:34:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:29][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:34:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:29][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:34:29][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003024 seconds.
[12/07 18:34:29][INFO] logging.py:  96: json_stats: {"RAM": "2.32/15.59G", "_type": "val_epoch", "cur_epoch": "85", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:34:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "86", "cur_iter": "1", "dt": 1.28836, "dt_data": 0.74867, "dt_net": 0.53968, "eta": "0:00:01", "loss": 0.26977, "lr": 0.00010, "mode": "train"}
[12/07 18:34:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "87", "cur_iter": "1", "dt": 1.29291, "dt_data": 0.75261, "dt_net": 0.54030, "eta": "0:00:01", "loss": 0.28098, "lr": 0.00010, "mode": "train"}
[12/07 18:34:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "88", "cur_iter": "1", "dt": 1.28925, "dt_data": 0.74875, "dt_net": 0.54049, "eta": "0:00:01", "loss": 0.27817, "lr": 0.00010, "mode": "train"}
[12/07 18:34:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "89", "cur_iter": "1", "dt": 1.28852, "dt_data": 0.74870, "dt_net": 0.53982, "eta": "0:00:01", "loss": 0.28423, "lr": 0.00010, "mode": "train"}
[12/07 18:34:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 1.28943, "dt_data": 0.74923, "dt_net": 0.54020, "eta": "0:00:01", "loss": 0.29265, "lr": 0.00010, "mode": "train"}
[12/07 18:34:38][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 0.84334, "dt_data": 0.76942, "dt_net": 0.07390, "eta": "0:00:00", "mode": "val"}
[12/07 18:34:38][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:34:38][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:34:38][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:34:38][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:38][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:34:38][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:38][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:34:38][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003063 seconds.
[12/07 18:34:38][INFO] logging.py:  96: json_stats: {"RAM": "2.33/15.59G", "_type": "val_epoch", "cur_epoch": "90", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:34:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "91", "cur_iter": "1", "dt": 1.28853, "dt_data": 0.74808, "dt_net": 0.54044, "eta": "0:00:01", "loss": 0.28826, "lr": 0.00010, "mode": "train"}
[12/07 18:34:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "92", "cur_iter": "1", "dt": 1.29221, "dt_data": 0.75182, "dt_net": 0.54039, "eta": "0:00:01", "loss": 0.28515, "lr": 0.00010, "mode": "train"}
[12/07 18:34:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "93", "cur_iter": "1", "dt": 1.29146, "dt_data": 0.75134, "dt_net": 0.54011, "eta": "0:00:01", "loss": 0.27823, "lr": 0.00010, "mode": "train"}
[12/07 18:34:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "94", "cur_iter": "1", "dt": 1.29032, "dt_data": 0.74994, "dt_net": 0.54038, "eta": "0:00:01", "loss": 0.27789, "lr": 0.00010, "mode": "train"}
[12/07 18:34:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 1.29242, "dt_data": 0.75212, "dt_net": 0.54030, "eta": "0:00:01", "loss": 0.28411, "lr": 0.00010, "mode": "train"}
[12/07 18:34:46][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 0.82739, "dt_data": 0.75307, "dt_net": 0.07431, "eta": "0:00:00", "mode": "val"}
[12/07 18:34:46][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:34:46][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:34:46][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:34:46][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:46][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:34:46][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:46][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:34:46][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003079 seconds.
[12/07 18:34:46][INFO] logging.py:  96: json_stats: {"RAM": "2.33/15.59G", "_type": "val_epoch", "cur_epoch": "95", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:34:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "96", "cur_iter": "1", "dt": 1.28847, "dt_data": 0.74896, "dt_net": 0.53950, "eta": "0:00:01", "loss": 0.27949, "lr": 0.00010, "mode": "train"}
[12/07 18:34:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "97", "cur_iter": "1", "dt": 1.28922, "dt_data": 0.75056, "dt_net": 0.53866, "eta": "0:00:01", "loss": 0.28277, "lr": 0.00010, "mode": "train"}
[12/07 18:34:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "98", "cur_iter": "1", "dt": 1.29232, "dt_data": 0.75321, "dt_net": 0.53910, "eta": "0:00:01", "loss": 0.27829, "lr": 0.00010, "mode": "train"}
[12/07 18:34:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "99", "cur_iter": "1", "dt": 1.29016, "dt_data": 0.75111, "dt_net": 0.53905, "eta": "0:00:01", "loss": 0.28313, "lr": 0.00010, "mode": "train"}
[12/07 18:34:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 1.29184, "dt_data": 0.75361, "dt_net": 0.53822, "eta": "0:00:01", "loss": 0.27936, "lr": 0.00010, "mode": "train"}
[12/07 18:34:54][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 0.83415, "dt_data": 0.76032, "dt_net": 0.07382, "eta": "0:00:00", "mode": "val"}
[12/07 18:34:54][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:34:54][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:34:54][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:34:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:54][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:34:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:34:54][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:34:54][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003135 seconds.
[12/07 18:34:54][INFO] logging.py:  96: json_stats: {"RAM": "2.33/15.59G", "_type": "val_epoch", "cur_epoch": "100", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:34:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "101", "cur_iter": "1", "dt": 1.28928, "dt_data": 0.75032, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.28445, "lr": 0.00010, "mode": "train"}
[12/07 18:34:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "102", "cur_iter": "1", "dt": 1.28970, "dt_data": 0.75088, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.27200, "lr": 0.00010, "mode": "train"}
[12/07 18:34:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "103", "cur_iter": "1", "dt": 1.29164, "dt_data": 0.75290, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.28297, "lr": 0.00010, "mode": "train"}
[12/07 18:35:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "104", "cur_iter": "1", "dt": 1.28840, "dt_data": 0.74996, "dt_net": 0.53844, "eta": "0:00:01", "loss": 0.27798, "lr": 0.00010, "mode": "train"}
[12/07 18:35:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 1.29235, "dt_data": 0.75328, "dt_net": 0.53907, "eta": "0:00:01", "loss": 0.28569, "lr": 0.00010, "mode": "train"}
[12/07 18:35:03][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 0.84733, "dt_data": 0.77333, "dt_net": 0.07399, "eta": "0:00:00", "mode": "val"}
[12/07 18:35:03][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:35:03][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:35:03][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:35:03][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:03][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:35:03][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:03][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:35:03][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003093 seconds.
[12/07 18:35:03][INFO] logging.py:  96: json_stats: {"RAM": "2.34/15.59G", "_type": "val_epoch", "cur_epoch": "105", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:35:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "106", "cur_iter": "1", "dt": 1.28778, "dt_data": 0.74904, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.27838, "lr": 0.00010, "mode": "train"}
[12/07 18:35:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "107", "cur_iter": "1", "dt": 1.28971, "dt_data": 0.75079, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.30026, "lr": 0.00010, "mode": "train"}
[12/07 18:35:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "108", "cur_iter": "1", "dt": 1.28913, "dt_data": 0.75085, "dt_net": 0.53828, "eta": "0:00:01", "loss": 0.27474, "lr": 0.00010, "mode": "train"}
[12/07 18:35:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "109", "cur_iter": "1", "dt": 1.28914, "dt_data": 0.75054, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.26898, "lr": 0.00010, "mode": "train"}
[12/07 18:35:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 1.29183, "dt_data": 0.75307, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27393, "lr": 0.00010, "mode": "train"}
[12/07 18:35:11][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 0.84105, "dt_data": 0.76705, "dt_net": 0.07399, "eta": "0:00:00", "mode": "val"}
[12/07 18:35:11][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:35:11][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:35:11][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:35:11][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:11][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:35:11][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:11][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:35:11][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003122 seconds.
[12/07 18:35:11][INFO] logging.py:  96: json_stats: {"RAM": "2.34/15.59G", "_type": "val_epoch", "cur_epoch": "110", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:35:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "111", "cur_iter": "1", "dt": 1.28696, "dt_data": 0.74832, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.27662, "lr": 0.00010, "mode": "train"}
[12/07 18:35:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "112", "cur_iter": "1", "dt": 1.29192, "dt_data": 0.75324, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.27649, "lr": 0.00010, "mode": "train"}
[12/07 18:35:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "113", "cur_iter": "1", "dt": 1.29106, "dt_data": 0.75232, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.28506, "lr": 0.00010, "mode": "train"}
[12/07 18:35:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "114", "cur_iter": "1", "dt": 1.28910, "dt_data": 0.75050, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.27968, "lr": 0.00010, "mode": "train"}
[12/07 18:35:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 1.29259, "dt_data": 0.75396, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.28021, "lr": 0.00010, "mode": "train"}
[12/07 18:35:19][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 0.84271, "dt_data": 0.76871, "dt_net": 0.07400, "eta": "0:00:00", "mode": "val"}
[12/07 18:35:19][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:35:19][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:35:19][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:35:19][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:19][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:35:19][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:19][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:35:19][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003035 seconds.
[12/07 18:35:19][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "115", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:35:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "116", "cur_iter": "1", "dt": 1.28873, "dt_data": 0.74987, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.31527, "lr": 0.00010, "mode": "train"}
[12/07 18:35:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "117", "cur_iter": "1", "dt": 1.29025, "dt_data": 0.75143, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.28168, "lr": 0.00010, "mode": "train"}
[12/07 18:35:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "118", "cur_iter": "1", "dt": 1.29023, "dt_data": 0.75173, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.27006, "lr": 0.00010, "mode": "train"}
[12/07 18:35:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "119", "cur_iter": "1", "dt": 1.28983, "dt_data": 0.75143, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.28484, "lr": 0.00010, "mode": "train"}
[12/07 18:35:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 1.29293, "dt_data": 0.75409, "dt_net": 0.53883, "eta": "0:00:01", "loss": 0.28093, "lr": 0.00010, "mode": "train"}
[12/07 18:35:28][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 0.84349, "dt_data": 0.76953, "dt_net": 0.07395, "eta": "0:00:00", "mode": "val"}
[12/07 18:35:28][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:35:28][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:35:28][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:35:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:28][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:35:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:28][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:35:28][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003152 seconds.
[12/07 18:35:28][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "120", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:35:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "121", "cur_iter": "1", "dt": 1.28801, "dt_data": 0.74926, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27577, "lr": 0.00010, "mode": "train"}
[12/07 18:35:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "122", "cur_iter": "1", "dt": 1.28891, "dt_data": 0.75059, "dt_net": 0.53832, "eta": "0:00:01", "loss": 0.27985, "lr": 0.00010, "mode": "train"}
[12/07 18:35:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "123", "cur_iter": "1", "dt": 1.29096, "dt_data": 0.75253, "dt_net": 0.53842, "eta": "0:00:01", "loss": 0.26795, "lr": 0.00010, "mode": "train"}
[12/07 18:35:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "124", "cur_iter": "1", "dt": 1.29755, "dt_data": 0.75859, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.27750, "lr": 0.00010, "mode": "train"}
[12/07 18:35:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 1.29350, "dt_data": 0.75531, "dt_net": 0.53818, "eta": "0:00:01", "loss": 0.27669, "lr": 0.00010, "mode": "train"}
[12/07 18:35:36][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 0.83942, "dt_data": 0.76537, "dt_net": 0.07404, "eta": "0:00:00", "mode": "val"}
[12/07 18:35:36][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:35:36][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:35:36][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:35:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:36][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:35:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:36][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:35:36][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003011 seconds.
[12/07 18:35:36][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "125", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:35:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "126", "cur_iter": "1", "dt": 1.28627, "dt_data": 0.74758, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.27613, "lr": 0.00010, "mode": "train"}
[12/07 18:35:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "127", "cur_iter": "1", "dt": 1.29167, "dt_data": 0.75344, "dt_net": 0.53822, "eta": "0:00:01", "loss": 0.27911, "lr": 0.00010, "mode": "train"}
[12/07 18:35:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "128", "cur_iter": "1", "dt": 1.29284, "dt_data": 0.75378, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.27765, "lr": 0.00010, "mode": "train"}
[12/07 18:35:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "129", "cur_iter": "1", "dt": 1.29056, "dt_data": 0.75219, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27958, "lr": 0.00010, "mode": "train"}
[12/07 18:35:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 1.29104, "dt_data": 0.75248, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.27379, "lr": 0.00010, "mode": "train"}
[12/07 18:35:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 0.84262, "dt_data": 0.76851, "dt_net": 0.07408, "eta": "0:00:00", "mode": "val"}
[12/07 18:35:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:35:44][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:35:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:35:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:35:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:44][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:35:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003085 seconds.
[12/07 18:35:44][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "130", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:35:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "131", "cur_iter": "1", "dt": 1.28508, "dt_data": 0.74695, "dt_net": 0.53813, "eta": "0:00:01", "loss": 0.27472, "lr": 0.00010, "mode": "train"}
[12/07 18:35:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "132", "cur_iter": "1", "dt": 1.28896, "dt_data": 0.75043, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.27342, "lr": 0.00010, "mode": "train"}
[12/07 18:35:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "133", "cur_iter": "1", "dt": 1.29017, "dt_data": 0.75187, "dt_net": 0.53830, "eta": "0:00:01", "loss": 0.27458, "lr": 0.00010, "mode": "train"}
[12/07 18:35:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "134", "cur_iter": "1", "dt": 1.28955, "dt_data": 0.75129, "dt_net": 0.53826, "eta": "0:00:01", "loss": 0.28468, "lr": 0.00010, "mode": "train"}
[12/07 18:35:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 1.29237, "dt_data": 0.75339, "dt_net": 0.53898, "eta": "0:00:01", "loss": 0.27329, "lr": 0.00010, "mode": "train"}
[12/07 18:35:53][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 0.84311, "dt_data": 0.76916, "dt_net": 0.07394, "eta": "0:00:00", "mode": "val"}
[12/07 18:35:53][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:35:53][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:35:53][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:35:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:53][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:35:53][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:35:53][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:35:53][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002910 seconds.
[12/07 18:35:53][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "135", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:35:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "136", "cur_iter": "1", "dt": 1.28671, "dt_data": 0.74794, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27307, "lr": 0.00010, "mode": "train"}
[12/07 18:35:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "137", "cur_iter": "1", "dt": 1.29043, "dt_data": 0.75181, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.27578, "lr": 0.00010, "mode": "train"}
[12/07 18:35:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "138", "cur_iter": "1", "dt": 1.28970, "dt_data": 0.75160, "dt_net": 0.53810, "eta": "0:00:01", "loss": 0.27926, "lr": 0.00010, "mode": "train"}
[12/07 18:35:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "139", "cur_iter": "1", "dt": 1.29136, "dt_data": 0.75243, "dt_net": 0.53893, "eta": "0:00:01", "loss": 0.28129, "lr": 0.00010, "mode": "train"}
[12/07 18:36:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 1.29029, "dt_data": 0.75183, "dt_net": 0.53845, "eta": "0:00:01", "loss": 0.28440, "lr": 0.00010, "mode": "train"}
[12/07 18:36:01][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 0.84141, "dt_data": 0.76746, "dt_net": 0.07395, "eta": "0:00:00", "mode": "val"}
[12/07 18:36:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:36:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:36:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:36:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:36:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:36:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003117 seconds.
[12/07 18:36:01][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "140", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:36:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "141", "cur_iter": "1", "dt": 1.28762, "dt_data": 0.74908, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.27826, "lr": 0.00010, "mode": "train"}
[12/07 18:36:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "142", "cur_iter": "1", "dt": 1.28996, "dt_data": 0.75141, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.27958, "lr": 0.00010, "mode": "train"}
[12/07 18:36:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "143", "cur_iter": "1", "dt": 1.29168, "dt_data": 0.75249, "dt_net": 0.53918, "eta": "0:00:01", "loss": 0.27946, "lr": 0.00010, "mode": "train"}
[12/07 18:36:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "144", "cur_iter": "1", "dt": 1.29000, "dt_data": 0.75152, "dt_net": 0.53848, "eta": "0:00:01", "loss": 0.28317, "lr": 0.00010, "mode": "train"}
[12/07 18:36:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 1.29098, "dt_data": 0.75167, "dt_net": 0.53931, "eta": "0:00:01", "loss": 0.27055, "lr": 0.00010, "mode": "train"}
[12/07 18:36:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 0.84336, "dt_data": 0.76939, "dt_net": 0.07396, "eta": "0:00:00", "mode": "val"}
[12/07 18:36:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:36:10][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:36:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:36:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:36:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:10][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:36:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003073 seconds.
[12/07 18:36:10][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "145", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:36:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "146", "cur_iter": "1", "dt": 1.28884, "dt_data": 0.75005, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.29322, "lr": 0.00010, "mode": "train"}
[12/07 18:36:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "147", "cur_iter": "1", "dt": 1.29115, "dt_data": 0.75191, "dt_net": 0.53923, "eta": "0:00:01", "loss": 0.27565, "lr": 0.00010, "mode": "train"}
[12/07 18:36:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "148", "cur_iter": "1", "dt": 1.29870, "dt_data": 0.76018, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.27865, "lr": 0.00010, "mode": "train"}
[12/07 18:36:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "149", "cur_iter": "1", "dt": 1.29031, "dt_data": 0.75146, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.26697, "lr": 0.00010, "mode": "train"}
[12/07 18:36:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 1.29304, "dt_data": 0.75432, "dt_net": 0.53872, "eta": "0:00:01", "loss": 0.28882, "lr": 0.00010, "mode": "train"}
[12/07 18:36:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 0.82780, "dt_data": 0.75336, "dt_net": 0.07444, "eta": "0:00:00", "mode": "val"}
[12/07 18:36:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:36:18][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:36:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:36:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:36:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:18][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:36:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003054 seconds.
[12/07 18:36:18][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "150", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:36:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "151", "cur_iter": "1", "dt": 1.28806, "dt_data": 0.74942, "dt_net": 0.53863, "eta": "0:00:01", "loss": 0.28839, "lr": 0.00010, "mode": "train"}
[12/07 18:36:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "152", "cur_iter": "1", "dt": 1.28978, "dt_data": 0.75129, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.28287, "lr": 0.00010, "mode": "train"}
[12/07 18:36:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "153", "cur_iter": "1", "dt": 1.29020, "dt_data": 0.75124, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.28529, "lr": 0.00010, "mode": "train"}
[12/07 18:36:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "154", "cur_iter": "1", "dt": 1.28984, "dt_data": 0.75088, "dt_net": 0.53896, "eta": "0:00:01", "loss": 0.27301, "lr": 0.00010, "mode": "train"}
[12/07 18:36:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 1.29024, "dt_data": 0.75138, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27539, "lr": 0.00010, "mode": "train"}
[12/07 18:36:26][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 0.84578, "dt_data": 0.77171, "dt_net": 0.07406, "eta": "0:00:00", "mode": "val"}
[12/07 18:36:26][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:36:26][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:36:26][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:36:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:26][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:36:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:26][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:36:26][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003163 seconds.
[12/07 18:36:26][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "155", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:36:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "156", "cur_iter": "1", "dt": 1.28713, "dt_data": 0.74822, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.27472, "lr": 0.00010, "mode": "train"}
[12/07 18:36:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "157", "cur_iter": "1", "dt": 1.28627, "dt_data": 0.74724, "dt_net": 0.53902, "eta": "0:00:01", "loss": 0.28901, "lr": 0.00010, "mode": "train"}
[12/07 18:36:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "158", "cur_iter": "1", "dt": 1.29075, "dt_data": 0.75189, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.28144, "lr": 0.00010, "mode": "train"}
[12/07 18:36:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "159", "cur_iter": "1", "dt": 1.28954, "dt_data": 0.75103, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.26899, "lr": 0.00010, "mode": "train"}
[12/07 18:36:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 1.29754, "dt_data": 0.75877, "dt_net": 0.53877, "eta": "0:00:01", "loss": 0.27456, "lr": 0.00010, "mode": "train"}
[12/07 18:36:35][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 0.84075, "dt_data": 0.76661, "dt_net": 0.07413, "eta": "0:00:00", "mode": "val"}
[12/07 18:36:35][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:36:35][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:36:35][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:36:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:35][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:36:35][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:35][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:36:35][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002983 seconds.
[12/07 18:36:35][INFO] logging.py:  96: json_stats: {"RAM": "2.35/15.59G", "_type": "val_epoch", "cur_epoch": "160", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:36:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "161", "cur_iter": "1", "dt": 1.28802, "dt_data": 0.74923, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.29126, "lr": 0.00010, "mode": "train"}
[12/07 18:36:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "162", "cur_iter": "1", "dt": 1.29115, "dt_data": 0.75265, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.27664, "lr": 0.00010, "mode": "train"}
[12/07 18:36:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "163", "cur_iter": "1", "dt": 1.29186, "dt_data": 0.75226, "dt_net": 0.53960, "eta": "0:00:01", "loss": 0.28465, "lr": 0.00010, "mode": "train"}
[12/07 18:36:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "164", "cur_iter": "1", "dt": 1.29146, "dt_data": 0.75100, "dt_net": 0.54045, "eta": "0:00:01", "loss": 0.27793, "lr": 0.00010, "mode": "train"}
[12/07 18:36:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 1.29143, "dt_data": 0.75143, "dt_net": 0.54000, "eta": "0:00:01", "loss": 0.27834, "lr": 0.00010, "mode": "train"}
[12/07 18:36:43][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 0.84754, "dt_data": 0.77330, "dt_net": 0.07421, "eta": "0:00:00", "mode": "val"}
[12/07 18:36:43][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:36:43][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:36:43][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:36:43][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:43][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:36:43][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:43][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:36:43][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003061 seconds.
[12/07 18:36:43][INFO] logging.py:  96: json_stats: {"RAM": "2.36/15.59G", "_type": "val_epoch", "cur_epoch": "165", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:36:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "166", "cur_iter": "1", "dt": 1.28856, "dt_data": 0.74859, "dt_net": 0.53997, "eta": "0:00:01", "loss": 0.26974, "lr": 0.00010, "mode": "train"}
[12/07 18:36:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "167", "cur_iter": "1", "dt": 1.28993, "dt_data": 0.74961, "dt_net": 0.54032, "eta": "0:00:01", "loss": 0.27717, "lr": 0.00010, "mode": "train"}
[12/07 18:36:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "168", "cur_iter": "1", "dt": 1.29146, "dt_data": 0.75104, "dt_net": 0.54042, "eta": "0:00:01", "loss": 0.27786, "lr": 0.00010, "mode": "train"}
[12/07 18:36:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "169", "cur_iter": "1", "dt": 1.29060, "dt_data": 0.75088, "dt_net": 0.53972, "eta": "0:00:01", "loss": 0.28618, "lr": 0.00010, "mode": "train"}
[12/07 18:36:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 1.29249, "dt_data": 0.75219, "dt_net": 0.54030, "eta": "0:00:01", "loss": 0.27323, "lr": 0.00010, "mode": "train"}
[12/07 18:36:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 0.84378, "dt_data": 0.76956, "dt_net": 0.07421, "eta": "0:00:00", "mode": "val"}
[12/07 18:36:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:36:52][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:36:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:36:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:36:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:36:52][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:36:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003092 seconds.
[12/07 18:36:52][INFO] logging.py:  96: json_stats: {"RAM": "2.36/15.59G", "_type": "val_epoch", "cur_epoch": "170", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:36:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "171", "cur_iter": "1", "dt": 1.28733, "dt_data": 0.74701, "dt_net": 0.54031, "eta": "0:00:01", "loss": 0.27322, "lr": 0.00010, "mode": "train"}
[12/07 18:36:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "172", "cur_iter": "1", "dt": 1.28799, "dt_data": 0.74803, "dt_net": 0.53996, "eta": "0:00:01", "loss": 0.27642, "lr": 0.00010, "mode": "train"}
[12/07 18:36:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "173", "cur_iter": "1", "dt": 1.29153, "dt_data": 0.75113, "dt_net": 0.54039, "eta": "0:00:01", "loss": 0.27623, "lr": 0.00010, "mode": "train"}
[12/07 18:36:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "174", "cur_iter": "1", "dt": 1.29376, "dt_data": 0.75332, "dt_net": 0.54044, "eta": "0:00:01", "loss": 0.26877, "lr": 0.00010, "mode": "train"}
[12/07 18:36:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 1.29252, "dt_data": 0.75222, "dt_net": 0.54029, "eta": "0:00:01", "loss": 0.27604, "lr": 0.00010, "mode": "train"}
[12/07 18:37:00][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 0.84610, "dt_data": 0.77194, "dt_net": 0.07416, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:00][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:00][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:00][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:00][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:00][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:00][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003069 seconds.
[12/07 18:37:00][INFO] logging.py:  96: json_stats: {"RAM": "2.36/15.59G", "_type": "val_epoch", "cur_epoch": "175", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:37:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "176", "cur_iter": "1", "dt": 1.28885, "dt_data": 0.75026, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.27185, "lr": 0.00010, "mode": "train"}
[12/07 18:37:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "177", "cur_iter": "1", "dt": 1.28443, "dt_data": 0.74617, "dt_net": 0.53826, "eta": "0:00:01", "loss": 0.27456, "lr": 0.00010, "mode": "train"}
[12/07 18:37:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "178", "cur_iter": "1", "dt": 1.32768, "dt_data": 0.78871, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27092, "lr": 0.00010, "mode": "train"}
[12/07 18:37:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "179", "cur_iter": "1", "dt": 1.28603, "dt_data": 0.74741, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.28539, "lr": 0.00010, "mode": "train"}
[12/07 18:37:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 1.28755, "dt_data": 0.74871, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.27137, "lr": 0.00010, "mode": "train"}
[12/07 18:37:09][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 0.84388, "dt_data": 0.76993, "dt_net": 0.07394, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:09][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:09][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:09][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:09][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:09][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:09][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:09][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003000 seconds.
[12/07 18:37:09][INFO] logging.py:  96: json_stats: {"RAM": "2.36/15.59G", "_type": "val_epoch", "cur_epoch": "180", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:37:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "181", "cur_iter": "1", "dt": 1.28865, "dt_data": 0.74989, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27690, "lr": 0.00010, "mode": "train"}
[12/07 18:37:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "182", "cur_iter": "1", "dt": 1.28907, "dt_data": 0.75042, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.27646, "lr": 0.00010, "mode": "train"}
[12/07 18:37:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "183", "cur_iter": "1", "dt": 1.28925, "dt_data": 0.75088, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.27638, "lr": 0.00010, "mode": "train"}
[12/07 18:37:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "184", "cur_iter": "1", "dt": 1.29028, "dt_data": 0.75134, "dt_net": 0.53893, "eta": "0:00:01", "loss": 0.27221, "lr": 0.00010, "mode": "train"}
[12/07 18:37:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 1.29124, "dt_data": 0.75248, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27123, "lr": 0.00010, "mode": "train"}
[12/07 18:37:17][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 0.84315, "dt_data": 0.76883, "dt_net": 0.07431, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:17][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:17][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:17][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:17][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:17][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:17][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:17][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:17][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003089 seconds.
[12/07 18:37:17][INFO] logging.py:  96: json_stats: {"RAM": "2.36/15.59G", "_type": "val_epoch", "cur_epoch": "185", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:37:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "186", "cur_iter": "1", "dt": 1.28832, "dt_data": 0.74944, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.28185, "lr": 0.00010, "mode": "train"}
[12/07 18:37:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "187", "cur_iter": "1", "dt": 1.28778, "dt_data": 0.74927, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.27331, "lr": 0.00010, "mode": "train"}
[12/07 18:37:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "188", "cur_iter": "1", "dt": 1.29087, "dt_data": 0.75181, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.28415, "lr": 0.00010, "mode": "train"}
[12/07 18:37:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "189", "cur_iter": "1", "dt": 1.28621, "dt_data": 0.74753, "dt_net": 0.53867, "eta": "0:00:01", "loss": 0.27207, "lr": 0.00010, "mode": "train"}
[12/07 18:37:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 1.30597, "dt_data": 0.76638, "dt_net": 0.53958, "eta": "0:00:01", "loss": 0.26990, "lr": 0.00010, "mode": "train"}
[12/07 18:37:25][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 0.85807, "dt_data": 0.78405, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:25][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:25][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:25][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:25][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:25][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:25][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:25][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:25][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003009 seconds.
[12/07 18:37:25][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "190", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:37:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "191", "cur_iter": "1", "dt": 1.28781, "dt_data": 0.74916, "dt_net": 0.53865, "eta": "0:00:01", "loss": 0.27505, "lr": 0.00010, "mode": "train"}
[12/07 18:37:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "192", "cur_iter": "1", "dt": 1.28645, "dt_data": 0.74794, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.27216, "lr": 0.00010, "mode": "train"}
[12/07 18:37:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "193", "cur_iter": "1", "dt": 1.28736, "dt_data": 0.74874, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.29071, "lr": 0.00010, "mode": "train"}
[12/07 18:37:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "194", "cur_iter": "1", "dt": 1.29072, "dt_data": 0.75220, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.27197, "lr": 0.00010, "mode": "train"}
[12/07 18:37:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 1.29039, "dt_data": 0.75171, "dt_net": 0.53867, "eta": "0:00:01", "loss": 0.26996, "lr": 0.00010, "mode": "train"}
[12/07 18:37:34][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 0.84380, "dt_data": 0.76988, "dt_net": 0.07391, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:34][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:34][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:34][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:34][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:34][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:34][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003108 seconds.
[12/07 18:37:34][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "195", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:37:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "196", "cur_iter": "1", "dt": 1.28820, "dt_data": 0.74933, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.26771, "lr": 0.00010, "mode": "train"}
[12/07 18:37:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "197", "cur_iter": "1", "dt": 1.28694, "dt_data": 0.74796, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27544, "lr": 0.00010, "mode": "train"}
[12/07 18:37:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "198", "cur_iter": "1", "dt": 1.28725, "dt_data": 0.74858, "dt_net": 0.53866, "eta": "0:00:01", "loss": 0.27762, "lr": 0.00010, "mode": "train"}
[12/07 18:37:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "199", "cur_iter": "1", "dt": 1.29053, "dt_data": 0.75169, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.27278, "lr": 0.00010, "mode": "train"}
[12/07 18:37:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 1.29271, "dt_data": 0.75371, "dt_net": 0.53900, "eta": "0:00:01", "loss": 0.28249, "lr": 0.00010, "mode": "train"}
[12/07 18:37:42][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 0.84102, "dt_data": 0.76703, "dt_net": 0.07398, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:42][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:42][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:42][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:42][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:42][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:42][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003009 seconds.
[12/07 18:37:42][INFO] logging.py:  96: json_stats: {"RAM": "2.42/15.59G", "_type": "val_epoch", "cur_epoch": "200", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:37:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "201", "cur_iter": "1", "dt": 1.28982, "dt_data": 0.75082, "dt_net": 0.53899, "eta": "0:00:01", "loss": 0.27482, "lr": 0.00010, "mode": "train"}
[12/07 18:37:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "202", "cur_iter": "1", "dt": 1.28885, "dt_data": 0.75028, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.27787, "lr": 0.00010, "mode": "train"}
[12/07 18:37:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "203", "cur_iter": "1", "dt": 1.28982, "dt_data": 0.75069, "dt_net": 0.53913, "eta": "0:00:01", "loss": 0.26696, "lr": 0.00010, "mode": "train"}
[12/07 18:37:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "204", "cur_iter": "1", "dt": 1.29266, "dt_data": 0.75369, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27190, "lr": 0.00010, "mode": "train"}
[12/07 18:37:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 1.29181, "dt_data": 0.75335, "dt_net": 0.53846, "eta": "0:00:01", "loss": 0.27779, "lr": 0.00010, "mode": "train"}
[12/07 18:37:50][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 0.82698, "dt_data": 0.75329, "dt_net": 0.07369, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:50][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:50][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:50][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:50][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:50][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:50][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:50][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002875 seconds.
[12/07 18:37:50][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "205", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:37:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "206", "cur_iter": "1", "dt": 1.28745, "dt_data": 0.74898, "dt_net": 0.53847, "eta": "0:00:01", "loss": 0.27328, "lr": 0.00010, "mode": "train"}
[12/07 18:37:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "207", "cur_iter": "1", "dt": 1.28997, "dt_data": 0.75101, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.27576, "lr": 0.00010, "mode": "train"}
[12/07 18:37:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "208", "cur_iter": "1", "dt": 1.29174, "dt_data": 0.75272, "dt_net": 0.53901, "eta": "0:00:01", "loss": 0.27785, "lr": 0.00010, "mode": "train"}
[12/07 18:37:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "209", "cur_iter": "1", "dt": 1.28655, "dt_data": 0.74834, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.26923, "lr": 0.00010, "mode": "train"}
[12/07 18:37:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 1.29098, "dt_data": 0.75227, "dt_net": 0.53871, "eta": "0:00:01", "loss": 0.27151, "lr": 0.00010, "mode": "train"}
[12/07 18:37:59][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 0.84458, "dt_data": 0.77057, "dt_net": 0.07400, "eta": "0:00:00", "mode": "val"}
[12/07 18:37:59][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:37:59][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:37:59][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:37:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:59][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:37:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:37:59][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:37:59][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002985 seconds.
[12/07 18:37:59][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "210", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "211", "cur_iter": "1", "dt": 1.28901, "dt_data": 0.75009, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.26837, "lr": 0.00010, "mode": "train"}
[12/07 18:38:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "212", "cur_iter": "1", "dt": 1.29037, "dt_data": 0.75169, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.27562, "lr": 0.00010, "mode": "train"}
[12/07 18:38:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "213", "cur_iter": "1", "dt": 1.29093, "dt_data": 0.75228, "dt_net": 0.53865, "eta": "0:00:01", "loss": 0.27190, "lr": 0.00010, "mode": "train"}
[12/07 18:38:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "214", "cur_iter": "1", "dt": 1.28988, "dt_data": 0.75122, "dt_net": 0.53865, "eta": "0:00:01", "loss": 0.28022, "lr": 0.00010, "mode": "train"}
[12/07 18:38:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 1.29048, "dt_data": 0.75231, "dt_net": 0.53816, "eta": "0:00:01", "loss": 0.27426, "lr": 0.00010, "mode": "train"}
[12/07 18:38:07][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 0.84592, "dt_data": 0.77179, "dt_net": 0.07412, "eta": "0:00:00", "mode": "val"}
[12/07 18:38:07][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:38:07][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:38:07][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:38:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:07][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:38:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:07][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:38:07][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002922 seconds.
[12/07 18:38:07][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "215", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "216", "cur_iter": "1", "dt": 1.28655, "dt_data": 0.74807, "dt_net": 0.53848, "eta": "0:00:01", "loss": 0.27296, "lr": 0.00010, "mode": "train"}
[12/07 18:38:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "217", "cur_iter": "1", "dt": 1.28968, "dt_data": 0.75129, "dt_net": 0.53838, "eta": "0:00:01", "loss": 0.27092, "lr": 0.00010, "mode": "train"}
[12/07 18:38:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "218", "cur_iter": "1", "dt": 1.29133, "dt_data": 0.75233, "dt_net": 0.53899, "eta": "0:00:01", "loss": 0.27395, "lr": 0.00010, "mode": "train"}
[12/07 18:38:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "219", "cur_iter": "1", "dt": 1.28945, "dt_data": 0.75153, "dt_net": 0.53792, "eta": "0:00:01", "loss": 0.27038, "lr": 0.00010, "mode": "train"}
[12/07 18:38:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 1.28945, "dt_data": 0.75102, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.26677, "lr": 0.00010, "mode": "train"}
[12/07 18:38:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 0.83972, "dt_data": 0.76584, "dt_net": 0.07387, "eta": "0:00:00", "mode": "val"}
[12/07 18:38:16][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:38:16][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:38:16][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:38:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:16][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:38:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:16][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:38:16][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003116 seconds.
[12/07 18:38:16][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "220", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "221", "cur_iter": "1", "dt": 1.29133, "dt_data": 0.75298, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.27632, "lr": 0.00010, "mode": "train"}
[12/07 18:38:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "222", "cur_iter": "1", "dt": 1.28862, "dt_data": 0.74972, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.28885, "lr": 0.00010, "mode": "train"}
[12/07 18:38:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "223", "cur_iter": "1", "dt": 1.29015, "dt_data": 0.75187, "dt_net": 0.53827, "eta": "0:00:01", "loss": 0.27214, "lr": 0.00010, "mode": "train"}
[12/07 18:38:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "224", "cur_iter": "1", "dt": 1.28701, "dt_data": 0.74783, "dt_net": 0.53917, "eta": "0:00:01", "loss": 0.27462, "lr": 0.00010, "mode": "train"}
[12/07 18:38:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 1.28939, "dt_data": 0.75044, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.27011, "lr": 0.00010, "mode": "train"}
[12/07 18:38:24][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 0.84418, "dt_data": 0.76978, "dt_net": 0.07439, "eta": "0:00:00", "mode": "val"}
[12/07 18:38:24][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:38:24][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:38:24][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:38:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:24][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:38:24][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:24][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:38:24][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003044 seconds.
[12/07 18:38:24][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "225", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "226", "cur_iter": "1", "dt": 1.28859, "dt_data": 0.74980, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.27121, "lr": 0.00010, "mode": "train"}
[12/07 18:38:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "227", "cur_iter": "1", "dt": 1.28535, "dt_data": 0.74697, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.27079, "lr": 0.00010, "mode": "train"}
[12/07 18:38:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "228", "cur_iter": "1", "dt": 1.28683, "dt_data": 0.74833, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.27527, "lr": 0.00010, "mode": "train"}
[12/07 18:38:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "229", "cur_iter": "1", "dt": 1.28595, "dt_data": 0.74739, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.27468, "lr": 0.00010, "mode": "train"}
[12/07 18:38:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 1.29183, "dt_data": 0.75321, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.26776, "lr": 0.00010, "mode": "train"}
[12/07 18:38:32][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 0.84510, "dt_data": 0.77107, "dt_net": 0.07402, "eta": "0:00:00", "mode": "val"}
[12/07 18:38:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:38:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:38:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:38:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:38:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:38:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003098 seconds.
[12/07 18:38:32][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "230", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "231", "cur_iter": "1", "dt": 1.28795, "dt_data": 0.74923, "dt_net": 0.53872, "eta": "0:00:01", "loss": 0.26636, "lr": 0.00010, "mode": "train"}
[12/07 18:38:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "232", "cur_iter": "1", "dt": 1.29066, "dt_data": 0.75170, "dt_net": 0.53895, "eta": "0:00:01", "loss": 0.27061, "lr": 0.00010, "mode": "train"}
[12/07 18:38:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "233", "cur_iter": "1", "dt": 1.29223, "dt_data": 0.75227, "dt_net": 0.53996, "eta": "0:00:01", "loss": 0.27311, "lr": 0.00010, "mode": "train"}
[12/07 18:38:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "234", "cur_iter": "1", "dt": 1.29006, "dt_data": 0.75003, "dt_net": 0.54003, "eta": "0:00:01", "loss": 0.26867, "lr": 0.00010, "mode": "train"}
[12/07 18:38:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 1.29131, "dt_data": 0.75061, "dt_net": 0.54069, "eta": "0:00:01", "loss": 0.27408, "lr": 0.00010, "mode": "train"}
[12/07 18:38:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 0.84033, "dt_data": 0.76642, "dt_net": 0.07391, "eta": "0:00:00", "mode": "val"}
[12/07 18:38:41][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:38:41][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:38:41][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:38:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:41][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:38:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:41][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:38:41][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003105 seconds.
[12/07 18:38:41][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "235", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "236", "cur_iter": "1", "dt": 1.28831, "dt_data": 0.74790, "dt_net": 0.54040, "eta": "0:00:01", "loss": 0.26923, "lr": 0.00010, "mode": "train"}
[12/07 18:38:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "237", "cur_iter": "1", "dt": 1.28954, "dt_data": 0.74908, "dt_net": 0.54046, "eta": "0:00:01", "loss": 0.27090, "lr": 0.00010, "mode": "train"}
[12/07 18:38:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "238", "cur_iter": "1", "dt": 1.29115, "dt_data": 0.75116, "dt_net": 0.53998, "eta": "0:00:01", "loss": 0.27752, "lr": 0.00010, "mode": "train"}
[12/07 18:38:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "239", "cur_iter": "1", "dt": 1.29219, "dt_data": 0.75177, "dt_net": 0.54041, "eta": "0:00:01", "loss": 0.26779, "lr": 0.00010, "mode": "train"}
[12/07 18:38:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 1.29807, "dt_data": 0.75768, "dt_net": 0.54038, "eta": "0:00:01", "loss": 0.27676, "lr": 0.00010, "mode": "train"}
[12/07 18:38:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 0.84313, "dt_data": 0.76877, "dt_net": 0.07435, "eta": "0:00:00", "mode": "val"}
[12/07 18:38:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:38:49][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:38:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:38:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:38:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:49][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:38:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002855 seconds.
[12/07 18:38:49][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "240", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "241", "cur_iter": "1", "dt": 1.29097, "dt_data": 0.75136, "dt_net": 0.53961, "eta": "0:00:01", "loss": 0.27823, "lr": 0.00010, "mode": "train"}
[12/07 18:38:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "242", "cur_iter": "1", "dt": 1.28601, "dt_data": 0.74764, "dt_net": 0.53837, "eta": "0:00:01", "loss": 0.27179, "lr": 0.00010, "mode": "train"}
[12/07 18:38:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "243", "cur_iter": "1", "dt": 1.29131, "dt_data": 0.75257, "dt_net": 0.53873, "eta": "0:00:01", "loss": 0.26612, "lr": 0.00010, "mode": "train"}
[12/07 18:38:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "244", "cur_iter": "1", "dt": 1.28871, "dt_data": 0.75011, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.26621, "lr": 0.00010, "mode": "train"}
[12/07 18:38:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 1.29071, "dt_data": 0.75201, "dt_net": 0.53870, "eta": "0:00:01", "loss": 0.28387, "lr": 0.00010, "mode": "train"}
[12/07 18:38:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 0.84388, "dt_data": 0.77010, "dt_net": 0.07377, "eta": "0:00:00", "mode": "val"}
[12/07 18:38:57][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:38:57][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:38:57][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:38:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:57][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:38:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:38:57][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:38:57][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002963 seconds.
[12/07 18:38:57][INFO] logging.py:  96: json_stats: {"RAM": "2.43/15.59G", "_type": "val_epoch", "cur_epoch": "245", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:38:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "246", "cur_iter": "1", "dt": 1.28638, "dt_data": 0.74822, "dt_net": 0.53816, "eta": "0:00:01", "loss": 0.27541, "lr": 0.00010, "mode": "train"}
[12/07 18:39:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "247", "cur_iter": "1", "dt": 1.29042, "dt_data": 0.75163, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.26634, "lr": 0.00010, "mode": "train"}
[12/07 18:39:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "248", "cur_iter": "1", "dt": 1.29016, "dt_data": 0.75189, "dt_net": 0.53827, "eta": "0:00:01", "loss": 0.27353, "lr": 0.00010, "mode": "train"}
[12/07 18:39:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "249", "cur_iter": "1", "dt": 1.28983, "dt_data": 0.75143, "dt_net": 0.53840, "eta": "0:00:01", "loss": 0.27353, "lr": 0.00010, "mode": "train"}
[12/07 18:39:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 1.29050, "dt_data": 0.75190, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.26855, "lr": 0.00010, "mode": "train"}
[12/07 18:39:06][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 0.84413, "dt_data": 0.77015, "dt_net": 0.07397, "eta": "0:00:00", "mode": "val"}
[12/07 18:39:06][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:39:06][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:39:06][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:39:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:06][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:39:06][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:06][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:39:06][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003022 seconds.
[12/07 18:39:06][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "250", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:39:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "251", "cur_iter": "1", "dt": 1.28803, "dt_data": 0.74912, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.28017, "lr": 0.00010, "mode": "train"}
[12/07 18:39:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "252", "cur_iter": "1", "dt": 1.29000, "dt_data": 0.75170, "dt_net": 0.53830, "eta": "0:00:01", "loss": 0.27683, "lr": 0.00010, "mode": "train"}
[12/07 18:39:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "253", "cur_iter": "1", "dt": 1.29002, "dt_data": 0.75116, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.28144, "lr": 0.00010, "mode": "train"}
[12/07 18:39:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "254", "cur_iter": "1", "dt": 1.29029, "dt_data": 0.75129, "dt_net": 0.53900, "eta": "0:00:01", "loss": 0.26512, "lr": 0.00010, "mode": "train"}
[12/07 18:39:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 1.29098, "dt_data": 0.75254, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.27228, "lr": 0.00010, "mode": "train"}
[12/07 18:39:14][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 0.84571, "dt_data": 0.77164, "dt_net": 0.07407, "eta": "0:00:00", "mode": "val"}
[12/07 18:39:14][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:39:14][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:39:14][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:39:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:14][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:39:14][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:14][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:39:14][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003103 seconds.
[12/07 18:39:14][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "255", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:39:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "256", "cur_iter": "1", "dt": 1.28667, "dt_data": 0.74825, "dt_net": 0.53841, "eta": "0:00:01", "loss": 0.28455, "lr": 0.00010, "mode": "train"}
[12/07 18:39:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "257", "cur_iter": "1", "dt": 1.29291, "dt_data": 0.75385, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.27314, "lr": 0.00010, "mode": "train"}
[12/07 18:39:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "258", "cur_iter": "1", "dt": 1.29093, "dt_data": 0.75208, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.26657, "lr": 0.00010, "mode": "train"}
[12/07 18:39:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "259", "cur_iter": "1", "dt": 1.28518, "dt_data": 0.74688, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.27075, "lr": 0.00010, "mode": "train"}
[12/07 18:39:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 1.29059, "dt_data": 0.75165, "dt_net": 0.53893, "eta": "0:00:01", "loss": 0.27821, "lr": 0.00010, "mode": "train"}
[12/07 18:39:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 0.84229, "dt_data": 0.76848, "dt_net": 0.07380, "eta": "0:00:00", "mode": "val"}
[12/07 18:39:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:39:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:39:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:39:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:39:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:39:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003220 seconds.
[12/07 18:39:23][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "260", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:39:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "261", "cur_iter": "1", "dt": 1.28633, "dt_data": 0.74746, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27295, "lr": 0.00010, "mode": "train"}
[12/07 18:39:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "262", "cur_iter": "1", "dt": 1.29099, "dt_data": 0.75216, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.29128, "lr": 0.00010, "mode": "train"}
[12/07 18:39:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "263", "cur_iter": "1", "dt": 1.28963, "dt_data": 0.75144, "dt_net": 0.53818, "eta": "0:00:01", "loss": 0.27147, "lr": 0.00010, "mode": "train"}
[12/07 18:39:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "264", "cur_iter": "1", "dt": 1.29045, "dt_data": 0.75159, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.26776, "lr": 0.00010, "mode": "train"}
[12/07 18:39:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 1.28704, "dt_data": 0.74875, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.27070, "lr": 0.00010, "mode": "train"}
[12/07 18:39:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 0.84334, "dt_data": 0.76954, "dt_net": 0.07379, "eta": "0:00:00", "mode": "val"}
[12/07 18:39:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:39:31][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:39:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:39:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:39:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:31][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:39:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003106 seconds.
[12/07 18:39:31][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "265", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:39:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "266", "cur_iter": "1", "dt": 1.28955, "dt_data": 0.75041, "dt_net": 0.53913, "eta": "0:00:01", "loss": 0.27467, "lr": 0.00010, "mode": "train"}
[12/07 18:39:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "267", "cur_iter": "1", "dt": 1.29207, "dt_data": 0.75334, "dt_net": 0.53872, "eta": "0:00:01", "loss": 0.26671, "lr": 0.00010, "mode": "train"}
[12/07 18:39:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "268", "cur_iter": "1", "dt": 1.29043, "dt_data": 0.75141, "dt_net": 0.53902, "eta": "0:00:01", "loss": 0.27262, "lr": 0.00010, "mode": "train"}
[12/07 18:39:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "269", "cur_iter": "1", "dt": 1.28999, "dt_data": 0.75117, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.26849, "lr": 0.00010, "mode": "train"}
[12/07 18:39:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 1.28763, "dt_data": 0.74950, "dt_net": 0.53812, "eta": "0:00:01", "loss": 0.26538, "lr": 0.00010, "mode": "train"}
[12/07 18:39:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 0.84336, "dt_data": 0.76933, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/07 18:39:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:39:39][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:39:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:39:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:39:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:39][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:39:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002952 seconds.
[12/07 18:39:39][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "270", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:39:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "271", "cur_iter": "1", "dt": 1.28937, "dt_data": 0.75073, "dt_net": 0.53863, "eta": "0:00:01", "loss": 0.26523, "lr": 0.00010, "mode": "train"}
[12/07 18:39:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "272", "cur_iter": "1", "dt": 1.28964, "dt_data": 0.75097, "dt_net": 0.53867, "eta": "0:00:01", "loss": 0.27446, "lr": 0.00010, "mode": "train"}
[12/07 18:39:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "273", "cur_iter": "1", "dt": 1.29150, "dt_data": 0.75265, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.27838, "lr": 0.00010, "mode": "train"}
[12/07 18:39:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "274", "cur_iter": "1", "dt": 1.28935, "dt_data": 0.75100, "dt_net": 0.53834, "eta": "0:00:01", "loss": 0.26915, "lr": 0.00010, "mode": "train"}
[12/07 18:39:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 1.29419, "dt_data": 0.75520, "dt_net": 0.53898, "eta": "0:00:01", "loss": 0.27341, "lr": 0.00010, "mode": "train"}
[12/07 18:39:48][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 0.84141, "dt_data": 0.76725, "dt_net": 0.07415, "eta": "0:00:00", "mode": "val"}
[12/07 18:39:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:39:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:39:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:39:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:39:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:39:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003125 seconds.
[12/07 18:39:48][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "275", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:39:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "276", "cur_iter": "1", "dt": 1.28869, "dt_data": 0.74988, "dt_net": 0.53880, "eta": "0:00:01", "loss": 0.27033, "lr": 0.00010, "mode": "train"}
[12/07 18:39:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "277", "cur_iter": "1", "dt": 1.28895, "dt_data": 0.75024, "dt_net": 0.53870, "eta": "0:00:01", "loss": 0.26759, "lr": 0.00010, "mode": "train"}
[12/07 18:39:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "278", "cur_iter": "1", "dt": 1.29109, "dt_data": 0.75292, "dt_net": 0.53817, "eta": "0:00:01", "loss": 0.27123, "lr": 0.00010, "mode": "train"}
[12/07 18:39:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "279", "cur_iter": "1", "dt": 1.29027, "dt_data": 0.75148, "dt_net": 0.53878, "eta": "0:00:01", "loss": 0.27063, "lr": 0.00010, "mode": "train"}
[12/07 18:39:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 1.28727, "dt_data": 0.74915, "dt_net": 0.53811, "eta": "0:00:01", "loss": 0.28020, "lr": 0.00010, "mode": "train"}
[12/07 18:39:56][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 0.86371, "dt_data": 0.78971, "dt_net": 0.07400, "eta": "0:00:00", "mode": "val"}
[12/07 18:39:56][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:39:56][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:39:56][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:39:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:56][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:39:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:39:56][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:39:56][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003147 seconds.
[12/07 18:39:56][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "280", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:39:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "281", "cur_iter": "1", "dt": 1.29092, "dt_data": 0.75213, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.26756, "lr": 0.00010, "mode": "train"}
[12/07 18:39:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "282", "cur_iter": "1", "dt": 1.29073, "dt_data": 0.75172, "dt_net": 0.53901, "eta": "0:00:01", "loss": 0.28200, "lr": 0.00010, "mode": "train"}
[12/07 18:40:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "283", "cur_iter": "1", "dt": 1.29311, "dt_data": 0.75411, "dt_net": 0.53900, "eta": "0:00:01", "loss": 0.27965, "lr": 0.00010, "mode": "train"}
[12/07 18:40:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "284", "cur_iter": "1", "dt": 1.28977, "dt_data": 0.75123, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.26991, "lr": 0.00010, "mode": "train"}
[12/07 18:40:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 1.29064, "dt_data": 0.75204, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.26743, "lr": 0.00010, "mode": "train"}
[12/07 18:40:05][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 0.85388, "dt_data": 0.77978, "dt_net": 0.07409, "eta": "0:00:00", "mode": "val"}
[12/07 18:40:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:40:05][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:40:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:40:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:40:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:05][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:40:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003279 seconds.
[12/07 18:40:05][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "285", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:40:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "286", "cur_iter": "1", "dt": 1.29234, "dt_data": 0.75351, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.27148, "lr": 0.00010, "mode": "train"}
[12/07 18:40:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "287", "cur_iter": "1", "dt": 1.29609, "dt_data": 0.75698, "dt_net": 0.53910, "eta": "0:00:01", "loss": 0.26696, "lr": 0.00010, "mode": "train"}
[12/07 18:40:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "288", "cur_iter": "1", "dt": 1.29681, "dt_data": 0.75805, "dt_net": 0.53875, "eta": "0:00:01", "loss": 0.27054, "lr": 0.00010, "mode": "train"}
[12/07 18:40:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "289", "cur_iter": "1", "dt": 1.29693, "dt_data": 0.75811, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.27102, "lr": 0.00010, "mode": "train"}
[12/07 18:40:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 1.29605, "dt_data": 0.75698, "dt_net": 0.53906, "eta": "0:00:01", "loss": 0.27596, "lr": 0.00010, "mode": "train"}
[12/07 18:40:13][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 0.84750, "dt_data": 0.77338, "dt_net": 0.07411, "eta": "0:00:00", "mode": "val"}
[12/07 18:40:13][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:40:13][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:40:13][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:40:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:13][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:40:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:13][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:40:13][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003045 seconds.
[12/07 18:40:13][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "290", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:40:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "291", "cur_iter": "1", "dt": 1.28960, "dt_data": 0.75071, "dt_net": 0.53888, "eta": "0:00:01", "loss": 0.26825, "lr": 0.00010, "mode": "train"}
[12/07 18:40:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "292", "cur_iter": "1", "dt": 1.29275, "dt_data": 0.75439, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27640, "lr": 0.00010, "mode": "train"}
[12/07 18:40:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "293", "cur_iter": "1", "dt": 1.29059, "dt_data": 0.75174, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.27009, "lr": 0.00010, "mode": "train"}
[12/07 18:40:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "294", "cur_iter": "1", "dt": 1.29390, "dt_data": 0.75503, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.26319, "lr": 0.00010, "mode": "train"}
[12/07 18:40:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 1.29353, "dt_data": 0.75498, "dt_net": 0.53855, "eta": "0:00:01", "loss": 0.27450, "lr": 0.00010, "mode": "train"}
[12/07 18:40:21][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 0.84607, "dt_data": 0.77222, "dt_net": 0.07383, "eta": "0:00:00", "mode": "val"}
[12/07 18:40:21][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:40:21][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:40:21][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:40:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:21][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:40:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:21][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:40:21][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002959 seconds.
[12/07 18:40:21][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "295", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 18:40:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "296", "cur_iter": "1", "dt": 1.28912, "dt_data": 0.75084, "dt_net": 0.53828, "eta": "0:00:01", "loss": 0.27057, "lr": 0.00010, "mode": "train"}
[12/07 18:40:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "297", "cur_iter": "1", "dt": 1.29109, "dt_data": 0.75246, "dt_net": 0.53863, "eta": "0:00:01", "loss": 0.26672, "lr": 0.00010, "mode": "train"}
[12/07 18:40:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "298", "cur_iter": "1", "dt": 1.29355, "dt_data": 0.75479, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.27005, "lr": 0.00010, "mode": "train"}
[12/07 18:40:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "299", "cur_iter": "1", "dt": 1.29137, "dt_data": 0.75314, "dt_net": 0.53823, "eta": "0:00:01", "loss": 0.26684, "lr": 0.00010, "mode": "train"}
[12/07 18:40:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 1.29247, "dt_data": 0.75386, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.26777, "lr": 0.00010, "mode": "train"}
[12/07 18:40:30][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 0.84455, "dt_data": 0.77038, "dt_net": 0.07416, "eta": "0:00:00", "mode": "val"}
[12/07 18:40:30][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 18:40:30][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 18:40:30][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 18:40:30][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:30][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 18:40:30][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 18:40:30][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 18:40:30][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003152 seconds.
[12/07 18:40:30][INFO] logging.py:  96: json_stats: {"RAM": "2.44/15.59G", "_type": "val_epoch", "cur_epoch": "300", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/07 21:25:23][INFO] train_net.py: 377: Train with config:
[12/07 21:25:23][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/07 21:25:26][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/07 21:25:26][INFO] misc.py: 170: Params: 33,653,708
[12/07 21:25:26][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/07 21:25:27][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/07 21:25:27][INFO] misc.py: 172: Flops: 74.18020761599999 G
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/07 21:25:27][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/07 21:25:27][INFO] misc.py: 177: Activations: 155.545604 M
[12/07 21:25:27][INFO] misc.py: 182: nvidia-smi
[12/07 21:25:27][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/07 21:25:27][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/07 21:25:27][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/07 21:25:27][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/07 21:25:27][INFO] ava_helper.py: 111: Number of annotations: 15
[12/07 21:25:27][INFO] ava_helper.py: 157: 1 keyframes used.
[12/07 21:25:27][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/07 21:25:27][INFO] ava_dataset.py:  89: Split: train
[12/07 21:25:27][INFO] ava_dataset.py:  90: Number of videos: 1
[12/07 21:25:27][INFO] ava_dataset.py:  94: Number of frames: 5
[12/07 21:25:27][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/07 21:25:27][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/07 21:25:27][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/07 21:25:27][INFO] ava_helper.py: 106: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/07 21:25:27][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/07 21:25:27][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/07 21:25:27][INFO] ava_helper.py: 111: Number of annotations: 11
[12/07 21:25:27][INFO] ava_helper.py: 157: 1 keyframes used.
[12/07 21:25:27][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/07 21:25:27][INFO] ava_dataset.py:  89: Split: val
[12/07 21:25:27][INFO] ava_dataset.py:  90: Number of videos: 1
[12/07 21:25:27][INFO] ava_dataset.py:  94: Number of frames: 4
[12/07 21:25:27][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/07 21:25:27][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/07 21:25:27][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/07 21:25:27][INFO] ava_helper.py:  61: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/07 21:25:29][DEBUG] tpu_cluster_resolver.py:  34: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
[12/07 21:25:30][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/07 21:25:30][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/07 21:25:30][DEBUG] __init__.py:  47: Creating converter from 7 to 5
[12/07 21:25:30][DEBUG] __init__.py:  47: Creating converter from 5 to 7
[12/07 21:25:32][INFO] tensorboard_vis.py:  54: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/07 21:25:32][INFO] tensorboard_vis.py:  63: Plotting confusion matrix is currently                     not supported for detection.
[12/07 21:25:32][INFO] train_net.py: 417: Start epoch: 1
[12/07 21:25:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.55787, "dt_data": 0.99410, "dt_net": 0.56376, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/07 21:25:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.56207, "dt_data": 1.02460, "dt_net": 0.53746, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/07 21:25:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.56556, "dt_data": 1.02705, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/07 21:25:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.53834, "dt_data": 0.99925, "dt_net": 0.53908, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/07 21:25:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.52258, "dt_data": 0.98341, "dt_net": 0.53916, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/07 21:25:45][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.03999, "dt_data": 0.96616, "dt_net": 0.07382, "eta": "0:00:01", "mode": "val"}
[12/07 21:25:47][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:25:47][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:25:47][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:25:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:25:47][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:25:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:25:47][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:25:47][INFO] ava_eval_helper.py: 169: AVA eval done in 0.010173 seconds.
[12/07 21:25:47][INFO] logging.py:  96: json_stats: {"RAM": "2.30/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.77G", "map": 0.72492, "mode": "val"}
[12/07 21:25:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.53630, "dt_data": 0.99560, "dt_net": 0.54069, "eta": "0:00:01", "loss": 0.92406, "lr": 0.10000, "mode": "train"}
[12/07 21:25:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.53689, "dt_data": 0.99804, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.72319, "lr": 0.10000, "mode": "train"}
[12/07 21:25:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.54257, "dt_data": 1.00299, "dt_net": 0.53957, "eta": "0:00:01", "loss": 0.70610, "lr": 0.10000, "mode": "train"}
[12/07 21:25:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.54367, "dt_data": 1.00403, "dt_net": 0.53963, "eta": "0:00:01", "loss": 0.47180, "lr": 0.10000, "mode": "train"}
[12/07 21:25:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.53634, "dt_data": 0.99617, "dt_net": 0.54016, "eta": "0:00:01", "loss": 0.74046, "lr": 0.10000, "mode": "train"}
[12/07 21:26:00][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.04580, "dt_data": 0.97170, "dt_net": 0.07408, "eta": "0:00:01", "mode": "val"}
[12/07 21:26:01][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:26:01][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:26:01][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:26:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:01][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:26:01][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:01][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:26:01][INFO] ava_eval_helper.py: 169: AVA eval done in 0.008441 seconds.
[12/07 21:26:01][INFO] logging.py:  96: json_stats: {"RAM": "2.31/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.77G", "map": 0.79801, "mode": "val"}
[12/07 21:26:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.55686, "dt_data": 1.01519, "dt_net": 0.54167, "eta": "0:00:01", "loss": 1.08006, "lr": 0.01000, "mode": "train"}
[12/07 21:26:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.52542, "dt_data": 0.98522, "dt_net": 0.54019, "eta": "0:00:01", "loss": 0.87886, "lr": 0.01000, "mode": "train"}
[12/07 21:26:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.54221, "dt_data": 1.00217, "dt_net": 0.54003, "eta": "0:00:01", "loss": 0.43822, "lr": 0.01000, "mode": "train"}
[12/07 21:26:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.52025, "dt_data": 0.98061, "dt_net": 0.53963, "eta": "0:00:01", "loss": 0.32955, "lr": 0.01000, "mode": "train"}
[12/07 21:26:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.53328, "dt_data": 0.99364, "dt_net": 0.53963, "eta": "0:00:01", "loss": 0.28628, "lr": 0.01000, "mode": "train"}
[12/07 21:26:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.07823, "dt_data": 0.99534, "dt_net": 0.08288, "eta": "0:00:01", "mode": "val"}
[12/07 21:26:17][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:26:17][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:26:17][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:26:17][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:17][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:26:17][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:17][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:26:17][INFO] ava_eval_helper.py: 169: AVA eval done in 0.008970 seconds.
[12/07 21:26:17][INFO] logging.py:  96: json_stats: {"RAM": "2.31/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.77G", "map": 0.62998, "mode": "val"}
[12/07 21:26:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.57127, "dt_data": 1.03169, "dt_net": 0.53957, "eta": "0:00:01", "loss": 0.37981, "lr": 0.00100, "mode": "train"}
[12/07 21:26:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.55050, "dt_data": 1.01103, "dt_net": 0.53946, "eta": "0:00:01", "loss": 0.37516, "lr": 0.00100, "mode": "train"}
[12/07 21:26:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.61780, "dt_data": 1.07807, "dt_net": 0.53971, "eta": "0:00:01", "loss": 0.36268, "lr": 0.00100, "mode": "train"}
[12/07 21:26:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.52248, "dt_data": 0.98361, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.34600, "lr": 0.00100, "mode": "train"}
[12/07 21:26:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.52675, "dt_data": 0.98707, "dt_net": 0.53967, "eta": "0:00:01", "loss": 0.35189, "lr": 0.00100, "mode": "train"}
[12/07 21:26:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.04947, "dt_data": 0.97486, "dt_net": 0.07459, "eta": "0:00:01", "mode": "val"}
[12/07 21:26:32][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:26:32][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:26:32][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:26:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:32][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:26:32][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:32][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:26:32][INFO] ava_eval_helper.py: 169: AVA eval done in 0.009066 seconds.
[12/07 21:26:32][INFO] logging.py:  96: json_stats: {"RAM": "2.31/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.77G", "map": 0.55498, "mode": "val"}
[12/07 21:26:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "21", "cur_iter": "1", "dt": 1.56681, "dt_data": 1.02648, "dt_net": 0.54032, "eta": "0:00:01", "loss": 0.32042, "lr": 0.00010, "mode": "train"}
[12/07 21:26:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "22", "cur_iter": "1", "dt": 1.53476, "dt_data": 0.99560, "dt_net": 0.53915, "eta": "0:00:01", "loss": 0.33547, "lr": 0.00010, "mode": "train"}
[12/07 21:26:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "23", "cur_iter": "1", "dt": 1.52980, "dt_data": 0.98932, "dt_net": 0.54047, "eta": "0:00:01", "loss": 0.33181, "lr": 0.00010, "mode": "train"}
[12/07 21:26:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "24", "cur_iter": "1", "dt": 1.60136, "dt_data": 1.05970, "dt_net": 0.54164, "eta": "0:00:01", "loss": 0.32635, "lr": 0.00010, "mode": "train"}
[12/07 21:26:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 1.52517, "dt_data": 0.98555, "dt_net": 0.53960, "eta": "0:00:01", "loss": 0.32610, "lr": 0.00010, "mode": "train"}
[12/07 21:26:47][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 1.08852, "dt_data": 1.01490, "dt_net": 0.07362, "eta": "0:00:01", "mode": "val"}
[12/07 21:26:48][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:26:48][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:26:48][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:26:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:48][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:26:48][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:26:48][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:26:48][INFO] ava_eval_helper.py: 169: AVA eval done in 0.009028 seconds.
[12/07 21:26:48][INFO] logging.py:  96: json_stats: {"RAM": "2.32/15.59G", "_type": "val_epoch", "cur_epoch": "25", "gpu_mem": "1.88G", "map": 0.55498, "mode": "val"}
[12/07 21:26:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "26", "cur_iter": "1", "dt": 1.58041, "dt_data": 1.04113, "dt_net": 0.53927, "eta": "0:00:01", "loss": 0.32569, "lr": 0.00010, "mode": "train"}
[12/07 21:26:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "27", "cur_iter": "1", "dt": 1.53670, "dt_data": 0.99602, "dt_net": 0.54067, "eta": "0:00:01", "loss": 0.31246, "lr": 0.00010, "mode": "train"}
[12/07 21:26:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "28", "cur_iter": "1", "dt": 1.53537, "dt_data": 0.99668, "dt_net": 0.53868, "eta": "0:00:01", "loss": 0.31582, "lr": 0.00010, "mode": "train"}
[12/07 21:26:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "29", "cur_iter": "1", "dt": 1.54788, "dt_data": 1.00820, "dt_net": 0.53967, "eta": "0:00:01", "loss": 0.33216, "lr": 0.00010, "mode": "train"}
[12/07 21:27:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.53802, "dt_data": 0.99861, "dt_net": 0.53940, "eta": "0:00:01", "loss": 0.28949, "lr": 0.00010, "mode": "train"}
[12/07 21:27:03][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.08105, "dt_data": 0.99831, "dt_net": 0.08272, "eta": "0:00:01", "mode": "val"}
[12/07 21:27:04][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:27:04][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:27:04][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:27:04][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:04][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:27:04][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:04][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:27:04][INFO] ava_eval_helper.py: 169: AVA eval done in 0.009003 seconds.
[12/07 21:27:04][INFO] logging.py:  96: json_stats: {"RAM": "2.32/15.59G", "_type": "val_epoch", "cur_epoch": "30", "gpu_mem": "1.88G", "map": 0.54416, "mode": "val"}
[12/07 21:27:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "31", "cur_iter": "1", "dt": 1.58365, "dt_data": 1.04220, "dt_net": 0.54144, "eta": "0:00:01", "loss": 0.31592, "lr": 0.00010, "mode": "train"}
[12/07 21:27:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "32", "cur_iter": "1", "dt": 1.54271, "dt_data": 1.00005, "dt_net": 0.54265, "eta": "0:00:01", "loss": 0.31104, "lr": 0.00010, "mode": "train"}
[12/07 21:27:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "33", "cur_iter": "1", "dt": 1.82643, "dt_data": 1.28517, "dt_net": 0.54125, "eta": "0:00:01", "loss": 0.33400, "lr": 0.00010, "mode": "train"}
[12/07 21:27:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "34", "cur_iter": "1", "dt": 1.55110, "dt_data": 1.00961, "dt_net": 0.54148, "eta": "0:00:01", "loss": 0.31195, "lr": 0.00010, "mode": "train"}
[12/07 21:27:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 1.54377, "dt_data": 1.00154, "dt_net": 0.54222, "eta": "0:00:01", "loss": 0.32253, "lr": 0.00010, "mode": "train"}
[12/07 21:27:21][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 1.06763, "dt_data": 0.99350, "dt_net": 0.07411, "eta": "0:00:01", "mode": "val"}
[12/07 21:27:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:27:23][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:27:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:27:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:27:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:23][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:27:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.010247 seconds.
[12/07 21:27:23][INFO] logging.py:  96: json_stats: {"RAM": "2.33/15.59G", "_type": "val_epoch", "cur_epoch": "35", "gpu_mem": "1.88G", "map": 0.55882, "mode": "val"}
[12/07 21:27:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "36", "cur_iter": "1", "dt": 1.57557, "dt_data": 1.03454, "dt_net": 0.54102, "eta": "0:00:01", "loss": 0.28505, "lr": 0.00010, "mode": "train"}
[12/07 21:27:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "37", "cur_iter": "1", "dt": 1.55750, "dt_data": 1.01583, "dt_net": 0.54167, "eta": "0:00:01", "loss": 0.33745, "lr": 0.00010, "mode": "train"}
[12/07 21:27:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "38", "cur_iter": "1", "dt": 1.53317, "dt_data": 0.99224, "dt_net": 0.54092, "eta": "0:00:01", "loss": 0.33405, "lr": 0.00010, "mode": "train"}
[12/07 21:27:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "39", "cur_iter": "1", "dt": 1.62816, "dt_data": 1.08684, "dt_net": 0.54131, "eta": "0:00:01", "loss": 0.29750, "lr": 0.00010, "mode": "train"}
[12/07 21:27:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 1.55323, "dt_data": 1.01209, "dt_net": 0.54113, "eta": "0:00:01", "loss": 0.30568, "lr": 0.00010, "mode": "train"}
[12/07 21:27:38][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 1.06705, "dt_data": 0.99244, "dt_net": 0.07459, "eta": "0:00:01", "mode": "val"}
[12/07 21:27:40][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:27:40][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:27:40][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:27:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:40][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:27:40][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:40][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:27:40][INFO] ava_eval_helper.py: 169: AVA eval done in 0.009200 seconds.
[12/07 21:27:40][INFO] logging.py:  96: json_stats: {"RAM": "2.33/15.59G", "_type": "val_epoch", "cur_epoch": "40", "gpu_mem": "1.88G", "map": 0.54632, "mode": "val"}
[12/07 21:27:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "41", "cur_iter": "1", "dt": 1.67308, "dt_data": 1.12869, "dt_net": 0.54438, "eta": "0:00:01", "loss": 0.29414, "lr": 0.00010, "mode": "train"}
[12/07 21:27:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "42", "cur_iter": "1", "dt": 1.55224, "dt_data": 1.01129, "dt_net": 0.54094, "eta": "0:00:01", "loss": 0.32511, "lr": 0.00010, "mode": "train"}
[12/07 21:27:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "43", "cur_iter": "1", "dt": 1.56311, "dt_data": 1.02046, "dt_net": 0.54264, "eta": "0:00:01", "loss": 0.32639, "lr": 0.00010, "mode": "train"}
[12/07 21:27:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "44", "cur_iter": "1", "dt": 1.57540, "dt_data": 1.03405, "dt_net": 0.54134, "eta": "0:00:01", "loss": 0.33603, "lr": 0.00010, "mode": "train"}
[12/07 21:27:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 1.54626, "dt_data": 1.00429, "dt_net": 0.54195, "eta": "0:00:01", "loss": 0.30316, "lr": 0.00010, "mode": "train"}
[12/07 21:27:55][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 1.08292, "dt_data": 1.00055, "dt_net": 0.08236, "eta": "0:00:01", "mode": "val"}
[12/07 21:27:56][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:27:56][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:27:56][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:27:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:56][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:27:56][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:27:56][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:27:56][INFO] ava_eval_helper.py: 169: AVA eval done in 0.010014 seconds.
[12/07 21:27:56][INFO] logging.py:  96: json_stats: {"RAM": "2.34/15.59G", "_type": "val_epoch", "cur_epoch": "45", "gpu_mem": "1.88G", "map": 0.54416, "mode": "val"}
[12/07 21:27:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "46", "cur_iter": "1", "dt": 1.58167, "dt_data": 1.04002, "dt_net": 0.54164, "eta": "0:00:01", "loss": 0.28812, "lr": 0.00010, "mode": "train"}
[12/07 21:28:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "47", "cur_iter": "1", "dt": 1.58511, "dt_data": 1.04291, "dt_net": 0.54219, "eta": "0:00:01", "loss": 0.33441, "lr": 0.00010, "mode": "train"}
[12/07 21:28:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "48", "cur_iter": "1", "dt": 1.55972, "dt_data": 1.01590, "dt_net": 0.54381, "eta": "0:00:01", "loss": 0.30379, "lr": 0.00010, "mode": "train"}
[12/07 21:28:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "49", "cur_iter": "1", "dt": 1.57808, "dt_data": 1.03374, "dt_net": 0.54433, "eta": "0:00:01", "loss": 0.30420, "lr": 0.00010, "mode": "train"}
[12/07 21:28:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 1.62869, "dt_data": 1.08328, "dt_net": 0.54541, "eta": "0:00:01", "loss": 0.29697, "lr": 0.00010, "mode": "train"}
[12/07 21:28:12][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 1.08112, "dt_data": 1.00648, "dt_net": 0.07462, "eta": "0:00:01", "mode": "val"}
[12/07 21:28:13][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/07 21:28:13][INFO] ava_eval_helper.py: 160: Evaluating with 1 unique detection frames
[12/07 21:28:13][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/07 21:28:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:28:13][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/07 21:28:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/07 21:28:13][INFO] object_detection_evaluation.py: 767: The following classes have no ground truth examples: [2 4]
[12/07 21:28:13][INFO] ava_eval_helper.py: 169: AVA eval done in 0.009297 seconds.
[12/07 21:28:13][INFO] logging.py:  96: json_stats: {"RAM": "2.34/15.59G", "_type": "val_epoch", "cur_epoch": "50", "gpu_mem": "1.88G", "map": 0.54416, "mode": "val"}
[12/07 21:28:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "51", "cur_iter": "1", "dt": 1.62281, "dt_data": 1.07888, "dt_net": 0.54393, "eta": "0:00:01", "loss": 0.28866, "lr": 0.00010, "mode": "train"}
[12/07 21:28:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "52", "cur_iter": "1", "dt": 1.62202, "dt_data": 1.07586, "dt_net": 0.54616, "eta": "0:00:01", "loss": 0.34335, "lr": 0.00010, "mode": "train"}
[12/08 21:17:20][INFO] train_net.py: 377: Train with config:
[12/08 21:17:20][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': True,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/08 21:17:22][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/08 21:17:22][INFO] misc.py: 170: Params: 33,653,708
[12/08 21:17:22][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/08 21:17:22][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/08 21:17:22][INFO] misc.py: 174: Flops: 74.18020761599999 G
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/08 21:17:22][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/08 21:17:22][INFO] misc.py: 179: Activations: 155.545604 M
[12/08 21:17:22][INFO] misc.py: 182: nvidia-smi
[12/08 21:17:22][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/08 21:17:22][INFO] ava_helper.py: 107: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/08 21:17:22][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/08 21:17:22][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/08 21:17:22][INFO] ava_helper.py: 111: Number of annotations: 15
[12/08 21:17:22][INFO] ava_helper.py: 157: 1 keyframes used.
[12/08 21:17:22][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/08 21:17:22][INFO] ava_dataset.py:  89: Split: train
[12/08 21:17:22][INFO] ava_dataset.py:  90: Number of videos: 1
[12/08 21:17:22][INFO] ava_dataset.py:  94: Number of frames: 5
[12/08 21:17:22][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/08 21:17:22][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/08 21:17:22][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/08 21:17:22][INFO] ava_helper.py: 107: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/08 21:17:22][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/08 21:17:22][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/08 21:17:22][INFO] ava_helper.py: 111: Number of annotations: 11
[12/08 21:17:22][INFO] ava_helper.py: 157: 1 keyframes used.
[12/08 21:17:22][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/08 21:17:22][INFO] ava_dataset.py:  89: Split: val
[12/08 21:17:22][INFO] ava_dataset.py:  90: Number of videos: 1
[12/08 21:17:22][INFO] ava_dataset.py:  94: Number of frames: 4
[12/08 21:17:22][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/08 21:17:22][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/08 21:17:22][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/08 21:17:22][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/08 21:17:22][INFO] tensorboard_vis.py:  57: To see logged results in Tensorboard, please launch using the command             `tensorboard  --port=<port-number> --logdir /home/gnk/ava2/out_log`
[12/08 21:17:22][INFO] tensorboard_vis.py:  65: Plotting confusion matrix is currently                     not supported for detection.
[12/08 21:17:22][INFO] train_net.py: 417: Start epoch: 1
[12/08 21:17:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.30242, "dt_data": 0.77168, "dt_net": 0.53074, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/08 21:17:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.28986, "dt_data": 0.75593, "dt_net": 0.53392, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/08 21:17:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.29212, "dt_data": 0.75715, "dt_net": 0.53496, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/08 21:17:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.29054, "dt_data": 0.75579, "dt_net": 0.53474, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/08 21:17:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.29298, "dt_data": 0.75862, "dt_net": 0.53436, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/08 21:17:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.85007, "dt_data": 0.77654, "dt_net": 0.07353, "eta": "0:00:00", "mode": "val"}
[12/08 21:17:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/08 21:17:31][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/08 21:17:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/08 21:17:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/08 21:17:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/08 21:17:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/08 21:17:31][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/08 21:17:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003387 seconds.
[12/08 21:17:31][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/08 21:17:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.29166, "dt_data": 0.75755, "dt_net": 0.53412, "eta": "0:00:01", "loss": 0.92366, "lr": 0.10000, "mode": "train"}
[12/08 21:17:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.29260, "dt_data": 0.75800, "dt_net": 0.53460, "eta": "0:00:01", "loss": 0.72910, "lr": 0.10000, "mode": "train"}
[12/09 00:30:19][INFO] train_net.py: 377: Train with config:
[12/09 00:30:19][INFO] train_net.py: 378: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data_ava/data/ava/annotations/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': '',
         'FRAME_DIR': '/home/gnk/data_ava/data/ava/frames/',
         'FRAME_LIST_DIR': '/home/gnk/data_ava/data/ava/frame_lists/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_bbox5.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'action_list.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_bbox5.csv'],
         'TRAIN_GT_BOX_LISTS': [],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['train_ava_box.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data_ava/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 5,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 4,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '/home/gnk/data_ava/data/ava/annotations/AVA_classnames.json',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '/home/gnk/ava2/out_log',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '/home/gnk/ava2/results',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': '/home/gnk/ava2/predictions'},
 'TRAIN': {'AUTO_RESUME': False,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[12/09 00:30:21][INFO] misc.py: 169: Model:
SlowFast(
  (s1): VideoModelStem(
    (pathway0_stem): ResNetBasicStem(
      (conv): Conv3d(3, 64, kernel_size=[1, 7, 7], stride=[1, 2, 2], padding=[0, 3, 3], bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (pathway1_stem): ResNetBasicStem(
      (conv): Conv3d(3, 8, kernel_size=[5, 7, 7], stride=[1, 2, 2], padding=[2, 3, 3], bias=False)
      (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
  )
  (s1_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(8, 16, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s2): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(80, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(8, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 8, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(8, 8, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(8, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s2_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(32, 64, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
  (s3): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(320, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(512, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(128, 128, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(128, 512, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(32, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 16, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(16, 16, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(16, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s3_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(64, 128, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s4): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(640, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(1024, 256, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(256, 256, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(256, 1024, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=[1, 2, 2], bias=False)
      (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(64, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res3): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res4): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res5): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 32, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(32, 32, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 1, 1], dilation=[1, 1, 1], bias=False)
        (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(32, 128, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (s4_fuse): FuseFastToSlow(
    (conv_f2s): Conv3d(128, 256, kernel_size=[7, 1, 1], stride=[4, 1, 1], padding=[3, 0, 0], bias=False)
    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (s5): ResStage(
    (pathway0_res0): ResBlock(
      (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(1280, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway0_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(2048, 512, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(512, 512, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(512, 2048, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res0): ResBlock(
      (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=[1, 1, 1], bias=False)
      (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (branch2): BottleneckTransform(
        (a): Conv3d(128, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res1): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
    (pathway1_res2): ResBlock(
      (branch2): BottleneckTransform(
        (a): Conv3d(256, 64, kernel_size=[3, 1, 1], stride=[1, 1, 1], padding=[1, 0, 0], bias=False)
        (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (a_relu): ReLU(inplace=True)
        (b): Conv3d(64, 64, kernel_size=[1, 3, 3], stride=[1, 1, 1], padding=[0, 2, 2], dilation=[1, 2, 2], bias=False)
        (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (b_relu): ReLU(inplace=True)
        (c): Conv3d(64, 256, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], bias=False)
        (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (relu): ReLU(inplace=True)
    )
  )
  (head): ResNetRoIHead(
    (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
    (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (s1_tpool): AvgPool3d(kernel_size=[32, 1, 1], stride=1, padding=0)
    (s1_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
    (s1_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=2304, out_features=4, bias=True)
    (act): Sigmoid()
  )
)
[12/09 00:30:21][INFO] misc.py: 170: Params: 33,653,708
[12/09 00:30:21][INFO] misc.py: 171: Mem: 0.1263289451599121 MB
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::batch_norm 110 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::relu_ 102 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::max_pool3d 4 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::add 32 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::avg_pool3d 2 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation prim::PythonOp 2 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::max_pool2d 2 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::dropout 1 time(s)
[12/09 00:30:21][WARNING] flop_count.py:  63: Skipped operation aten::sigmoid 1 time(s)
[12/09 00:30:21][INFO] misc.py: 174: Flops: 74.18020761599999 G
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::batch_norm 110 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::relu_ 102 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::max_pool3d 4 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::add 32 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::avg_pool3d 2 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation prim::PythonOp 2 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::max_pool2d 2 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::dropout 1 time(s)
[12/09 00:30:21][WARNING] activation_count.py:  54: Skipped operation aten::sigmoid 1 time(s)
[12/09 00:30:21][INFO] misc.py: 179: Activations: 155.545604 M
[12/09 00:30:21][INFO] misc.py: 182: nvidia-smi
[12/09 00:30:21][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/09 00:30:21][INFO] ava_helper.py: 107: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/train_ava_box.csv
[12/09 00:30:21][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/09 00:30:21][INFO] ava_helper.py: 110: Number of unique boxes: 15
[12/09 00:30:21][INFO] ava_helper.py: 111: Number of annotations: 15
[12/09 00:30:21][INFO] ava_helper.py: 157: 1 keyframes used.
[12/09 00:30:21][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/09 00:30:21][INFO] ava_dataset.py:  89: Split: train
[12/09 00:30:21][INFO] ava_dataset.py:  90: Number of videos: 1
[12/09 00:30:21][INFO] ava_dataset.py:  94: Number of frames: 5
[12/09 00:30:21][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/09 00:30:21][INFO] ava_dataset.py:  96: Number of boxes: 15.
[12/09 00:30:21][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/09 00:30:21][INFO] ava_helper.py: 107: Finished loading annotations from: /home/gnk/data_ava/data/ava/annotations/ava_bbox5.csv
[12/09 00:30:21][INFO] ava_helper.py: 109: Detection threshold: 0.8
[12/09 00:30:21][INFO] ava_helper.py: 110: Number of unique boxes: 11
[12/09 00:30:21][INFO] ava_helper.py: 111: Number of annotations: 11
[12/09 00:30:21][INFO] ava_helper.py: 157: 1 keyframes used.
[12/09 00:30:21][INFO] ava_dataset.py:  88: === AVA dataset summary ===
[12/09 00:30:21][INFO] ava_dataset.py:  89: Split: val
[12/09 00:30:21][INFO] ava_dataset.py:  90: Number of videos: 1
[12/09 00:30:21][INFO] ava_dataset.py:  94: Number of frames: 4
[12/09 00:30:21][INFO] ava_dataset.py:  95: Number of key frames: 1
[12/09 00:30:21][INFO] ava_dataset.py:  96: Number of boxes: 11.
[12/09 00:30:21][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/train3.csv
[12/09 00:30:21][INFO] ava_helper.py:  62: Finished loading image paths from: /home/gnk/data_ava/data/ava/frame_lists/val3.csv
[12/09 00:30:21][INFO] train_net.py: 417: Start epoch: 1
[12/09 00:30:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "1", "cur_iter": "1", "dt": 1.29778, "dt_data": 0.76986, "dt_net": 0.52792, "eta": "0:00:01", "loss": 0.67910, "lr": 0.00013, "mode": "train"}
[12/09 00:30:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "2", "cur_iter": "1", "dt": 1.29200, "dt_data": 0.75889, "dt_net": 0.53311, "eta": "0:00:01", "loss": 0.67648, "lr": 0.02010, "mode": "train"}
[12/09 00:30:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "3", "cur_iter": "1", "dt": 1.28909, "dt_data": 0.75536, "dt_net": 0.53372, "eta": "0:00:01", "loss": 0.49547, "lr": 0.04007, "mode": "train"}
[12/09 00:30:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "4", "cur_iter": "1", "dt": 1.28870, "dt_data": 0.75422, "dt_net": 0.53448, "eta": "0:00:01", "loss": 0.45404, "lr": 0.06005, "mode": "train"}
[12/09 00:30:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 1.29665, "dt_data": 0.76288, "dt_net": 0.53376, "eta": "0:00:01", "loss": 0.58495, "lr": 0.08002, "mode": "train"}
[12/09 00:30:29][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "5", "cur_iter": "1", "dt": 0.82188, "dt_data": 0.74846, "dt_net": 0.07342, "eta": "0:00:00", "mode": "val"}
[12/09 00:30:29][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:30:29][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:30:29][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:30:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:29][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:30:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:29][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:30:29][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003393 seconds.
[12/09 00:30:29][INFO] logging.py:  96: json_stats: {"RAM": "2.45/15.59G", "_type": "val_epoch", "cur_epoch": "5", "gpu_mem": "1.74G", "map": 0.72492, "mode": "val"}
[12/09 00:30:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "6", "cur_iter": "1", "dt": 1.29195, "dt_data": 0.75847, "dt_net": 0.53348, "eta": "0:00:01", "loss": 0.92423, "lr": 0.10000, "mode": "train"}
[12/09 00:30:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "7", "cur_iter": "1", "dt": 1.28891, "dt_data": 0.75466, "dt_net": 0.53425, "eta": "0:00:01", "loss": 0.72841, "lr": 0.10000, "mode": "train"}
[12/09 00:30:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "8", "cur_iter": "1", "dt": 1.29169, "dt_data": 0.75764, "dt_net": 0.53405, "eta": "0:00:01", "loss": 0.69435, "lr": 0.10000, "mode": "train"}
[12/09 00:30:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "9", "cur_iter": "1", "dt": 1.28960, "dt_data": 0.75543, "dt_net": 0.53417, "eta": "0:00:01", "loss": 0.47372, "lr": 0.10000, "mode": "train"}
[12/09 00:30:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 1.28949, "dt_data": 0.75604, "dt_net": 0.53345, "eta": "0:00:01", "loss": 0.64199, "lr": 0.10000, "mode": "train"}
[12/09 00:30:36][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "10", "cur_iter": "1", "dt": 0.82085, "dt_data": 0.74740, "dt_net": 0.07345, "eta": "0:00:00", "mode": "val"}
[12/09 00:30:36][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:30:36][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:30:36][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:30:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:36][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:30:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:36][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:30:36][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003224 seconds.
[12/09 00:30:36][INFO] logging.py:  96: json_stats: {"RAM": "2.45/15.59G", "_type": "val_epoch", "cur_epoch": "10", "gpu_mem": "1.74G", "map": 0.80645, "mode": "val"}
[12/09 00:30:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "11", "cur_iter": "1", "dt": 1.29179, "dt_data": 0.75770, "dt_net": 0.53409, "eta": "0:00:01", "loss": 1.24241, "lr": 0.01000, "mode": "train"}
[12/09 00:30:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "12", "cur_iter": "1", "dt": 1.29285, "dt_data": 0.75812, "dt_net": 0.53473, "eta": "0:00:01", "loss": 0.90911, "lr": 0.01000, "mode": "train"}
[12/09 00:30:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "13", "cur_iter": "1", "dt": 1.28997, "dt_data": 0.75642, "dt_net": 0.53355, "eta": "0:00:01", "loss": 0.40978, "lr": 0.01000, "mode": "train"}
[12/09 00:30:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "14", "cur_iter": "1", "dt": 1.28914, "dt_data": 0.75445, "dt_net": 0.53469, "eta": "0:00:01", "loss": 0.32260, "lr": 0.01000, "mode": "train"}
[12/09 00:30:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 1.29151, "dt_data": 0.75771, "dt_net": 0.53380, "eta": "0:00:01", "loss": 0.28079, "lr": 0.01000, "mode": "train"}
[12/09 00:30:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "15", "cur_iter": "1", "dt": 0.82394, "dt_data": 0.75073, "dt_net": 0.07320, "eta": "0:00:00", "mode": "val"}
[12/09 00:30:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:30:44][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:30:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:30:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:30:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:44][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:30:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003208 seconds.
[12/09 00:30:44][INFO] logging.py:  96: json_stats: {"RAM": "2.45/15.59G", "_type": "val_epoch", "cur_epoch": "15", "gpu_mem": "1.74G", "map": 0.58108, "mode": "val"}
[12/09 00:30:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "16", "cur_iter": "1", "dt": 1.29281, "dt_data": 0.75891, "dt_net": 0.53390, "eta": "0:00:01", "loss": 0.35413, "lr": 0.00100, "mode": "train"}
[12/09 00:30:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "17", "cur_iter": "1", "dt": 1.29403, "dt_data": 0.75959, "dt_net": 0.53444, "eta": "0:00:01", "loss": 0.36680, "lr": 0.00100, "mode": "train"}
[12/09 00:30:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "18", "cur_iter": "1", "dt": 1.28939, "dt_data": 0.75562, "dt_net": 0.53377, "eta": "0:00:01", "loss": 0.32157, "lr": 0.00100, "mode": "train"}
[12/09 00:30:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "19", "cur_iter": "1", "dt": 1.29148, "dt_data": 0.75736, "dt_net": 0.53412, "eta": "0:00:01", "loss": 0.31332, "lr": 0.00100, "mode": "train"}
[12/09 00:30:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 1.29607, "dt_data": 0.76198, "dt_net": 0.53409, "eta": "0:00:01", "loss": 0.32184, "lr": 0.00100, "mode": "train"}
[12/09 00:30:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "20", "cur_iter": "1", "dt": 0.84449, "dt_data": 0.77082, "dt_net": 0.07367, "eta": "0:00:00", "mode": "val"}
[12/09 00:30:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:30:52][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:30:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:30:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:30:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:30:52][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:30:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003312 seconds.
[12/09 00:30:52][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "20", "gpu_mem": "1.74G", "map": 0.55498, "mode": "val"}
[12/09 00:30:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "21", "cur_iter": "1", "dt": 1.28958, "dt_data": 0.75564, "dt_net": 0.53393, "eta": "0:00:01", "loss": 0.30347, "lr": 0.00010, "mode": "train"}
[12/09 00:30:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "22", "cur_iter": "1", "dt": 1.28980, "dt_data": 0.75574, "dt_net": 0.53406, "eta": "0:00:01", "loss": 0.32521, "lr": 0.00010, "mode": "train"}
[12/09 00:30:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "23", "cur_iter": "1", "dt": 1.29060, "dt_data": 0.75739, "dt_net": 0.53320, "eta": "0:00:01", "loss": 0.31722, "lr": 0.00010, "mode": "train"}
[12/09 00:30:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "24", "cur_iter": "1", "dt": 1.28837, "dt_data": 0.75418, "dt_net": 0.53419, "eta": "0:00:01", "loss": 0.29298, "lr": 0.00010, "mode": "train"}
[12/09 00:30:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 1.29246, "dt_data": 0.75882, "dt_net": 0.53364, "eta": "0:00:01", "loss": 0.32156, "lr": 0.00010, "mode": "train"}
[12/09 00:31:00][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "25", "cur_iter": "1", "dt": 0.82453, "dt_data": 0.75077, "dt_net": 0.07375, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:00][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:00][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:00][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:00][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:00][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:00][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003240 seconds.
[12/09 00:31:00][INFO] logging.py:  96: json_stats: {"RAM": "2.45/15.59G", "_type": "val_epoch", "cur_epoch": "25", "gpu_mem": "1.74G", "map": 0.57013, "mode": "val"}
[12/09 00:31:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "26", "cur_iter": "1", "dt": 1.29035, "dt_data": 0.75684, "dt_net": 0.53351, "eta": "0:00:01", "loss": 0.32070, "lr": 0.00010, "mode": "train"}
[12/09 00:31:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "27", "cur_iter": "1", "dt": 1.29239, "dt_data": 0.75880, "dt_net": 0.53358, "eta": "0:00:01", "loss": 0.30806, "lr": 0.00010, "mode": "train"}
[12/09 00:31:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "28", "cur_iter": "1", "dt": 1.29391, "dt_data": 0.75997, "dt_net": 0.53394, "eta": "0:00:01", "loss": 0.31304, "lr": 0.00010, "mode": "train"}
[12/09 00:31:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "29", "cur_iter": "1", "dt": 1.29167, "dt_data": 0.75799, "dt_net": 0.53367, "eta": "0:00:01", "loss": 0.30046, "lr": 0.00010, "mode": "train"}
[12/09 00:31:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 1.29002, "dt_data": 0.75622, "dt_net": 0.53380, "eta": "0:00:01", "loss": 0.28138, "lr": 0.00010, "mode": "train"}
[12/09 00:31:07][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "30", "cur_iter": "1", "dt": 0.82388, "dt_data": 0.75026, "dt_net": 0.07362, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:07][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:07][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:07][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:07][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:07][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:07][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:07][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003308 seconds.
[12/09 00:31:07][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "30", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/09 00:31:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "31", "cur_iter": "1", "dt": 1.29274, "dt_data": 0.75943, "dt_net": 0.53331, "eta": "0:00:01", "loss": 0.28455, "lr": 0.00010, "mode": "train"}
[12/09 00:31:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "32", "cur_iter": "1", "dt": 1.29095, "dt_data": 0.75701, "dt_net": 0.53394, "eta": "0:00:01", "loss": 0.30398, "lr": 0.00010, "mode": "train"}
[12/09 00:31:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "33", "cur_iter": "1", "dt": 1.29348, "dt_data": 0.76053, "dt_net": 0.53295, "eta": "0:00:01", "loss": 0.32643, "lr": 0.00010, "mode": "train"}
[12/09 00:31:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "34", "cur_iter": "1", "dt": 1.28985, "dt_data": 0.75544, "dt_net": 0.53440, "eta": "0:00:01", "loss": 0.29830, "lr": 0.00010, "mode": "train"}
[12/09 00:31:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 1.29677, "dt_data": 0.76376, "dt_net": 0.53301, "eta": "0:00:01", "loss": 0.30890, "lr": 0.00010, "mode": "train"}
[12/09 00:31:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "35", "cur_iter": "1", "dt": 0.82304, "dt_data": 0.74945, "dt_net": 0.07359, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:15][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:15][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003056 seconds.
[12/09 00:31:15][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "35", "gpu_mem": "1.74G", "map": 0.62132, "mode": "val"}
[12/09 00:31:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "36", "cur_iter": "1", "dt": 1.29170, "dt_data": 0.75845, "dt_net": 0.53325, "eta": "0:00:01", "loss": 0.27888, "lr": 0.00010, "mode": "train"}
[12/09 00:31:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "37", "cur_iter": "1", "dt": 1.29331, "dt_data": 0.75887, "dt_net": 0.53443, "eta": "0:00:01", "loss": 0.32624, "lr": 0.00010, "mode": "train"}
[12/09 00:31:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "38", "cur_iter": "1", "dt": 1.29359, "dt_data": 0.75991, "dt_net": 0.53368, "eta": "0:00:01", "loss": 0.32685, "lr": 0.00010, "mode": "train"}
[12/09 00:31:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "39", "cur_iter": "1", "dt": 1.28771, "dt_data": 0.75405, "dt_net": 0.53365, "eta": "0:00:01", "loss": 0.29023, "lr": 0.00010, "mode": "train"}
[12/09 00:31:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 1.29217, "dt_data": 0.75712, "dt_net": 0.53505, "eta": "0:00:01", "loss": 0.29749, "lr": 0.00010, "mode": "train"}
[12/09 00:31:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "40", "cur_iter": "1", "dt": 0.84405, "dt_data": 0.77044, "dt_net": 0.07361, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:23][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:23][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:24][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003198 seconds.
[12/09 00:31:24][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "40", "gpu_mem": "1.74G", "map": 0.54632, "mode": "val"}
[12/09 00:31:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "41", "cur_iter": "1", "dt": 1.29394, "dt_data": 0.75816, "dt_net": 0.53578, "eta": "0:00:01", "loss": 0.29020, "lr": 0.00010, "mode": "train"}
[12/09 00:31:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "42", "cur_iter": "1", "dt": 1.29467, "dt_data": 0.75818, "dt_net": 0.53649, "eta": "0:00:01", "loss": 0.32598, "lr": 0.00010, "mode": "train"}
[12/09 00:31:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "43", "cur_iter": "1", "dt": 1.29662, "dt_data": 0.76009, "dt_net": 0.53652, "eta": "0:00:01", "loss": 0.31248, "lr": 0.00010, "mode": "train"}
[12/09 00:31:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "44", "cur_iter": "1", "dt": 1.29137, "dt_data": 0.75473, "dt_net": 0.53664, "eta": "0:00:01", "loss": 0.33250, "lr": 0.00010, "mode": "train"}
[12/09 00:31:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 1.29484, "dt_data": 0.75911, "dt_net": 0.53573, "eta": "0:00:01", "loss": 0.29433, "lr": 0.00010, "mode": "train"}
[12/09 00:31:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "45", "cur_iter": "1", "dt": 0.82391, "dt_data": 0.74982, "dt_net": 0.07409, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:31][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:31][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003203 seconds.
[12/09 00:31:31][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "45", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:31:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "46", "cur_iter": "1", "dt": 1.29377, "dt_data": 0.75801, "dt_net": 0.53576, "eta": "0:00:01", "loss": 0.28223, "lr": 0.00010, "mode": "train"}
[12/09 00:31:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "47", "cur_iter": "1", "dt": 1.29086, "dt_data": 0.75409, "dt_net": 0.53677, "eta": "0:00:01", "loss": 0.31810, "lr": 0.00010, "mode": "train"}
[12/09 00:31:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "48", "cur_iter": "1", "dt": 1.29321, "dt_data": 0.75709, "dt_net": 0.53611, "eta": "0:00:01", "loss": 0.29433, "lr": 0.00010, "mode": "train"}
[12/09 00:31:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "49", "cur_iter": "1", "dt": 1.29382, "dt_data": 0.75754, "dt_net": 0.53627, "eta": "0:00:01", "loss": 0.29777, "lr": 0.00010, "mode": "train"}
[12/09 00:31:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 1.29477, "dt_data": 0.75865, "dt_net": 0.53612, "eta": "0:00:01", "loss": 0.28129, "lr": 0.00010, "mode": "train"}
[12/09 00:31:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "50", "cur_iter": "1", "dt": 0.82301, "dt_data": 0.74903, "dt_net": 0.07398, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:39][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:39][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003266 seconds.
[12/09 00:31:39][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "50", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:31:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "51", "cur_iter": "1", "dt": 1.29334, "dt_data": 0.75736, "dt_net": 0.53598, "eta": "0:00:01", "loss": 0.29109, "lr": 0.00010, "mode": "train"}
[12/09 00:31:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "52", "cur_iter": "1", "dt": 1.29442, "dt_data": 0.75797, "dt_net": 0.53644, "eta": "0:00:01", "loss": 0.31557, "lr": 0.00010, "mode": "train"}
[12/09 00:31:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "53", "cur_iter": "1", "dt": 1.29529, "dt_data": 0.75910, "dt_net": 0.53618, "eta": "0:00:01", "loss": 0.27458, "lr": 0.00010, "mode": "train"}
[12/09 00:31:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "54", "cur_iter": "1", "dt": 1.28994, "dt_data": 0.75354, "dt_net": 0.53640, "eta": "0:00:01", "loss": 0.29120, "lr": 0.00010, "mode": "train"}
[12/09 00:31:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 1.29314, "dt_data": 0.75739, "dt_net": 0.53575, "eta": "0:00:01", "loss": 0.28304, "lr": 0.00010, "mode": "train"}
[12/09 00:31:46][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "55", "cur_iter": "1", "dt": 0.82402, "dt_data": 0.74996, "dt_net": 0.07406, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:46][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:46][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:46][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:46][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:46][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:46][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:46][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:46][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003110 seconds.
[12/09 00:31:46][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "55", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:31:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "56", "cur_iter": "1", "dt": 1.29312, "dt_data": 0.75672, "dt_net": 0.53640, "eta": "0:00:01", "loss": 0.30117, "lr": 0.00010, "mode": "train"}
[12/09 00:31:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "57", "cur_iter": "1", "dt": 1.29132, "dt_data": 0.75400, "dt_net": 0.53732, "eta": "0:00:01", "loss": 0.27903, "lr": 0.00010, "mode": "train"}
[12/09 00:31:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "58", "cur_iter": "1", "dt": 1.29094, "dt_data": 0.75486, "dt_net": 0.53608, "eta": "0:00:01", "loss": 0.29077, "lr": 0.00010, "mode": "train"}
[12/09 00:31:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "59", "cur_iter": "1", "dt": 1.29257, "dt_data": 0.75546, "dt_net": 0.53711, "eta": "0:00:01", "loss": 0.28373, "lr": 0.00010, "mode": "train"}
[12/09 00:31:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 1.29560, "dt_data": 0.75954, "dt_net": 0.53606, "eta": "0:00:01", "loss": 0.29521, "lr": 0.00010, "mode": "train"}
[12/09 00:31:55][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "60", "cur_iter": "1", "dt": 0.84865, "dt_data": 0.77492, "dt_net": 0.07372, "eta": "0:00:00", "mode": "val"}
[12/09 00:31:55][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:31:55][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:31:55][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:31:55][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:55][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:31:55][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:31:55][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:31:55][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003104 seconds.
[12/09 00:31:55][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "60", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:31:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "61", "cur_iter": "1", "dt": 1.29482, "dt_data": 0.75867, "dt_net": 0.53616, "eta": "0:00:01", "loss": 0.29823, "lr": 0.00010, "mode": "train"}
[12/09 00:31:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "62", "cur_iter": "1", "dt": 1.29151, "dt_data": 0.75507, "dt_net": 0.53645, "eta": "0:00:01", "loss": 0.31722, "lr": 0.00010, "mode": "train"}
[12/09 00:31:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "63", "cur_iter": "1", "dt": 1.29387, "dt_data": 0.75628, "dt_net": 0.53759, "eta": "0:00:01", "loss": 0.29400, "lr": 0.00010, "mode": "train"}
[12/09 00:32:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "64", "cur_iter": "1", "dt": 1.29526, "dt_data": 0.75706, "dt_net": 0.53819, "eta": "0:00:01", "loss": 0.31987, "lr": 0.00010, "mode": "train"}
[12/09 00:32:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 1.29505, "dt_data": 0.75699, "dt_net": 0.53806, "eta": "0:00:01", "loss": 0.31340, "lr": 0.00010, "mode": "train"}
[12/09 00:32:02][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "65", "cur_iter": "1", "dt": 0.82233, "dt_data": 0.74801, "dt_net": 0.07432, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:02][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:02][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:02][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:02][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:02][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:02][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:02][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:02][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003160 seconds.
[12/09 00:32:02][INFO] logging.py:  96: json_stats: {"RAM": "2.45/15.59G", "_type": "val_epoch", "cur_epoch": "65", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "66", "cur_iter": "1", "dt": 1.29331, "dt_data": 0.75465, "dt_net": 0.53866, "eta": "0:00:01", "loss": 0.28380, "lr": 0.00010, "mode": "train"}
[12/09 00:32:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "67", "cur_iter": "1", "dt": 1.29325, "dt_data": 0.75482, "dt_net": 0.53843, "eta": "0:00:01", "loss": 0.27578, "lr": 0.00010, "mode": "train"}
[12/09 00:32:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "68", "cur_iter": "1", "dt": 1.29557, "dt_data": 0.75721, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.28924, "lr": 0.00010, "mode": "train"}
[12/09 00:32:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "69", "cur_iter": "1", "dt": 1.29665, "dt_data": 0.75803, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.29134, "lr": 0.00010, "mode": "train"}
[12/09 00:32:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 1.29829, "dt_data": 0.76008, "dt_net": 0.53821, "eta": "0:00:01", "loss": 0.29275, "lr": 0.00010, "mode": "train"}
[12/09 00:32:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "70", "cur_iter": "1", "dt": 0.82417, "dt_data": 0.74993, "dt_net": 0.07424, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:10][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:10][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003149 seconds.
[12/09 00:32:10][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "70", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "71", "cur_iter": "1", "dt": 1.29572, "dt_data": 0.75749, "dt_net": 0.53822, "eta": "0:00:01", "loss": 0.30448, "lr": 0.00010, "mode": "train"}
[12/09 00:32:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "72", "cur_iter": "1", "dt": 1.29654, "dt_data": 0.75767, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27853, "lr": 0.00010, "mode": "train"}
[12/09 00:32:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "73", "cur_iter": "1", "dt": 1.29413, "dt_data": 0.75608, "dt_net": 0.53805, "eta": "0:00:01", "loss": 0.29915, "lr": 0.00010, "mode": "train"}
[12/09 00:32:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "74", "cur_iter": "1", "dt": 1.29265, "dt_data": 0.75408, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.28709, "lr": 0.00010, "mode": "train"}
[12/09 00:32:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 1.29576, "dt_data": 0.75728, "dt_net": 0.53847, "eta": "0:00:01", "loss": 0.28097, "lr": 0.00010, "mode": "train"}
[12/09 00:32:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "75", "cur_iter": "1", "dt": 0.82339, "dt_data": 0.74930, "dt_net": 0.07409, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:18][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:18][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003326 seconds.
[12/09 00:32:18][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "75", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "76", "cur_iter": "1", "dt": 1.29630, "dt_data": 0.75794, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.30855, "lr": 0.00010, "mode": "train"}
[12/09 00:32:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "77", "cur_iter": "1", "dt": 1.29546, "dt_data": 0.75717, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.27868, "lr": 0.00010, "mode": "train"}
[12/09 00:32:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "78", "cur_iter": "1", "dt": 1.29393, "dt_data": 0.75578, "dt_net": 0.53815, "eta": "0:00:01", "loss": 0.30144, "lr": 0.00010, "mode": "train"}
[12/09 00:32:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "79", "cur_iter": "1", "dt": 1.29571, "dt_data": 0.75746, "dt_net": 0.53824, "eta": "0:00:01", "loss": 0.28282, "lr": 0.00010, "mode": "train"}
[12/09 00:32:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 1.29821, "dt_data": 0.76026, "dt_net": 0.53795, "eta": "0:00:01", "loss": 0.27593, "lr": 0.00010, "mode": "train"}
[12/09 00:32:26][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "80", "cur_iter": "1", "dt": 0.84738, "dt_data": 0.77340, "dt_net": 0.07397, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:26][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:26][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:26][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:26][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:26][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:26][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003179 seconds.
[12/09 00:32:26][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "80", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "81", "cur_iter": "1", "dt": 1.29740, "dt_data": 0.75964, "dt_net": 0.53776, "eta": "0:00:01", "loss": 0.28288, "lr": 0.00010, "mode": "train"}
[12/09 00:32:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "82", "cur_iter": "1", "dt": 1.29406, "dt_data": 0.75537, "dt_net": 0.53870, "eta": "0:00:01", "loss": 0.28021, "lr": 0.00010, "mode": "train"}
[12/09 00:32:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "83", "cur_iter": "1", "dt": 1.29538, "dt_data": 0.75763, "dt_net": 0.53775, "eta": "0:00:01", "loss": 0.28088, "lr": 0.00010, "mode": "train"}
[12/09 00:32:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "84", "cur_iter": "1", "dt": 1.29318, "dt_data": 0.75484, "dt_net": 0.53834, "eta": "0:00:01", "loss": 0.28309, "lr": 0.00010, "mode": "train"}
[12/09 00:32:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 1.29531, "dt_data": 0.75671, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.27406, "lr": 0.00010, "mode": "train"}
[12/09 00:32:34][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "85", "cur_iter": "1", "dt": 0.82408, "dt_data": 0.74980, "dt_net": 0.07428, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:34][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:34][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:34][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:34][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:34][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:34][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003197 seconds.
[12/09 00:32:34][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "85", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "86", "cur_iter": "1", "dt": 1.29753, "dt_data": 0.75975, "dt_net": 0.53778, "eta": "0:00:01", "loss": 0.26963, "lr": 0.00010, "mode": "train"}
[12/09 00:32:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "87", "cur_iter": "1", "dt": 1.29745, "dt_data": 0.75905, "dt_net": 0.53840, "eta": "0:00:01", "loss": 0.27697, "lr": 0.00010, "mode": "train"}
[12/09 00:32:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "88", "cur_iter": "1", "dt": 1.29920, "dt_data": 0.76082, "dt_net": 0.53838, "eta": "0:00:01", "loss": 0.27709, "lr": 0.00010, "mode": "train"}
[12/09 00:32:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "89", "cur_iter": "1", "dt": 1.29857, "dt_data": 0.75923, "dt_net": 0.53934, "eta": "0:00:01", "loss": 0.28086, "lr": 0.00010, "mode": "train"}
[12/09 00:32:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 1.29610, "dt_data": 0.75659, "dt_net": 0.53951, "eta": "0:00:01", "loss": 0.30511, "lr": 0.00010, "mode": "train"}
[12/09 00:32:41][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "90", "cur_iter": "1", "dt": 0.82505, "dt_data": 0.75068, "dt_net": 0.07436, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:41][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:41][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:41][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:41][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:41][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:41][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:41][INFO] ava_eval_helper.py: 169: AVA eval done in 0.004566 seconds.
[12/09 00:32:41][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "90", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "91", "cur_iter": "1", "dt": 1.29973, "dt_data": 0.75992, "dt_net": 0.53981, "eta": "0:00:01", "loss": 0.28253, "lr": 0.00010, "mode": "train"}
[12/09 00:32:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "92", "cur_iter": "1", "dt": 1.29986, "dt_data": 0.76006, "dt_net": 0.53980, "eta": "0:00:01", "loss": 0.28843, "lr": 0.00010, "mode": "train"}
[12/09 00:32:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "93", "cur_iter": "1", "dt": 1.29590, "dt_data": 0.75663, "dt_net": 0.53927, "eta": "0:00:01", "loss": 0.27891, "lr": 0.00010, "mode": "train"}
[12/09 00:32:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "94", "cur_iter": "1", "dt": 1.29945, "dt_data": 0.75937, "dt_net": 0.54008, "eta": "0:00:01", "loss": 0.27789, "lr": 0.00010, "mode": "train"}
[12/09 00:32:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 1.30141, "dt_data": 0.76186, "dt_net": 0.53955, "eta": "0:00:01", "loss": 0.28398, "lr": 0.00010, "mode": "train"}
[12/09 00:32:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "95", "cur_iter": "1", "dt": 0.82476, "dt_data": 0.75035, "dt_net": 0.07441, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:49][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:49][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003277 seconds.
[12/09 00:32:49][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "95", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "96", "cur_iter": "1", "dt": 1.29794, "dt_data": 0.75833, "dt_net": 0.53961, "eta": "0:00:01", "loss": 0.28045, "lr": 0.00010, "mode": "train"}
[12/09 00:32:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "97", "cur_iter": "1", "dt": 1.29532, "dt_data": 0.75469, "dt_net": 0.54063, "eta": "0:00:01", "loss": 0.28602, "lr": 0.00010, "mode": "train"}
[12/09 00:32:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "98", "cur_iter": "1", "dt": 1.30210, "dt_data": 0.76200, "dt_net": 0.54011, "eta": "0:00:01", "loss": 0.28420, "lr": 0.00010, "mode": "train"}
[12/09 00:32:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "99", "cur_iter": "1", "dt": 1.29866, "dt_data": 0.75860, "dt_net": 0.54006, "eta": "0:00:01", "loss": 0.29070, "lr": 0.00010, "mode": "train"}
[12/09 00:32:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 1.30085, "dt_data": 0.76086, "dt_net": 0.53999, "eta": "0:00:01", "loss": 0.28145, "lr": 0.00010, "mode": "train"}
[12/09 00:32:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "100", "cur_iter": "1", "dt": 0.84836, "dt_data": 0.77411, "dt_net": 0.07424, "eta": "0:00:00", "mode": "val"}
[12/09 00:32:58][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:32:58][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:32:58][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:32:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:58][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:32:58][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:32:58][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:32:58][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002969 seconds.
[12/09 00:32:58][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "100", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:32:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "101", "cur_iter": "1", "dt": 1.29991, "dt_data": 0.75966, "dt_net": 0.54025, "eta": "0:00:01", "loss": 0.28054, "lr": 0.00010, "mode": "train"}
[12/09 00:33:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "102", "cur_iter": "1", "dt": 1.29594, "dt_data": 0.75611, "dt_net": 0.53983, "eta": "0:00:01", "loss": 0.27136, "lr": 0.00010, "mode": "train"}
[12/09 00:33:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "103", "cur_iter": "1", "dt": 1.29658, "dt_data": 0.75660, "dt_net": 0.53997, "eta": "0:00:01", "loss": 0.28324, "lr": 0.00010, "mode": "train"}
[12/09 00:33:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "104", "cur_iter": "1", "dt": 1.29829, "dt_data": 0.75782, "dt_net": 0.54047, "eta": "0:00:01", "loss": 0.27952, "lr": 0.00010, "mode": "train"}
[12/09 00:33:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 1.29544, "dt_data": 0.75570, "dt_net": 0.53974, "eta": "0:00:01", "loss": 0.28567, "lr": 0.00010, "mode": "train"}
[12/09 00:33:05][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "105", "cur_iter": "1", "dt": 0.82207, "dt_data": 0.74776, "dt_net": 0.07431, "eta": "0:00:00", "mode": "val"}
[12/09 00:33:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:33:05][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:33:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:33:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:33:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:05][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:33:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003282 seconds.
[12/09 00:33:05][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "105", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:33:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "106", "cur_iter": "1", "dt": 1.29749, "dt_data": 0.75908, "dt_net": 0.53841, "eta": "0:00:01", "loss": 0.27641, "lr": 0.00010, "mode": "train"}
[12/09 00:33:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "107", "cur_iter": "1", "dt": 1.29621, "dt_data": 0.75741, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.29121, "lr": 0.00010, "mode": "train"}
[12/09 00:33:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "108", "cur_iter": "1", "dt": 1.29558, "dt_data": 0.75775, "dt_net": 0.53783, "eta": "0:00:01", "loss": 0.27736, "lr": 0.00010, "mode": "train"}
[12/09 00:33:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "109", "cur_iter": "1", "dt": 1.29604, "dt_data": 0.75725, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.26934, "lr": 0.00010, "mode": "train"}
[12/09 00:33:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 1.29775, "dt_data": 0.75938, "dt_net": 0.53836, "eta": "0:00:01", "loss": 0.27605, "lr": 0.00010, "mode": "train"}
[12/09 00:33:13][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "110", "cur_iter": "1", "dt": 0.82352, "dt_data": 0.74931, "dt_net": 0.07421, "eta": "0:00:00", "mode": "val"}
[12/09 00:33:13][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:33:13][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:33:13][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:33:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:13][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:33:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:13][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:33:13][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003166 seconds.
[12/09 00:33:13][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "110", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:33:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "111", "cur_iter": "1", "dt": 1.29513, "dt_data": 0.75726, "dt_net": 0.53787, "eta": "0:00:01", "loss": 0.27791, "lr": 0.00010, "mode": "train"}
[12/09 00:33:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "112", "cur_iter": "1", "dt": 1.29743, "dt_data": 0.75861, "dt_net": 0.53881, "eta": "0:00:01", "loss": 0.27570, "lr": 0.00010, "mode": "train"}
[12/09 00:33:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "113", "cur_iter": "1", "dt": 1.29730, "dt_data": 0.75877, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.28388, "lr": 0.00010, "mode": "train"}
[12/09 00:33:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "114", "cur_iter": "1", "dt": 1.29293, "dt_data": 0.75431, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.27572, "lr": 0.00010, "mode": "train"}
[12/09 00:33:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 1.29636, "dt_data": 0.75828, "dt_net": 0.53808, "eta": "0:00:01", "loss": 0.27983, "lr": 0.00010, "mode": "train"}
[12/09 00:33:20][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "115", "cur_iter": "1", "dt": 0.82438, "dt_data": 0.75017, "dt_net": 0.07421, "eta": "0:00:00", "mode": "val"}
[12/09 00:33:20][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:33:20][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:33:20][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:33:20][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:20][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:33:20][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:20][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:33:20][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003278 seconds.
[12/09 00:33:20][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "115", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:33:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "116", "cur_iter": "1", "dt": 1.29629, "dt_data": 0.75794, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.33439, "lr": 0.00010, "mode": "train"}
[12/09 00:33:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "117", "cur_iter": "1", "dt": 1.29301, "dt_data": 0.75456, "dt_net": 0.53844, "eta": "0:00:01", "loss": 0.28418, "lr": 0.00010, "mode": "train"}
[12/09 00:33:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "118", "cur_iter": "1", "dt": 1.29409, "dt_data": 0.75610, "dt_net": 0.53798, "eta": "0:00:01", "loss": 0.27530, "lr": 0.00010, "mode": "train"}
[12/09 00:33:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "119", "cur_iter": "1", "dt": 1.29368, "dt_data": 0.75459, "dt_net": 0.53909, "eta": "0:00:01", "loss": 0.28639, "lr": 0.00010, "mode": "train"}
[12/09 00:33:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 1.29390, "dt_data": 0.75619, "dt_net": 0.53771, "eta": "0:00:01", "loss": 0.28488, "lr": 0.00010, "mode": "train"}
[12/09 00:33:29][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "120", "cur_iter": "1", "dt": 0.84974, "dt_data": 0.77574, "dt_net": 0.07400, "eta": "0:00:00", "mode": "val"}
[12/09 00:33:29][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:33:29][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:33:29][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:33:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:29][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:33:29][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:29][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:33:29][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003297 seconds.
[12/09 00:33:29][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "120", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:33:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "121", "cur_iter": "1", "dt": 1.29765, "dt_data": 0.75977, "dt_net": 0.53788, "eta": "0:00:01", "loss": 0.27719, "lr": 0.00010, "mode": "train"}
[12/09 00:33:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "122", "cur_iter": "1", "dt": 1.29430, "dt_data": 0.75556, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.28123, "lr": 0.00010, "mode": "train"}
[12/09 00:33:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "123", "cur_iter": "1", "dt": 1.29823, "dt_data": 0.75981, "dt_net": 0.53842, "eta": "0:00:01", "loss": 0.26900, "lr": 0.00010, "mode": "train"}
[12/09 00:33:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "124", "cur_iter": "1", "dt": 1.29359, "dt_data": 0.75498, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.27855, "lr": 0.00010, "mode": "train"}
[12/09 00:33:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 1.29602, "dt_data": 0.75729, "dt_net": 0.53873, "eta": "0:00:01", "loss": 0.27720, "lr": 0.00010, "mode": "train"}
[12/09 00:33:36][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "125", "cur_iter": "1", "dt": 0.82339, "dt_data": 0.74911, "dt_net": 0.07427, "eta": "0:00:00", "mode": "val"}
[12/09 00:33:36][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:33:36][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:33:36][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:33:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:36][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:33:36][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:36][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:33:36][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003224 seconds.
[12/09 00:33:36][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "125", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:33:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "126", "cur_iter": "1", "dt": 1.29677, "dt_data": 0.75837, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.28073, "lr": 0.00010, "mode": "train"}
[12/09 00:33:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "127", "cur_iter": "1", "dt": 1.29629, "dt_data": 0.75806, "dt_net": 0.53823, "eta": "0:00:01", "loss": 0.28094, "lr": 0.00010, "mode": "train"}
[12/09 00:33:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "128", "cur_iter": "1", "dt": 1.29604, "dt_data": 0.75838, "dt_net": 0.53765, "eta": "0:00:01", "loss": 0.28122, "lr": 0.00010, "mode": "train"}
[12/09 00:33:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "129", "cur_iter": "1", "dt": 1.29493, "dt_data": 0.75577, "dt_net": 0.53915, "eta": "0:00:01", "loss": 0.28443, "lr": 0.00010, "mode": "train"}
[12/09 00:33:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 1.29950, "dt_data": 0.76126, "dt_net": 0.53823, "eta": "0:00:01", "loss": 0.27524, "lr": 0.00010, "mode": "train"}
[12/09 00:33:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "130", "cur_iter": "1", "dt": 0.82567, "dt_data": 0.75132, "dt_net": 0.07434, "eta": "0:00:00", "mode": "val"}
[12/09 00:33:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:33:44][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:33:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:33:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:33:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:44][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:33:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003253 seconds.
[12/09 00:33:44][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "130", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:33:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "131", "cur_iter": "1", "dt": 1.29710, "dt_data": 0.75930, "dt_net": 0.53780, "eta": "0:00:01", "loss": 0.27543, "lr": 0.00010, "mode": "train"}
[12/09 00:33:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "132", "cur_iter": "1", "dt": 1.29378, "dt_data": 0.75504, "dt_net": 0.53874, "eta": "0:00:01", "loss": 0.27440, "lr": 0.00010, "mode": "train"}
[12/09 00:33:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "133", "cur_iter": "1", "dt": 1.30035, "dt_data": 0.76237, "dt_net": 0.53797, "eta": "0:00:01", "loss": 0.27647, "lr": 0.00010, "mode": "train"}
[12/09 00:33:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "134", "cur_iter": "1", "dt": 1.29371, "dt_data": 0.75505, "dt_net": 0.53866, "eta": "0:00:01", "loss": 0.29316, "lr": 0.00010, "mode": "train"}
[12/09 00:33:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 1.29650, "dt_data": 0.75809, "dt_net": 0.53840, "eta": "0:00:01", "loss": 0.27450, "lr": 0.00010, "mode": "train"}
[12/09 00:33:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "135", "cur_iter": "1", "dt": 0.82473, "dt_data": 0.75055, "dt_net": 0.07418, "eta": "0:00:00", "mode": "val"}
[12/09 00:33:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:33:52][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:33:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:33:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:33:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:33:52][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:33:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002996 seconds.
[12/09 00:33:52][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "135", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:33:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "136", "cur_iter": "1", "dt": 1.29700, "dt_data": 0.75899, "dt_net": 0.53801, "eta": "0:00:01", "loss": 0.27465, "lr": 0.00010, "mode": "train"}
[12/09 00:33:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "137", "cur_iter": "1", "dt": 1.29685, "dt_data": 0.75834, "dt_net": 0.53850, "eta": "0:00:01", "loss": 0.27453, "lr": 0.00010, "mode": "train"}
[12/09 00:33:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "138", "cur_iter": "1", "dt": 1.29486, "dt_data": 0.75651, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.27886, "lr": 0.00010, "mode": "train"}
[12/09 00:33:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "139", "cur_iter": "1", "dt": 1.29640, "dt_data": 0.75815, "dt_net": 0.53825, "eta": "0:00:01", "loss": 0.28806, "lr": 0.00010, "mode": "train"}
[12/09 00:33:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 1.29947, "dt_data": 0.76144, "dt_net": 0.53803, "eta": "0:00:01", "loss": 0.27871, "lr": 0.00010, "mode": "train"}
[12/09 00:34:00][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "140", "cur_iter": "1", "dt": 0.84064, "dt_data": 0.76668, "dt_net": 0.07395, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:00][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:00][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:00][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:00][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:00][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:00][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:00][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002979 seconds.
[12/09 00:34:00][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "140", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "141", "cur_iter": "1", "dt": 1.29770, "dt_data": 0.75951, "dt_net": 0.53819, "eta": "0:00:01", "loss": 0.28065, "lr": 0.00010, "mode": "train"}
[12/09 00:34:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "142", "cur_iter": "1", "dt": 1.29247, "dt_data": 0.75362, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.28030, "lr": 0.00010, "mode": "train"}
[12/09 00:34:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "143", "cur_iter": "1", "dt": 1.29835, "dt_data": 0.76018, "dt_net": 0.53816, "eta": "0:00:01", "loss": 0.28132, "lr": 0.00010, "mode": "train"}
[12/09 00:34:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "144", "cur_iter": "1", "dt": 1.29413, "dt_data": 0.75549, "dt_net": 0.53864, "eta": "0:00:01", "loss": 0.28281, "lr": 0.00010, "mode": "train"}
[12/09 00:34:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 1.29900, "dt_data": 0.76046, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.27222, "lr": 0.00010, "mode": "train"}
[12/09 00:34:08][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "145", "cur_iter": "1", "dt": 0.82514, "dt_data": 0.75087, "dt_net": 0.07427, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:08][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:08][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:08][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:08][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:08][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:08][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003146 seconds.
[12/09 00:34:08][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "145", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "146", "cur_iter": "1", "dt": 1.29499, "dt_data": 0.75744, "dt_net": 0.53755, "eta": "0:00:01", "loss": 0.29408, "lr": 0.00010, "mode": "train"}
[12/09 00:34:10][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "147", "cur_iter": "1", "dt": 1.29612, "dt_data": 0.75736, "dt_net": 0.53876, "eta": "0:00:01", "loss": 0.28358, "lr": 0.00010, "mode": "train"}
[12/09 00:34:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "148", "cur_iter": "1", "dt": 1.29583, "dt_data": 0.75767, "dt_net": 0.53816, "eta": "0:00:01", "loss": 0.27905, "lr": 0.00010, "mode": "train"}
[12/09 00:34:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "149", "cur_iter": "1", "dt": 1.29734, "dt_data": 0.75854, "dt_net": 0.53879, "eta": "0:00:01", "loss": 0.26758, "lr": 0.00010, "mode": "train"}
[12/09 00:34:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 1.29547, "dt_data": 0.75750, "dt_net": 0.53797, "eta": "0:00:01", "loss": 0.28636, "lr": 0.00010, "mode": "train"}
[12/09 00:34:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "150", "cur_iter": "1", "dt": 0.82597, "dt_data": 0.75166, "dt_net": 0.07431, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:15][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:15][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:15][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:15][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:15][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:15][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:15][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003182 seconds.
[12/09 00:34:15][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "150", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "151", "cur_iter": "1", "dt": 1.29608, "dt_data": 0.75799, "dt_net": 0.53808, "eta": "0:00:01", "loss": 0.29583, "lr": 0.00010, "mode": "train"}
[12/09 00:34:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "152", "cur_iter": "1", "dt": 1.29470, "dt_data": 0.75562, "dt_net": 0.53909, "eta": "0:00:01", "loss": 0.28099, "lr": 0.00010, "mode": "train"}
[12/09 00:34:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "153", "cur_iter": "1", "dt": 1.29419, "dt_data": 0.75598, "dt_net": 0.53821, "eta": "0:00:01", "loss": 0.28787, "lr": 0.00010, "mode": "train"}
[12/09 00:34:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "154", "cur_iter": "1", "dt": 1.29345, "dt_data": 0.75461, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.27351, "lr": 0.00010, "mode": "train"}
[12/09 00:34:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 1.29596, "dt_data": 0.75777, "dt_net": 0.53818, "eta": "0:00:01", "loss": 0.27367, "lr": 0.00010, "mode": "train"}
[12/09 00:34:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "155", "cur_iter": "1", "dt": 0.82296, "dt_data": 0.74872, "dt_net": 0.07423, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:23][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:23][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003349 seconds.
[12/09 00:34:23][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "155", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "156", "cur_iter": "1", "dt": 1.29534, "dt_data": 0.75736, "dt_net": 0.53798, "eta": "0:00:01", "loss": 0.27532, "lr": 0.00010, "mode": "train"}
[12/09 00:34:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "157", "cur_iter": "1", "dt": 1.29885, "dt_data": 0.75995, "dt_net": 0.53890, "eta": "0:00:01", "loss": 0.29548, "lr": 0.00010, "mode": "train"}
[12/09 00:34:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "158", "cur_iter": "1", "dt": 1.29403, "dt_data": 0.75564, "dt_net": 0.53839, "eta": "0:00:01", "loss": 0.28620, "lr": 0.00010, "mode": "train"}
[12/09 00:34:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "159", "cur_iter": "1", "dt": 1.29267, "dt_data": 0.75406, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.27356, "lr": 0.00010, "mode": "train"}
[12/09 00:34:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 1.29627, "dt_data": 0.75778, "dt_net": 0.53849, "eta": "0:00:01", "loss": 0.27136, "lr": 0.00010, "mode": "train"}
[12/09 00:34:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "160", "cur_iter": "1", "dt": 0.84941, "dt_data": 0.77552, "dt_net": 0.07388, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:31][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:31][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003163 seconds.
[12/09 00:34:31][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "160", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "161", "cur_iter": "1", "dt": 1.29711, "dt_data": 0.75857, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.29107, "lr": 0.00010, "mode": "train"}
[12/09 00:34:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "162", "cur_iter": "1", "dt": 1.29412, "dt_data": 0.75507, "dt_net": 0.53905, "eta": "0:00:01", "loss": 0.27352, "lr": 0.00010, "mode": "train"}
[12/09 00:34:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "163", "cur_iter": "1", "dt": 1.29467, "dt_data": 0.75658, "dt_net": 0.53809, "eta": "0:00:01", "loss": 0.28134, "lr": 0.00010, "mode": "train"}
[12/09 00:34:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "164", "cur_iter": "1", "dt": 1.29607, "dt_data": 0.75714, "dt_net": 0.53892, "eta": "0:00:01", "loss": 0.28253, "lr": 0.00010, "mode": "train"}
[12/09 00:34:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 1.29733, "dt_data": 0.75903, "dt_net": 0.53830, "eta": "0:00:01", "loss": 0.28352, "lr": 0.00010, "mode": "train"}
[12/09 00:34:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "165", "cur_iter": "1", "dt": 0.82401, "dt_data": 0.74985, "dt_net": 0.07417, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:39][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:39][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003031 seconds.
[12/09 00:34:39][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "165", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "166", "cur_iter": "1", "dt": 1.29588, "dt_data": 0.75788, "dt_net": 0.53800, "eta": "0:00:01", "loss": 0.27005, "lr": 0.00010, "mode": "train"}
[12/09 00:34:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "167", "cur_iter": "1", "dt": 1.29647, "dt_data": 0.75756, "dt_net": 0.53891, "eta": "0:00:01", "loss": 0.27565, "lr": 0.00010, "mode": "train"}
[12/09 00:34:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "168", "cur_iter": "1", "dt": 1.29907, "dt_data": 0.76054, "dt_net": 0.53853, "eta": "0:00:01", "loss": 0.27852, "lr": 0.00010, "mode": "train"}
[12/09 00:34:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "169", "cur_iter": "1", "dt": 1.29740, "dt_data": 0.75915, "dt_net": 0.53825, "eta": "0:00:01", "loss": 0.29066, "lr": 0.00010, "mode": "train"}
[12/09 00:34:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 1.29492, "dt_data": 0.75621, "dt_net": 0.53871, "eta": "0:00:01", "loss": 0.27244, "lr": 0.00010, "mode": "train"}
[12/09 00:34:47][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "170", "cur_iter": "1", "dt": 0.82211, "dt_data": 0.74789, "dt_net": 0.07421, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:47][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:47][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:47][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:47][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:47][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:47][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003340 seconds.
[12/09 00:34:47][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "170", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "171", "cur_iter": "1", "dt": 1.29634, "dt_data": 0.75814, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.27856, "lr": 0.00010, "mode": "train"}
[12/09 00:34:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "172", "cur_iter": "1", "dt": 1.29208, "dt_data": 0.75363, "dt_net": 0.53845, "eta": "0:00:01", "loss": 0.27724, "lr": 0.00010, "mode": "train"}
[12/09 00:34:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "173", "cur_iter": "1", "dt": 1.29817, "dt_data": 0.75957, "dt_net": 0.53860, "eta": "0:00:01", "loss": 0.27739, "lr": 0.00010, "mode": "train"}
[12/09 00:34:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "174", "cur_iter": "1", "dt": 1.29729, "dt_data": 0.75754, "dt_net": 0.53974, "eta": "0:00:01", "loss": 0.26741, "lr": 0.00010, "mode": "train"}
[12/09 00:34:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 1.29994, "dt_data": 0.76023, "dt_net": 0.53970, "eta": "0:00:01", "loss": 0.29317, "lr": 0.00010, "mode": "train"}
[12/09 00:34:54][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "175", "cur_iter": "1", "dt": 0.82487, "dt_data": 0.75040, "dt_net": 0.07447, "eta": "0:00:00", "mode": "val"}
[12/09 00:34:54][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:34:54][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:34:54][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:34:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:54][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:34:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:34:54][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:34:54][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003133 seconds.
[12/09 00:34:54][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "175", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:34:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "176", "cur_iter": "1", "dt": 1.29673, "dt_data": 0.75700, "dt_net": 0.53973, "eta": "0:00:01", "loss": 0.27113, "lr": 0.00010, "mode": "train"}
[12/09 00:34:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "177", "cur_iter": "1", "dt": 1.29428, "dt_data": 0.75386, "dt_net": 0.54042, "eta": "0:00:01", "loss": 0.28250, "lr": 0.00010, "mode": "train"}
[12/09 00:34:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "178", "cur_iter": "1", "dt": 1.29552, "dt_data": 0.75565, "dt_net": 0.53987, "eta": "0:00:01", "loss": 0.26974, "lr": 0.00010, "mode": "train"}
[12/09 00:35:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "179", "cur_iter": "1", "dt": 1.29895, "dt_data": 0.75827, "dt_net": 0.54068, "eta": "0:00:01", "loss": 0.28646, "lr": 0.00010, "mode": "train"}
[12/09 00:35:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 1.29546, "dt_data": 0.75534, "dt_net": 0.54012, "eta": "0:00:01", "loss": 0.27139, "lr": 0.00010, "mode": "train"}
[12/09 00:35:03][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "180", "cur_iter": "1", "dt": 0.85025, "dt_data": 0.77600, "dt_net": 0.07424, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:03][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:03][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:03][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:03][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:03][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:03][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:03][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:03][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003178 seconds.
[12/09 00:35:03][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "180", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "181", "cur_iter": "1", "dt": 1.29885, "dt_data": 0.75959, "dt_net": 0.53926, "eta": "0:00:01", "loss": 0.27933, "lr": 0.00010, "mode": "train"}
[12/09 00:35:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "182", "cur_iter": "1", "dt": 1.29303, "dt_data": 0.75473, "dt_net": 0.53830, "eta": "0:00:01", "loss": 0.27817, "lr": 0.00010, "mode": "train"}
[12/09 00:35:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "183", "cur_iter": "1", "dt": 1.29456, "dt_data": 0.75625, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.27770, "lr": 0.00010, "mode": "train"}
[12/09 00:35:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "184", "cur_iter": "1", "dt": 1.29264, "dt_data": 0.75379, "dt_net": 0.53885, "eta": "0:00:01", "loss": 0.27344, "lr": 0.00010, "mode": "train"}
[12/09 00:35:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 1.29419, "dt_data": 0.75646, "dt_net": 0.53772, "eta": "0:00:01", "loss": 0.27183, "lr": 0.00010, "mode": "train"}
[12/09 00:35:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "185", "cur_iter": "1", "dt": 0.82396, "dt_data": 0.74958, "dt_net": 0.07438, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:10][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:10][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.004692 seconds.
[12/09 00:35:10][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "185", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "186", "cur_iter": "1", "dt": 1.29671, "dt_data": 0.75810, "dt_net": 0.53861, "eta": "0:00:01", "loss": 0.28862, "lr": 0.00010, "mode": "train"}
[12/09 00:35:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "187", "cur_iter": "1", "dt": 1.29301, "dt_data": 0.75439, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.27453, "lr": 0.00010, "mode": "train"}
[12/09 00:35:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "188", "cur_iter": "1", "dt": 1.29564, "dt_data": 0.75718, "dt_net": 0.53846, "eta": "0:00:01", "loss": 0.28908, "lr": 0.00010, "mode": "train"}
[12/09 00:35:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "189", "cur_iter": "1", "dt": 1.29655, "dt_data": 0.75757, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.27157, "lr": 0.00010, "mode": "train"}
[12/09 00:35:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 1.29394, "dt_data": 0.75620, "dt_net": 0.53773, "eta": "0:00:01", "loss": 0.27209, "lr": 0.00010, "mode": "train"}
[12/09 00:35:18][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "190", "cur_iter": "1", "dt": 0.82412, "dt_data": 0.74984, "dt_net": 0.07427, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:18][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:18][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:18][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:18][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:18][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:18][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:18][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003233 seconds.
[12/09 00:35:18][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "190", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:19][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "191", "cur_iter": "1", "dt": 1.29484, "dt_data": 0.75669, "dt_net": 0.53815, "eta": "0:00:01", "loss": 0.27501, "lr": 0.00010, "mode": "train"}
[12/09 00:35:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "192", "cur_iter": "1", "dt": 1.29598, "dt_data": 0.75729, "dt_net": 0.53869, "eta": "0:00:01", "loss": 0.27103, "lr": 0.00010, "mode": "train"}
[12/09 00:35:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "193", "cur_iter": "1", "dt": 1.29548, "dt_data": 0.75726, "dt_net": 0.53821, "eta": "0:00:01", "loss": 0.30229, "lr": 0.00010, "mode": "train"}
[12/09 00:35:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "194", "cur_iter": "1", "dt": 1.29711, "dt_data": 0.75854, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.27431, "lr": 0.00010, "mode": "train"}
[12/09 00:35:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 1.29608, "dt_data": 0.75787, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.27037, "lr": 0.00010, "mode": "train"}
[12/09 00:35:26][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "195", "cur_iter": "1", "dt": 0.82435, "dt_data": 0.75005, "dt_net": 0.07430, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:26][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:26][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:26][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:26][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:26][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:26][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:26][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003204 seconds.
[12/09 00:35:26][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "195", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "196", "cur_iter": "1", "dt": 1.29687, "dt_data": 0.75847, "dt_net": 0.53840, "eta": "0:00:01", "loss": 0.26857, "lr": 0.00010, "mode": "train"}
[12/09 00:35:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "197", "cur_iter": "1", "dt": 1.29552, "dt_data": 0.75666, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27636, "lr": 0.00010, "mode": "train"}
[12/09 00:35:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "198", "cur_iter": "1", "dt": 1.29915, "dt_data": 0.76057, "dt_net": 0.53858, "eta": "0:00:01", "loss": 0.28109, "lr": 0.00010, "mode": "train"}
[12/09 00:35:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "199", "cur_iter": "1", "dt": 1.29745, "dt_data": 0.75841, "dt_net": 0.53904, "eta": "0:00:01", "loss": 0.27422, "lr": 0.00010, "mode": "train"}
[12/09 00:35:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 1.29371, "dt_data": 0.75575, "dt_net": 0.53795, "eta": "0:00:01", "loss": 0.28294, "lr": 0.00010, "mode": "train"}
[12/09 00:35:34][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "200", "cur_iter": "1", "dt": 0.85039, "dt_data": 0.77635, "dt_net": 0.07403, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:34][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:34][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:34][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:34][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:34][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:34][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:34][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003038 seconds.
[12/09 00:35:34][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "200", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "201", "cur_iter": "1", "dt": 1.29567, "dt_data": 0.75792, "dt_net": 0.53775, "eta": "0:00:01", "loss": 0.27190, "lr": 0.00010, "mode": "train"}
[12/09 00:35:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "202", "cur_iter": "1", "dt": 1.29176, "dt_data": 0.75288, "dt_net": 0.53887, "eta": "0:00:01", "loss": 0.27725, "lr": 0.00010, "mode": "train"}
[12/09 00:35:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "203", "cur_iter": "1", "dt": 1.29285, "dt_data": 0.75478, "dt_net": 0.53807, "eta": "0:00:01", "loss": 0.26764, "lr": 0.00010, "mode": "train"}
[12/09 00:35:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "204", "cur_iter": "1", "dt": 1.29648, "dt_data": 0.75838, "dt_net": 0.53810, "eta": "0:00:01", "loss": 0.26853, "lr": 0.00010, "mode": "train"}
[12/09 00:35:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 1.29524, "dt_data": 0.75697, "dt_net": 0.53826, "eta": "0:00:01", "loss": 0.28062, "lr": 0.00010, "mode": "train"}
[12/09 00:35:42][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "205", "cur_iter": "1", "dt": 0.82329, "dt_data": 0.74910, "dt_net": 0.07419, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:42][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:42][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:42][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:42][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:42][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:42][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:42][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003271 seconds.
[12/09 00:35:42][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "205", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "206", "cur_iter": "1", "dt": 1.29506, "dt_data": 0.75700, "dt_net": 0.53806, "eta": "0:00:01", "loss": 0.27273, "lr": 0.00010, "mode": "train"}
[12/09 00:35:44][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "207", "cur_iter": "1", "dt": 1.29679, "dt_data": 0.75832, "dt_net": 0.53847, "eta": "0:00:01", "loss": 0.27834, "lr": 0.00010, "mode": "train"}
[12/09 00:35:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "208", "cur_iter": "1", "dt": 1.29702, "dt_data": 0.75837, "dt_net": 0.53865, "eta": "0:00:01", "loss": 0.27782, "lr": 0.00010, "mode": "train"}
[12/09 00:35:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "209", "cur_iter": "1", "dt": 1.29179, "dt_data": 0.75348, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.26928, "lr": 0.00010, "mode": "train"}
[12/09 00:35:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 1.29754, "dt_data": 0.75971, "dt_net": 0.53783, "eta": "0:00:01", "loss": 0.27417, "lr": 0.00010, "mode": "train"}
[12/09 00:35:49][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "210", "cur_iter": "1", "dt": 0.82230, "dt_data": 0.74808, "dt_net": 0.07422, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:49][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:49][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:49][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:49][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:49][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:49][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:49][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003157 seconds.
[12/09 00:35:49][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "210", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "211", "cur_iter": "1", "dt": 1.29425, "dt_data": 0.75536, "dt_net": 0.53889, "eta": "0:00:01", "loss": 0.26898, "lr": 0.00010, "mode": "train"}
[12/09 00:35:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "212", "cur_iter": "1", "dt": 1.29589, "dt_data": 0.75705, "dt_net": 0.53884, "eta": "0:00:01", "loss": 0.28153, "lr": 0.00010, "mode": "train"}
[12/09 00:35:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "213", "cur_iter": "1", "dt": 1.29565, "dt_data": 0.75760, "dt_net": 0.53805, "eta": "0:00:01", "loss": 0.27783, "lr": 0.00010, "mode": "train"}
[12/09 00:35:55][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "214", "cur_iter": "1", "dt": 1.29701, "dt_data": 0.75800, "dt_net": 0.53900, "eta": "0:00:01", "loss": 0.28205, "lr": 0.00010, "mode": "train"}
[12/09 00:35:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 1.29447, "dt_data": 0.75637, "dt_net": 0.53810, "eta": "0:00:01", "loss": 0.27175, "lr": 0.00010, "mode": "train"}
[12/09 00:35:57][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "215", "cur_iter": "1", "dt": 0.82284, "dt_data": 0.74862, "dt_net": 0.07422, "eta": "0:00:00", "mode": "val"}
[12/09 00:35:57][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:35:57][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:35:57][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:35:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:57][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:35:57][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:35:57][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:35:57][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003085 seconds.
[12/09 00:35:57][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "215", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:35:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "216", "cur_iter": "1", "dt": 1.29388, "dt_data": 0.75597, "dt_net": 0.53791, "eta": "0:00:01", "loss": 0.27505, "lr": 0.00010, "mode": "train"}
[12/09 00:36:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "217", "cur_iter": "1", "dt": 1.29227, "dt_data": 0.75341, "dt_net": 0.53886, "eta": "0:00:01", "loss": 0.27122, "lr": 0.00010, "mode": "train"}
[12/09 00:36:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "218", "cur_iter": "1", "dt": 1.29312, "dt_data": 0.75483, "dt_net": 0.53830, "eta": "0:00:01", "loss": 0.27251, "lr": 0.00010, "mode": "train"}
[12/09 00:36:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "219", "cur_iter": "1", "dt": 1.29243, "dt_data": 0.75413, "dt_net": 0.53829, "eta": "0:00:01", "loss": 0.26972, "lr": 0.00010, "mode": "train"}
[12/09 00:36:04][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 1.29400, "dt_data": 0.75558, "dt_net": 0.53842, "eta": "0:00:01", "loss": 0.26858, "lr": 0.00010, "mode": "train"}
[12/09 00:36:05][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "220", "cur_iter": "1", "dt": 0.84632, "dt_data": 0.77231, "dt_net": 0.07400, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:05][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:05][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:05][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:05][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:05][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:05][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:05][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003290 seconds.
[12/09 00:36:05][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "220", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:36:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "221", "cur_iter": "1", "dt": 1.29682, "dt_data": 0.75823, "dt_net": 0.53859, "eta": "0:00:01", "loss": 0.28001, "lr": 0.00010, "mode": "train"}
[12/09 00:36:08][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "222", "cur_iter": "1", "dt": 1.29585, "dt_data": 0.75703, "dt_net": 0.53882, "eta": "0:00:01", "loss": 0.28258, "lr": 0.00010, "mode": "train"}
[12/09 00:36:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "223", "cur_iter": "1", "dt": 1.29373, "dt_data": 0.75524, "dt_net": 0.53848, "eta": "0:00:01", "loss": 0.27294, "lr": 0.00010, "mode": "train"}
[12/09 00:36:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "224", "cur_iter": "1", "dt": 1.29701, "dt_data": 0.75771, "dt_net": 0.53930, "eta": "0:00:01", "loss": 0.28117, "lr": 0.00010, "mode": "train"}
[12/09 00:36:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 1.29736, "dt_data": 0.75879, "dt_net": 0.53857, "eta": "0:00:01", "loss": 0.26952, "lr": 0.00010, "mode": "train"}
[12/09 00:36:13][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "225", "cur_iter": "1", "dt": 0.82143, "dt_data": 0.74716, "dt_net": 0.07427, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:13][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:13][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:13][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:13][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:13][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:13][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:13][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003088 seconds.
[12/09 00:36:13][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "225", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:36:14][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "226", "cur_iter": "1", "dt": 1.29663, "dt_data": 0.75850, "dt_net": 0.53813, "eta": "0:00:01", "loss": 0.27592, "lr": 0.00010, "mode": "train"}
[12/09 00:36:16][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "227", "cur_iter": "1", "dt": 1.29822, "dt_data": 0.75925, "dt_net": 0.53897, "eta": "0:00:01", "loss": 0.26953, "lr": 0.00010, "mode": "train"}
[12/09 00:36:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "228", "cur_iter": "1", "dt": 1.29506, "dt_data": 0.75675, "dt_net": 0.53831, "eta": "0:00:01", "loss": 0.27880, "lr": 0.00010, "mode": "train"}
[12/09 00:36:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "229", "cur_iter": "1", "dt": 1.29531, "dt_data": 0.75696, "dt_net": 0.53835, "eta": "0:00:01", "loss": 0.28029, "lr": 0.00010, "mode": "train"}
[12/09 00:36:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 1.29781, "dt_data": 0.75918, "dt_net": 0.53862, "eta": "0:00:01", "loss": 0.26831, "lr": 0.00010, "mode": "train"}
[12/09 00:36:21][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "230", "cur_iter": "1", "dt": 0.82400, "dt_data": 0.74946, "dt_net": 0.07453, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:21][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:21][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:21][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:21][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:21][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:21][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:21][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002967 seconds.
[12/09 00:36:21][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "230", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:36:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "231", "cur_iter": "1", "dt": 1.29329, "dt_data": 0.75485, "dt_net": 0.53844, "eta": "0:00:01", "loss": 0.26626, "lr": 0.00010, "mode": "train"}
[12/09 00:36:23][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "232", "cur_iter": "1", "dt": 1.29545, "dt_data": 0.75687, "dt_net": 0.53858, "eta": "0:00:01", "loss": 0.27020, "lr": 0.00010, "mode": "train"}
[12/09 00:36:25][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "233", "cur_iter": "1", "dt": 1.29852, "dt_data": 0.76001, "dt_net": 0.53851, "eta": "0:00:01", "loss": 0.27509, "lr": 0.00010, "mode": "train"}
[12/09 00:36:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "234", "cur_iter": "1", "dt": 1.29552, "dt_data": 0.75647, "dt_net": 0.53904, "eta": "0:00:01", "loss": 0.26878, "lr": 0.00010, "mode": "train"}
[12/09 00:36:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 1.29898, "dt_data": 0.76077, "dt_net": 0.53820, "eta": "0:00:01", "loss": 0.27430, "lr": 0.00010, "mode": "train"}
[12/09 00:36:28][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "235", "cur_iter": "1", "dt": 0.82372, "dt_data": 0.74942, "dt_net": 0.07430, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:28][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:28][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:28][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:28][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:28][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:28][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:28][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003015 seconds.
[12/09 00:36:28][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "235", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:36:29][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "236", "cur_iter": "1", "dt": 1.29515, "dt_data": 0.75714, "dt_net": 0.53802, "eta": "0:00:01", "loss": 0.26948, "lr": 0.00010, "mode": "train"}
[12/09 00:36:31][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "237", "cur_iter": "1", "dt": 1.29312, "dt_data": 0.75418, "dt_net": 0.53894, "eta": "0:00:01", "loss": 0.27070, "lr": 0.00010, "mode": "train"}
[12/09 00:36:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "238", "cur_iter": "1", "dt": 1.29720, "dt_data": 0.75911, "dt_net": 0.53809, "eta": "0:00:01", "loss": 0.27614, "lr": 0.00010, "mode": "train"}
[12/09 00:36:34][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "239", "cur_iter": "1", "dt": 1.29627, "dt_data": 0.75753, "dt_net": 0.53873, "eta": "0:00:01", "loss": 0.27013, "lr": 0.00010, "mode": "train"}
[12/09 00:36:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 1.29460, "dt_data": 0.75606, "dt_net": 0.53854, "eta": "0:00:01", "loss": 0.27686, "lr": 0.00010, "mode": "train"}
[12/09 00:36:37][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "240", "cur_iter": "1", "dt": 0.84918, "dt_data": 0.77459, "dt_net": 0.07459, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:37][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:37][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:37][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:37][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:37][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:37][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:37][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:37][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003160 seconds.
[12/09 00:36:37][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "240", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:36:38][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "241", "cur_iter": "1", "dt": 1.29674, "dt_data": 0.75692, "dt_net": 0.53981, "eta": "0:00:01", "loss": 0.27972, "lr": 0.00010, "mode": "train"}
[12/09 00:36:39][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "242", "cur_iter": "1", "dt": 1.29465, "dt_data": 0.75437, "dt_net": 0.54027, "eta": "0:00:01", "loss": 0.27310, "lr": 0.00010, "mode": "train"}
[12/09 00:36:41][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "243", "cur_iter": "1", "dt": 1.29723, "dt_data": 0.75679, "dt_net": 0.54043, "eta": "0:00:01", "loss": 0.26536, "lr": 0.00010, "mode": "train"}
[12/09 00:36:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "244", "cur_iter": "1", "dt": 1.29305, "dt_data": 0.75312, "dt_net": 0.53993, "eta": "0:00:01", "loss": 0.26596, "lr": 0.00010, "mode": "train"}
[12/09 00:36:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 1.29579, "dt_data": 0.75582, "dt_net": 0.53996, "eta": "0:00:01", "loss": 0.28357, "lr": 0.00010, "mode": "train"}
[12/09 00:36:44][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "245", "cur_iter": "1", "dt": 0.82379, "dt_data": 0.74927, "dt_net": 0.07452, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:44][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:44][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:44][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:44][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:44][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:44][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:44][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003207 seconds.
[12/09 00:36:44][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "245", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:36:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "246", "cur_iter": "1", "dt": 1.29749, "dt_data": 0.75784, "dt_net": 0.53964, "eta": "0:00:01", "loss": 0.27997, "lr": 0.00010, "mode": "train"}
[12/09 00:36:47][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "247", "cur_iter": "1", "dt": 1.29728, "dt_data": 0.75678, "dt_net": 0.54049, "eta": "0:00:01", "loss": 0.26734, "lr": 0.00010, "mode": "train"}
[12/09 00:36:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "248", "cur_iter": "1", "dt": 1.29888, "dt_data": 0.75937, "dt_net": 0.53951, "eta": "0:00:01", "loss": 0.27270, "lr": 0.00010, "mode": "train"}
[12/09 00:36:50][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "249", "cur_iter": "1", "dt": 1.29478, "dt_data": 0.75467, "dt_net": 0.54011, "eta": "0:00:01", "loss": 0.27141, "lr": 0.00010, "mode": "train"}
[12/09 00:36:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 1.29395, "dt_data": 0.75406, "dt_net": 0.53988, "eta": "0:00:01", "loss": 0.27326, "lr": 0.00010, "mode": "train"}
[12/09 00:36:52][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "250", "cur_iter": "1", "dt": 0.82470, "dt_data": 0.75020, "dt_net": 0.07449, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:52][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:52][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:52][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:52][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:52][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:52][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:52][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003025 seconds.
[12/09 00:36:52][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "250", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:36:53][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "251", "cur_iter": "1", "dt": 1.29539, "dt_data": 0.75602, "dt_net": 0.53936, "eta": "0:00:01", "loss": 0.27807, "lr": 0.00010, "mode": "train"}
[12/09 00:36:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "252", "cur_iter": "1", "dt": 1.29373, "dt_data": 0.75322, "dt_net": 0.54051, "eta": "0:00:01", "loss": 0.27650, "lr": 0.00010, "mode": "train"}
[12/09 00:36:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "253", "cur_iter": "1", "dt": 1.29588, "dt_data": 0.75614, "dt_net": 0.53974, "eta": "0:00:01", "loss": 0.27875, "lr": 0.00010, "mode": "train"}
[12/09 00:36:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "254", "cur_iter": "1", "dt": 1.29759, "dt_data": 0.75737, "dt_net": 0.54022, "eta": "0:00:01", "loss": 0.26442, "lr": 0.00010, "mode": "train"}
[12/09 00:36:59][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 1.30043, "dt_data": 0.76024, "dt_net": 0.54018, "eta": "0:00:01", "loss": 0.27308, "lr": 0.00010, "mode": "train"}
[12/09 00:36:59][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "255", "cur_iter": "1", "dt": 0.82518, "dt_data": 0.75076, "dt_net": 0.07441, "eta": "0:00:00", "mode": "val"}
[12/09 00:36:59][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:36:59][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:36:59][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:36:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:59][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:36:59][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:36:59][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:36:59][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003314 seconds.
[12/09 00:36:59][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "255", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "256", "cur_iter": "1", "dt": 1.29682, "dt_data": 0.75720, "dt_net": 0.53962, "eta": "0:00:01", "loss": 0.28120, "lr": 0.00010, "mode": "train"}
[12/09 00:37:02][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "257", "cur_iter": "1", "dt": 1.29639, "dt_data": 0.75646, "dt_net": 0.53993, "eta": "0:00:01", "loss": 0.27341, "lr": 0.00010, "mode": "train"}
[12/09 00:37:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "258", "cur_iter": "1", "dt": 1.29810, "dt_data": 0.75881, "dt_net": 0.53929, "eta": "0:00:01", "loss": 0.26640, "lr": 0.00010, "mode": "train"}
[12/09 00:37:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "259", "cur_iter": "1", "dt": 1.29462, "dt_data": 0.75413, "dt_net": 0.54049, "eta": "0:00:01", "loss": 0.26930, "lr": 0.00010, "mode": "train"}
[12/09 00:37:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 1.29811, "dt_data": 0.75835, "dt_net": 0.53975, "eta": "0:00:01", "loss": 0.29152, "lr": 0.00010, "mode": "train"}
[12/09 00:37:08][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "260", "cur_iter": "1", "dt": 0.85177, "dt_data": 0.77759, "dt_net": 0.07418, "eta": "0:00:00", "mode": "val"}
[12/09 00:37:08][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:37:08][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:37:08][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:37:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:08][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:37:08][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:08][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:37:08][INFO] ava_eval_helper.py: 169: AVA eval done in 0.002967 seconds.
[12/09 00:37:08][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "260", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "261", "cur_iter": "1", "dt": 1.29805, "dt_data": 0.75850, "dt_net": 0.53955, "eta": "0:00:01", "loss": 0.27359, "lr": 0.00010, "mode": "train"}
[12/09 00:37:11][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "262", "cur_iter": "1", "dt": 1.29403, "dt_data": 0.75347, "dt_net": 0.54056, "eta": "0:00:01", "loss": 0.28732, "lr": 0.00010, "mode": "train"}
[12/09 00:37:12][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "263", "cur_iter": "1", "dt": 1.29912, "dt_data": 0.75908, "dt_net": 0.54004, "eta": "0:00:01", "loss": 0.27600, "lr": 0.00010, "mode": "train"}
[12/09 00:37:13][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "264", "cur_iter": "1", "dt": 1.29680, "dt_data": 0.75684, "dt_net": 0.53996, "eta": "0:00:01", "loss": 0.26947, "lr": 0.00010, "mode": "train"}
[12/09 00:37:15][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 1.29510, "dt_data": 0.75524, "dt_net": 0.53986, "eta": "0:00:01", "loss": 0.27530, "lr": 0.00010, "mode": "train"}
[12/09 00:37:15][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "265", "cur_iter": "1", "dt": 0.82480, "dt_data": 0.75037, "dt_net": 0.07443, "eta": "0:00:00", "mode": "val"}
[12/09 00:37:16][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:37:16][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:37:16][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:37:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:16][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:37:16][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:16][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:37:16][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003204 seconds.
[12/09 00:37:16][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "265", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:17][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "266", "cur_iter": "1", "dt": 1.29683, "dt_data": 0.75688, "dt_net": 0.53995, "eta": "0:00:01", "loss": 0.27606, "lr": 0.00010, "mode": "train"}
[12/09 00:37:18][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "267", "cur_iter": "1", "dt": 1.29566, "dt_data": 0.75547, "dt_net": 0.54019, "eta": "0:00:01", "loss": 0.26545, "lr": 0.00010, "mode": "train"}
[12/09 00:37:20][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "268", "cur_iter": "1", "dt": 1.30075, "dt_data": 0.76060, "dt_net": 0.54015, "eta": "0:00:01", "loss": 0.27045, "lr": 0.00010, "mode": "train"}
[12/09 00:37:21][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "269", "cur_iter": "1", "dt": 1.29720, "dt_data": 0.75700, "dt_net": 0.54020, "eta": "0:00:01", "loss": 0.27303, "lr": 0.00010, "mode": "train"}
[12/09 00:37:22][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 1.29409, "dt_data": 0.75484, "dt_net": 0.53924, "eta": "0:00:01", "loss": 0.26525, "lr": 0.00010, "mode": "train"}
[12/09 00:37:23][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "270", "cur_iter": "1", "dt": 0.82532, "dt_data": 0.75092, "dt_net": 0.07440, "eta": "0:00:00", "mode": "val"}
[12/09 00:37:23][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:37:23][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:37:23][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:37:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:23][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:37:23][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:23][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:37:23][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003004 seconds.
[12/09 00:37:23][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "270", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:24][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "271", "cur_iter": "1", "dt": 1.29611, "dt_data": 0.75684, "dt_net": 0.53927, "eta": "0:00:01", "loss": 0.26423, "lr": 0.00010, "mode": "train"}
[12/09 00:37:26][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "272", "cur_iter": "1", "dt": 1.29402, "dt_data": 0.75386, "dt_net": 0.54015, "eta": "0:00:01", "loss": 0.28005, "lr": 0.00010, "mode": "train"}
[12/09 00:37:27][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "273", "cur_iter": "1", "dt": 1.29864, "dt_data": 0.75897, "dt_net": 0.53967, "eta": "0:00:01", "loss": 0.27877, "lr": 0.00010, "mode": "train"}
[12/09 00:37:28][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "274", "cur_iter": "1", "dt": 1.29762, "dt_data": 0.75756, "dt_net": 0.54005, "eta": "0:00:01", "loss": 0.27439, "lr": 0.00010, "mode": "train"}
[12/09 00:37:30][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 1.30054, "dt_data": 0.76056, "dt_net": 0.53998, "eta": "0:00:01", "loss": 0.27746, "lr": 0.00010, "mode": "train"}
[12/09 00:37:31][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "275", "cur_iter": "1", "dt": 0.82487, "dt_data": 0.75036, "dt_net": 0.07451, "eta": "0:00:00", "mode": "val"}
[12/09 00:37:31][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:37:31][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:37:31][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:37:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:31][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:37:31][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:31][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:37:31][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003184 seconds.
[12/09 00:37:31][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "275", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:32][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "276", "cur_iter": "1", "dt": 1.29681, "dt_data": 0.75730, "dt_net": 0.53950, "eta": "0:00:01", "loss": 0.27275, "lr": 0.00010, "mode": "train"}
[12/09 00:37:33][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "277", "cur_iter": "1", "dt": 1.29758, "dt_data": 0.75755, "dt_net": 0.54003, "eta": "0:00:01", "loss": 0.26681, "lr": 0.00010, "mode": "train"}
[12/09 00:37:35][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "278", "cur_iter": "1", "dt": 1.29987, "dt_data": 0.76055, "dt_net": 0.53931, "eta": "0:00:01", "loss": 0.27402, "lr": 0.00010, "mode": "train"}
[12/09 00:37:36][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "279", "cur_iter": "1", "dt": 1.29618, "dt_data": 0.75636, "dt_net": 0.53982, "eta": "0:00:01", "loss": 0.27077, "lr": 0.00010, "mode": "train"}
[12/09 00:37:37][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 1.29891, "dt_data": 0.75952, "dt_net": 0.53938, "eta": "0:00:01", "loss": 0.27975, "lr": 0.00010, "mode": "train"}
[12/09 00:37:39][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "280", "cur_iter": "1", "dt": 0.85116, "dt_data": 0.77704, "dt_net": 0.07411, "eta": "0:00:00", "mode": "val"}
[12/09 00:37:39][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:37:39][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:37:39][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:37:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:39][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:37:39][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:39][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:37:39][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003160 seconds.
[12/09 00:37:39][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "280", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:40][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "281", "cur_iter": "1", "dt": 1.29602, "dt_data": 0.75668, "dt_net": 0.53934, "eta": "0:00:01", "loss": 0.26886, "lr": 0.00010, "mode": "train"}
[12/09 00:37:42][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "282", "cur_iter": "1", "dt": 1.29707, "dt_data": 0.75664, "dt_net": 0.54043, "eta": "0:00:01", "loss": 0.28234, "lr": 0.00010, "mode": "train"}
[12/09 00:37:43][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "283", "cur_iter": "1", "dt": 1.29922, "dt_data": 0.75979, "dt_net": 0.53942, "eta": "0:00:01", "loss": 0.28033, "lr": 0.00010, "mode": "train"}
[12/09 00:37:45][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "284", "cur_iter": "1", "dt": 1.29396, "dt_data": 0.75374, "dt_net": 0.54022, "eta": "0:00:01", "loss": 0.26907, "lr": 0.00010, "mode": "train"}
[12/09 00:37:46][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 1.29664, "dt_data": 0.75656, "dt_net": 0.54007, "eta": "0:00:01", "loss": 0.26703, "lr": 0.00010, "mode": "train"}
[12/09 00:37:47][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "285", "cur_iter": "1", "dt": 0.82086, "dt_data": 0.74644, "dt_net": 0.07442, "eta": "0:00:00", "mode": "val"}
[12/09 00:37:47][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:37:47][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:37:47][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:37:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:47][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:37:47][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:47][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:37:47][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003165 seconds.
[12/09 00:37:47][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "285", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:48][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "286", "cur_iter": "1", "dt": 1.29664, "dt_data": 0.75731, "dt_net": 0.53933, "eta": "0:00:01", "loss": 0.27377, "lr": 0.00010, "mode": "train"}
[12/09 00:37:49][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "287", "cur_iter": "1", "dt": 1.29664, "dt_data": 0.75648, "dt_net": 0.54016, "eta": "0:00:01", "loss": 0.26905, "lr": 0.00010, "mode": "train"}
[12/09 00:37:51][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "288", "cur_iter": "1", "dt": 1.29766, "dt_data": 0.75727, "dt_net": 0.54039, "eta": "0:00:01", "loss": 0.27316, "lr": 0.00010, "mode": "train"}
[12/09 00:37:52][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "289", "cur_iter": "1", "dt": 1.29466, "dt_data": 0.75469, "dt_net": 0.53997, "eta": "0:00:01", "loss": 0.27575, "lr": 0.00010, "mode": "train"}
[12/09 00:37:54][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 1.29481, "dt_data": 0.75498, "dt_net": 0.53983, "eta": "0:00:01", "loss": 0.27485, "lr": 0.00010, "mode": "train"}
[12/09 00:37:54][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "290", "cur_iter": "1", "dt": 0.82176, "dt_data": 0.74736, "dt_net": 0.07440, "eta": "0:00:00", "mode": "val"}
[12/09 00:37:54][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:37:54][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:37:54][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:37:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:54][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:37:54][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:37:54][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:37:54][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003081 seconds.
[12/09 00:37:54][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "290", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:37:56][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "291", "cur_iter": "1", "dt": 1.29717, "dt_data": 0.75700, "dt_net": 0.54017, "eta": "0:00:01", "loss": 0.27148, "lr": 0.00010, "mode": "train"}
[12/09 00:37:57][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "292", "cur_iter": "1", "dt": 1.29810, "dt_data": 0.75803, "dt_net": 0.54007, "eta": "0:00:01", "loss": 0.27692, "lr": 0.00010, "mode": "train"}
[12/09 00:37:58][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "293", "cur_iter": "1", "dt": 1.29873, "dt_data": 0.75920, "dt_net": 0.53952, "eta": "0:00:01", "loss": 0.27096, "lr": 0.00010, "mode": "train"}
[12/09 00:38:00][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "294", "cur_iter": "1", "dt": 1.29823, "dt_data": 0.75770, "dt_net": 0.54052, "eta": "0:00:01", "loss": 0.26511, "lr": 0.00010, "mode": "train"}
[12/09 00:38:01][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 1.30069, "dt_data": 0.76117, "dt_net": 0.53952, "eta": "0:00:01", "loss": 0.27979, "lr": 0.00010, "mode": "train"}
[12/09 00:38:02][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "295", "cur_iter": "1", "dt": 0.82368, "dt_data": 0.74929, "dt_net": 0.07439, "eta": "0:00:00", "mode": "val"}
[12/09 00:38:02][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:38:02][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:38:02][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:38:02][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:38:02][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:38:02][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:38:02][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:38:02][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003336 seconds.
[12/09 00:38:02][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "295", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[12/09 00:38:03][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "296", "cur_iter": "1", "dt": 1.29337, "dt_data": 0.75415, "dt_net": 0.53922, "eta": "0:00:01", "loss": 0.27514, "lr": 0.00010, "mode": "train"}
[12/09 00:38:05][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "297", "cur_iter": "1", "dt": 1.29764, "dt_data": 0.75751, "dt_net": 0.54013, "eta": "0:00:01", "loss": 0.26911, "lr": 0.00010, "mode": "train"}
[12/09 00:38:06][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "298", "cur_iter": "1", "dt": 1.29950, "dt_data": 0.75998, "dt_net": 0.53951, "eta": "0:00:01", "loss": 0.27264, "lr": 0.00010, "mode": "train"}
[12/09 00:38:07][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "299", "cur_iter": "1", "dt": 1.29434, "dt_data": 0.75660, "dt_net": 0.53773, "eta": "0:00:01", "loss": 0.26702, "lr": 0.00010, "mode": "train"}
[12/09 00:38:09][INFO] logging.py:  96: json_stats: {"_type": "train_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 1.29754, "dt_data": 0.75891, "dt_net": 0.53863, "eta": "0:00:01", "loss": 0.27035, "lr": 0.00010, "mode": "train"}
[12/09 00:38:10][INFO] logging.py:  96: json_stats: {"_type": "val_iter", "cur_epoch": "300", "cur_iter": "1", "dt": 0.84616, "dt_data": 0.77214, "dt_net": 0.07401, "eta": "0:00:00", "mode": "val"}
[12/09 00:38:10][INFO] ava_eval_helper.py: 159: Evaluating with 1 unique GT frames.
[12/09 00:38:10][INFO] ava_eval_helper.py: 161: Evaluating with 1 unique detection frames
[12/09 00:38:10][INFO] ava_eval_helper.py: 284: AVA results wrote to detections_latest.csv
[12/09 00:38:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:38:10][INFO] ava_eval_helper.py: 284: AVA results wrote to groundtruth_latest.csv
[12/09 00:38:10][INFO] ava_eval_helper.py: 285: 	took 0 seconds.
[12/09 00:38:10][INFO] object_detection_evaluation.py: 770: The following classes have no ground truth examples: [2 4]
[12/09 00:38:10][INFO] ava_eval_helper.py: 169: AVA eval done in 0.003299 seconds.
[12/09 00:38:10][INFO] logging.py:  96: json_stats: {"RAM": "2.46/15.59G", "_type": "val_epoch", "cur_epoch": "300", "gpu_mem": "1.74G", "map": 0.54416, "mode": "val"}
[02/11 18:04:42][INFO] demo_net.py:  37: Run demo with config:
[02/11 18:04:42][INFO] demo_net.py:  38: AVA:
  ANNOTATION_DIR: /home/gnk/new/annotaions/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: 
  FRAME_DIR: /mnt/dst_datasets/own_omni_dataset/theodore_v3/images
  FRAME_LIST_DIR: /home/gnk/new/frame_lists/
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: val_full.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: action_list.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val_new3_path.csv']
  TEST_PREDICT_BOX_LISTS: ['test_full.csv']
  TRAIN_GT_BOX_LISTS: ['train_full.csv']
  TRAIN_LISTS: ['train_new3_path.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: /home/gnk/data/ava/
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 5
  TEST_CROP_SIZE: 256
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 2
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.5
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: True
  FPS: 5
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: /home/gnk/data_ava/data/ava/test/test.mp4
  LABEL_FILE_PATH: /home/gnk/data_ava/data/ava/annotations/AVA_classnames.json
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 0
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: 0
DETECTION:
  ALIGNED: False
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 1
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 4
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[6, 13, 20], []], [[], []]]
  POOL: [[[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 101
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 0.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.01
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: /home/gnk/data_ava/data/ava/annotations/AVA_classnames.json
  CONFUSION_MATRIX:
    ENABLE: True
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: True
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: /home/gnk/ava2/out_log
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: True
    TOPK_PREDS: 1
  PREDICTIONS_PATH: /home/gnk/ava2/predictions/
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 8
  CHECKPOINT_FILE_PATH: /home/gnk/ava2/predictions/checkpoints/checkpoints/checkpoint_epoch_00040.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: /home/gnk/ava2/predictions/
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 4
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: /home/gnk/ava2/predictions/checkpoints/checkpoints/checkpoint_epoch_00050.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[02/11 18:04:45][INFO] predictor.py: 185: Initialized Detectron2 Object Detection Model.
[02/11 18:04:46][INFO] checkpoint.py: 138: Loading checkpoint from detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
[02/11 18:04:46][INFO] file_io.py: 597: URL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl cached in /home/gnk/.torch/iopath_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
[02/11 18:04:46][INFO] detection_checkpoint.py:  44: Reading a file from 'Detectron2 Model Zoo'
[02/11 18:04:46][INFO] predictor.py:  45: Start loading model weights.
[02/11 18:04:46][INFO] checkpoint.py: 209: Loading network weights from /home/gnk/ava2/predictions/checkpoints/checkpoints/checkpoint_epoch_00040.pyth.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s1_fuse.conv_f2s.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s2_fuse.conv_f2s.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s3_fuse.conv_f2s.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_theta.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_theta.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_phi.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_phi.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_g.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_g.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_out.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_out.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_theta.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_theta.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_phi.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_phi.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_g.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_g.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_out.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_out.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_theta.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_theta.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_phi.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_phi.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_g.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_g.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_out.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_out.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.weight not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.bias not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.running_mean not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.running_var not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:04:47][INFO] checkpoint.py: 332: Network weights s4_fuse.conv_f2s.weight not loaded.
[02/11 18:04:47][INFO] predictor.py:  47: Finish loading model weights
[02/11 18:04:47][INFO] demo_net.py: 119: Finish demo in: 5.245807647705078
[02/11 18:06:14][INFO] demo_net.py:  37: Run demo with config:
[02/11 18:06:14][INFO] demo_net.py:  38: AVA:
  ANNOTATION_DIR: /home/gnk/new/annotaions/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: 
  FRAME_DIR: /mnt/dst_datasets/own_omni_dataset/theodore_v3/images
  FRAME_LIST_DIR: /home/gnk/new/frame_lists/
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: val_full.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: action_list.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val_new3_path.csv']
  TEST_PREDICT_BOX_LISTS: ['test_full.csv']
  TRAIN_GT_BOX_LISTS: ['train_full.csv']
  TRAIN_LISTS: ['train_new3_path.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: /home/gnk/data/ava/
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 5
  TEST_CROP_SIZE: 256
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 2
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.5
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: True
  FPS: 5
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: /home/gnk/data_ava/data/ava/test/test.mp4
  LABEL_FILE_PATH: /home/gnk/data_ava/data/ava/annotations/AVA_classnames.json
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 0
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: 0
DETECTION:
  ALIGNED: False
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 1
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 4
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[6, 13, 20], []], [[], []]]
  POOL: [[[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 101
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 0.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.01
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: /home/gnk/data_ava/data/ava/annotations/AVA_classnames.json
  CONFUSION_MATRIX:
    ENABLE: True
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: True
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: /home/gnk/ava2/out_log
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: True
    TOPK_PREDS: 1
  PREDICTIONS_PATH: /home/gnk/ava2/predictions/
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 8
  CHECKPOINT_FILE_PATH: /home/gnk/ava2/predictions/checkpoints/checkpoints/checkpoint_epoch_00040.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: /home/gnk/ava2/predictions/
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 4
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: /home/gnk/ava2/predictions/checkpoints/checkpoints/checkpoint_epoch_00050.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: caffe2
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[02/11 18:06:17][INFO] predictor.py: 185: Initialized Detectron2 Object Detection Model.
[02/11 18:06:17][INFO] checkpoint.py: 138: Loading checkpoint from detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
[02/11 18:06:17][INFO] file_io.py: 597: URL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl cached in /home/gnk/.torch/iopath_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
[02/11 18:06:17][INFO] detection_checkpoint.py:  44: Reading a file from 'Detectron2 Model Zoo'
[02/11 18:06:17][INFO] predictor.py:  45: Start loading model weights.
[02/11 18:06:17][INFO] checkpoint.py: 209: Loading network weights from /home/gnk/ava2/predictions/checkpoints/checkpoints/checkpoint_epoch_00040.pyth.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s1_fuse.conv_f2s.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s2_fuse.conv_f2s.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s3_fuse.conv_f2s.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res6.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_theta.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_theta.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_phi.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_phi.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_g.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_g.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_out.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.conv_out.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal6.bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res7.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res8.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res9.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res10.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res11.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res12.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res13.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_theta.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_theta.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_phi.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_phi.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_g.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_g.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_out.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.conv_out.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal13.bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res14.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res15.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res16.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res17.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res18.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res19.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res20.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_theta.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_theta.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_phi.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_phi.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_g.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_g.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_out.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.conv_out.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_nonlocal20.bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res21.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway0_res22.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res6.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res7.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res8.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res9.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res10.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res11.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res12.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res13.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res14.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res15.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res16.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res17.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res18.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res19.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res20.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res21.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.a_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.b_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.weight not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.bias not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.running_mean not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.running_var not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4.pathway1_res22.branch2.c_bn.num_batches_tracked not loaded.
[02/11 18:06:17][INFO] checkpoint.py: 332: Network weights s4_fuse.conv_f2s.weight not loaded.
[02/11 18:06:17][INFO] predictor.py:  47: Finish loading model weights
[02/11 18:06:17][INFO] demo_net.py: 119: Finish demo in: 2.9826316833496094
[02/23 10:51:39][INFO] train_net.py: 392: Train with config:
[02/23 10:51:39][INFO] train_net.py: 393: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data/ava/annotations',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.1.csv',
         'FRAME_DIR': '/home/gnk/data/ava/frames',
         'FRAME_LIST_DIR': '/home/gnk/data/ava/frame_lists',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.1.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.1_for_activitynet_2018.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes_filterd.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train1_v2.1.csv'],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['ava_train_v2.2.csv',
                                     'person_box_67091280_iou90/ava_detection_train_boxes_and_labels_include_negative_v2.2.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 0,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': False,
 'LOG_PERIOD': 10,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 80,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 64,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[02/23 10:52:24][INFO] train_net.py: 392: Train with config:
[02/23 10:52:24][INFO] train_net.py: 393: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data/ava/annotations',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.1.csv',
         'FRAME_DIR': '/home/gnk/data/ava/frames',
         'FRAME_LIST_DIR': '/home/gnk/data/ava/frame_lists',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.1.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.1_for_activitynet_2018.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes_filterd.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train1_v2.1.csv'],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['ava_train_v2.2.csv',
                                     'person_box_67091280_iou90/ava_detection_train_boxes_and_labels_include_negative_v2.2.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 0,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': False,
 'LOG_PERIOD': 10,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 80,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 64,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[02/23 10:52:42][INFO] train_net.py: 392: Train with config:
[02/23 10:52:42][INFO] train_net.py: 393: {'AVA': {'ANNOTATION_DIR': '/home/gnk/data/ava/annotations',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.8,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.1.csv',
         'FRAME_DIR': '/home/gnk/data/ava/frames',
         'FRAME_LIST_DIR': '/home/gnk/data/ava/frame_lists',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.1.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.1_for_activitynet_2018.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val3.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes_filterd.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train1_v2.1.csv'],
         'TRAIN_LISTS': ['train3.csv'],
         'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
         'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                              [-0.5808, -0.0045, -0.814],
                              [-0.5836, -0.6948, 0.4203]],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': ['ava_train_v2.2.csv',
                                     'person_box_67091280_iou90/ava_detection_train_boxes_and_labels_include_negative_v2.2.csv'],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'DATA': {'DECODING_BACKEND': 'pyav',
          'ENSEMBLE_METHOD': 'sum',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 32,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/home/gnk/data/ava',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 2,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_SCALES': [256, 320]},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 0,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': False,
 'LOG_PERIOD': 10,
 'MODEL': {'ARCH': 'slowfast',
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'HEAD_ACT': 'sigmoid',
           'LOSS_FUNC': 'bce',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 80,
           'SINGLE_PATHWAY_ARCH': ['c2d', 'i3d', 'slow', 'x3d']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [2, 2]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [1, 1]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LRS': [1, 0.1, 0.01, 0.001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 20,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [0, 10, 15, 20],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.000125,
            'WEIGHT_DECAY': 1e-07},
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 1,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 64,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5},
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
